{
    "topic_description": "novel prompting methods for large language models to improve mathematical problem solving",
    "idea_name": "Exemplar-Guided Prompting",
    "raw_idea": {
        "Problem": "Large language models can struggle to generate accurate solutions to mathematical problems that are significantly different from the examples they were trained on or prompted with.",
        "Existing Methods": "Few-shot prompting methods, such as chain-of-thought prompting, provide a small set of examples to guide the model's reasoning process. However, these examples are often manually selected and may not be optimally relevant to the target problem.",
        "Motivation": "Retrieving and prompting with the most relevant examples from a large corpus could help guide the model to generate more accurate solutions, especially for problems that are dissimilar to the training data. By dynamically selecting examples based on their similarity to the target problem, we can provide more tailored and effective guidance.",
        "Proposed Method": "We propose Exemplar-Guided Prompting (EGP), a method that retrieves the most relevant examples from a large corpus and uses them to guide the model's reasoning process. The prompt includes instructions like: '1) Retrieve the top-k examples from the corpus that are most similar to the target problem, based on a semantic similarity metric. 2) Analyze the key features and solution steps of the retrieved examples. 3) Adapt the solution steps from the examples to solve the target problem.' By dynamically selecting and leveraging relevant examples, EGP can guide the model to generate more accurate solutions, even for problems that are dissimilar to the training data.",
        "Experiment Plan": "We will evaluate EGP on mathematical reasoning benchmarks like GSM8K and MATH, comparing its performance to few-shot prompting baselines that use manually selected examples. We will also experiment with different semantic similarity metrics and values of k for example retrieval. Additionally, we will analyze the relationship between the similarity of the retrieved examples and the accuracy of the generated solutions."
    },
    "full_experiment_plan": {
        "Title": "Exemplar-Guided Prompting: Retrieving Relevant Examples for Mathematical Problem Solving",
        "Problem Statement": "Large language models can struggle to generate accurate solutions to mathematical problems that are significantly different from the examples they were trained on or prompted with. Existing few-shot prompting methods, such as chain-of-thought prompting, provide a small set of manually selected examples to guide the model's reasoning process. However, these examples may not be optimally relevant to the target problem, limiting the effectiveness of the guidance.",
        "Motivation": "Retrieving and prompting with the most relevant examples from a large corpus could help guide the model to generate more accurate solutions, especially for problems that are dissimilar to the training data. By dynamically selecting examples based on their similarity to the target problem, we can provide more tailored and effective guidance. This approach leverages the model's ability to reason about the relevance of examples and adapt the solution steps to the target problem.",
        "Proposed Method": "We propose Exemplar-Guided Prompting (EGP), a method that retrieves the most relevant examples from a large corpus and uses them to guide the model's reasoning process. The prompt includes instructions like: '1) Retrieve the top-k examples from the corpus that are most similar to the target problem, based on a semantic similarity metric. 2) Analyze the key features and solution steps of the retrieved examples. 3) Adapt the solution steps from the examples to solve the target problem.' By dynamically selecting and leveraging relevant examples, EGP can guide the model to generate more accurate solutions, even for problems that are dissimilar to the training data.",
        "Step-by-Step Experiment Plan": {
            "Step 1: Prepare Datasets": "We will use the GSM8K and MATH datasets for evaluating the performance of EGP on mathematical problem solving. These datasets contain a diverse set of mathematical problems and their solutions. We will split each dataset into a training set (for building the example corpus) and a test set (for evaluating the model's performance).",
            "Step 2: Build Example Corpus": "Using the training set of each dataset, we will build a corpus of examples. Each example will consist of a mathematical problem and its corresponding solution. We will preprocess the examples by tokenizing the text and representing each example as a dense vector using a sentence embedding model (e.g., SBERT).",
            "Step 3: Implement Retrieval Function": "We will implement a retrieval function that takes a target problem as input and retrieves the top-k most similar examples from the corpus. The similarity will be computed using a semantic similarity metric, such as cosine similarity, between the dense vector representations of the target problem and the examples in the corpus.",
            "Step 4: Construct Prompts": "For each target problem in the test set, we will construct a prompt using EGP. The prompt will include the following components:\n1) The target problem itself.\n2) Instructions for retrieving the top-k most similar examples from the corpus.\n3) Instructions for analyzing the key features and solution steps of the retrieved examples.\n4) Instructions for adapting the solution steps from the examples to solve the target problem.\nWe will experiment with different values of k (e.g., 3, 5, 10) to determine the optimal number of examples to retrieve.",
            "Step 5: Evaluate Model Performance": "We will use GPT-3.5 (text-davinci-003) and GPT-4 as the base models for our experiments. For each target problem in the test set, we will prompt the model using EGP and generate a solution. We will evaluate the generated solutions using the following metrics:\n1) Accuracy: The percentage of problems for which the model generates the correct solution.\n2) BLEU score: A measure of the similarity between the generated solution and the reference solution.\nWe will compare the performance of EGP with few-shot prompting baselines that use manually selected examples, such as chain-of-thought prompting.",
            "Step 6: Analyze Results": "We will analyze the results to determine the effectiveness of EGP in improving the model's performance on mathematical problem solving. We will examine the relationship between the similarity of the retrieved examples and the accuracy of the generated solutions. Additionally, we will qualitatively analyze the retrieved examples and the generated solutions to gain insights into how EGP guides the model's reasoning process."
        },
        "Test Case Examples": {
            "Test Case 1": {
                "Target Problem": "A rectangular garden has a length that is 3 meters longer than its width. If the perimeter of the garden is 26 meters, what is the area of the garden?",
                "Baseline Prompt (Chain-of-Thought)": "A rectangular garden has a length that is 3 meters longer than its width. If the perimeter of the garden is 26 meters, what is the area of the garden? Let's solve this step by step:",
                "Baseline Output": "1) Let's denote the width of the garden as w and the length as l.\n2) We know that l = w + 3.\n3) The perimeter of the garden is 26 meters, so 2(l + w) = 26.\n4) Substituting l with w + 3, we get 2(w + 3 + w) = 26.\n5) Simplifying, 4w + 6 = 26.\n6) Subtracting 6 from both sides, 4w = 20.\n7) Dividing both sides by 4, w = 5.\n8) Since l = w + 3, l = 5 + 3 = 8.\n9) The area of the garden is l * w = 8 * 5 = 40.\nTherefore, the area of the garden is 40 square meters.",
                "EGP Prompt": "A rectangular garden has a length that is 3 meters longer than its width. If the perimeter of the garden is 26 meters, what is the area of the garden?\n\nInstructions:\n1) Retrieve the top-3 examples from the corpus that are most similar to the target problem, based on cosine similarity.\n2) Analyze the key features and solution steps of the retrieved examples.\n3) Adapt the solution steps from the examples to solve the target problem.",
                "EGP Output": "Retrieved Examples:\n1) A rectangular field has a length that is 5 meters longer than its width. If the perimeter of the field is 50 meters, find the area of the field.\nSolution: Let the width be w. Then, the length is w + 5. Perimeter = 2(l + w) = 2(w + 5 + w) = 4w + 10 = 50. Solving, w = 10. Length = 10 + 5 = 15. Area = l * w = 15 * 10 = 150 square meters.\n\n2) The length of a rectangular pool is 4 meters more than its width. The perimeter of the pool is 32 meters. What is the area of the pool?\nSolution: Let the width be w. Then, the length is w + 4. Perimeter = 2(l + w) = 2(w + 4 + w) = 4w + 8 = 32. Solving, w = 6. Length = 6 + 4 = 10. Area = l * w = 10 * 6 = 60 square meters.\n\n3) A rectangular room has a length that is 2 meters longer than its width. If the perimeter of the room is 28 meters, calculate the area of the room.\nSolution: Let the width be w. Then, the length is w + 2. Perimeter = 2(l + w) = 2(w + 2 + w) = 4w + 4 = 28. Solving, w = 6. Length = 6 + 2 = 8. Area = l * w = 8 * 6 = 48 square meters.\n\nSolution for the target problem:\nLet the width of the garden be w. Then, the length is w + 3.\nPerimeter = 2(l + w) = 2(w + 3 + w) = 4w + 6 = 26\nSolving the equation, 4w = 20, so w = 5.\nLength = 5 + 3 = 8.\nArea = l * w = 8 * 5 = 40 square meters.\n\nTherefore, the area of the rectangular garden is 40 square meters.",
                "Explanation": "The retrieved examples provide a clear pattern for solving problems involving rectangular shapes with a length that is a certain amount longer than the width. By adapting the solution steps from the examples, the model can accurately solve the target problem. The examples guide the model to set up the equations for the perimeter and solve for the width, then calculate the length and area accordingly."
            },
            "Test Case 2": {
                "Target Problem": "A store sells apples and bananas. Apples cost $0.50 each and bananas cost $0.75 each. If a customer buys a total of 20 pieces of fruit and the bill comes to $13.50, how many apples and bananas did the customer buy?",
                "Baseline Prompt (Chain-of-Thought)": "A store sells apples and bananas. Apples cost $0.50 each and bananas cost $0.75 each. If a customer buys a total of 20 pieces of fruit and the bill comes to $13.50, how many apples and bananas did the customer buy? Let's solve this step by step:",
                "Baseline Output": "1) Let's denote the number of apples as a and the number of bananas as b.\n2) We know that the total number of fruits is 20, so a + b = 20.\n3) The total bill is $13.50, and each apple costs $0.50 while each banana costs $0.75. So, 0.50a + 0.75b = 13.50.\n4) We have a system of two equations:\na + b = 20\n0.50a + 0.75b = 13.50\n5) Solving this system of equations:\na = 20 - b\n0.50(20 - b) + 0.75b = 13.50\n10 - 0.50b + 0.75b = 13.50\n10 + 0.25b = 13.50\n0.25b = 3.50\nb = 14\n6) Substituting b = 14 into a + b = 20, we get:\na + 14 = 20\na = 6\n\nTherefore, the customer bought 6 apples and 14 bananas.",
                "EGP Prompt": "A store sells apples and bananas. Apples cost $0.50 each and bananas cost $0.75 each. If a customer buys a total of 20 pieces of fruit and the bill comes to $13.50, how many apples and bananas did the customer buy?\n\nInstructions:\n1) Retrieve the top-3 examples from the corpus that are most similar to the target problem, based on cosine similarity.\n2) Analyze the key features and solution steps of the retrieved examples.\n3) Adapt the solution steps from the examples to solve the target problem.",
                "EGP Output": "Retrieved Examples:\n1) A fruit stand sells oranges and pears. Oranges cost $0.60 each and pears cost $0.80 each. If a customer buys a total of 25 pieces of fruit and the bill comes to $16.00, how many oranges and pears did the customer buy?\nSolution: Let o be the number of oranges and p be the number of pears. o + p = 25 and 0.60o + 0.80p = 16.00. Solving the system of equations, o = 15 and p = 10. The customer bought 15 oranges and 10 pears.\n\n2) A candy store sells gumballs and lollipops. Gumballs cost $0.20 each and lollipops cost $0.50 each. If a customer buys a total of 30 pieces of candy and the bill comes to $9.00, how many gumballs and lollipops did the customer buy?\nSolution: Let g be the number of gumballs and l be the number of lollipops. g + l = 30 and 0.20g + 0.50l = 9.00. Solving the system of equations, g = 20 and l = 10. The customer bought 20 gumballs and 10 lollipops.\n\n3) A bakery sells cookies and muffins. Cookies cost $0.75 each and muffins cost $1.25 each. If a customer buys a total of 18 items and the bill comes to $18.00, how many cookies and muffins did the customer buy?\nSolution: Let c be the number of cookies and m be the number of muffins. c + m = 18 and 0.75c + 1.25m = 18.00. Solving the system of equations, c = 12 and m = 6. The customer bought 12 cookies and 6 muffins.\n\nSolution for the target problem:\nLet a be the number of apples and b be the number of bananas.\na + b = 20 (total number of fruits)\n0.50a + 0.75b = 13.50 (total bill)\n\nSolving the system of equations:\na = 20 - b\n0.50(20 - b) + 0.75b = 13.50\n10 - 0.50b + 0.75b = 13.50\n10 + 0.25b = 13.50\n0.25b = 3.50\nb = 14\n\nSubstituting b = 14 into a + b = 20:\na + 14 = 20\na = 6\n\nTherefore, the customer bought 6 apples and 14 bananas.",
                "Explanation": "The retrieved examples demonstrate a consistent approach for solving problems involving two types of items with different prices, where the total number of items and the total bill are known. By setting up a system of equations and solving for the variables, the model can determine the number of each type of item purchased. The examples provide a clear template for the model to follow, leading to an accurate solution for the target problem."
            }
        },
        "Fallback Plan": "If the proposed Exemplar-Guided Prompting method does not significantly improve the model's performance compared to the baselines, we can consider the following alternative approaches:\n\n1) Analyze the retrieved examples to determine if they are truly relevant to the target problem. If the examples are not sufficiently similar or do not provide useful guidance, we can experiment with different semantic similarity metrics or adjust the number of retrieved examples (k).\n\n2) Investigate the quality of the example corpus. If the corpus lacks diversity or does not cover a wide range of problem types, we can expand the corpus by incorporating additional datasets or generating synthetic examples using data augmentation techniques.\n\n3) Explore alternative prompting strategies. Instead of providing explicit instructions for retrieving, analyzing, and adapting examples, we can experiment with more open-ended prompts that allow the model to develop its own reasoning process based on the retrieved examples.\n\n4) Conduct an error analysis to identify common patterns or challenges in the problems where EGP fails to generate accurate solutions. This analysis can provide insights into the limitations of the approach and guide the development of more targeted improvements.\n\n5) Consider combining EGP with other prompting techniques, such as chain-of-thought prompting or self-consistency, to leverage the strengths of multiple approaches.\n\nIf the proposed method and the alternative approaches do not yield satisfactory results, we can pivot the project to focus on analyzing the factors that influence the effectiveness of example-based prompting for mathematical problem solving. This analysis can include studying the relationship between example similarity and solution accuracy, evaluating the impact of example diversity on model performance, and investigating the role of problem complexity in the success of example-guided prompting. The insights gained from this analysis can inform the design of future prompting strategies and contribute to a better understanding of how language models reason about mathematical problems."
    }
}