{
    "topic_description": "novel prompting methods for large language models to improve mathematical problem solving",
    "idea_name": "Visual Hint Prompting",
    "raw_idea": {
        "Problem": "Large language models struggle with mathematical and scientific problems that are most naturally solved with visual aids like diagrams, plots and tables. Solving such problems purely textually fails to leverage human insights from visual understanding.",
        "Existing Methods": "Benchmarks like GeoQA and PlotQA involve problems that are accompanied by visual information like diagrams and plots. Most existing methods rely on OCR to extract text from the visuals and then use the text to solve the problems, without deeply understanding the visual semantics.",
        "Motivation": "Many mathematical and scientific concepts are inherently visual (e.g., geometry, graphs and charts). Using visual representations makes the problems more intuitive to understand and solve for humans. We hypothesize that reasoning with visual hints can also improve the problem solving capabilities of language models.",
        "Proposed Method": "We propose Visual Hint Prompting (VHP) which associates key visual representations (diagrams, plots, tables) with math/science problems. For each problem, VHP first prompts LLMs to generate high-level descriptions of the insights that can be drawn from the associated visuals (e.g., 'the diagram shows that angle ABC is a right angle'). These visual hints are then appended to the problem text, and the LLM is prompted to generate the solution while taking into account the visual hints.",
        "Experiment Plan": "Evaluate VHP on visual math/science benchmarks like GeoQA and PlotQA. Compare with baselines that use plain text extracted from the visuals. Perform qualitative analysis on the generated visual hints and how they impact the solution quality. Collect expert annotations on the visual hints to enable supervised training and evaluation."
    },
    "full_experiment_plan": {
        "Title": "Visual Hint Prompting: Leveraging Visual Semantics for Improved Mathematical Problem Solving in Large Language Models",
        "Problem Statement": "Large language models struggle with mathematical and scientific problems that are most naturally solved with visual aids like diagrams, plots and tables. Solving such problems purely textually fails to leverage human insights from visual understanding.",
        "Motivation": "Existing methods for visual question answering benchmarks like GeoQA and PlotQA typically rely on OCR to extract text from the visuals and then use the text to solve the problems, without deeply understanding the visual semantics. However, many mathematical and scientific concepts are inherently visual (e.g., geometry, graphs and charts). Using visual representations makes the problems more intuitive to understand and solve for humans. We hypothesize that reasoning with visual hints can also improve the problem solving capabilities of language models.",
        "Proposed Method": "We propose Visual Hint Prompting (VHP) which associates key visual representations (diagrams, plots, tables) with math/science problems. For each problem, VHP first prompts LLMs to generate high-level descriptions of the insights that can be drawn from the associated visuals (e.g., 'the diagram shows that angle ABC is a right angle'). These visual hints are then appended to the problem text, and the LLM is prompted to generate the solution while taking into account the visual hints.",
        "Step-by-Step Experiment Plan": {
            "Step 1: Gather Datasets": "Evaluate VHP on visual math/science benchmarks like GeoQA and PlotQA. GeoQA contains geometry problems with diagrams. PlotQA contains data science problems with plots and charts.",
            "Step 2: Construct Prompts": "For each problem, the baseline prompt includes just the problem text. The VHP prompt has two steps:\n1) Visual Hint Generation: Prompt the LLM to generate high-level descriptions of the insights from the associated visual. Example: 'What key information can be derived from this diagram to help solve the problem?'\n2) Solution Generation: Append the generated visual hints to the original problem text, and prompt the LLM to solve the augmented problem. Example: '{Original problem text} Based on the diagram, we can see that: {Generated visual hints}. Using this information, answer the question.'",
            "Step 3: Select Models": "Evaluate VHP on GPT-3.5 (text-davinci-002) and GPT-4 via the OpenAI API. As an open-source alternative, also try Anthropic's Claude model.",
            "Step 4: Get Results": "For each problem in the test sets of GeoQA and PlotQA:\n1) Get the baseline result by prompting the LLM with just the problem text.\n2) Get the VHP result by first generating visual hints, appending them to the problem, and prompting the LLM to solve the augmented problem.\n3) Evaluate the accuracy of the generated answers against the ground truth.",
            "Step 5: Analyze Results": "1) Compare the overall accuracy of VHP vs the text-only baseline on GeoQA and PlotQA. Hypothesize that VHP outperforms the baseline by leveraging visual semantics.\n2) Perform qualitative analysis on the generated visual hints. Manually assess if they capture the key insights from the visuals. Provide representative examples.\n3) Analyze the types of problems where VHP helps the most vs least. Hypothesize that VHP is most beneficial for problems that rely heavily on visual concepts and spatial reasoning."
        },
        "Test Case Examples": {
            "Baseline Prompt Input": "In the diagram, ABCD is a square and BCE is an equilateral triangle. What is the measure of angle DEC? \n[Diagram showing square ABCD with equilateral triangle BCE outside the square, sharing side BC]",
            "Baseline Prompt Expected Output": "Angle DEC is 15 degrees.",
            "Proposed Prompt Input (VHP Step 1: Visual Hint Generation)": "In the diagram, ABCD is a square and BCE is an equilateral triangle. What key information can be derived from this diagram to help find the measure of angle DEC? \n[Diagram showing square ABCD with equilateral triangle BCE outside the square, sharing side BC]",
            "Proposed Prompt Expected Output (VHP Step 1: Visual Hint Generation)": "- ABCD being a square means all its angles are 90 degrees.\n- BCE being an equilateral triangle means all its angles are 60 degrees.\n- Triangle BCE shares side BC with the square. So angle BCD of the square coincides with angle BCE of the triangle.",
            "Proposed Prompt Input (VHP Step 2: Solution Generation)": "In the diagram, ABCD is a square and BCE is an equilateral triangle. What is the measure of angle DEC? \n[Diagram showing square ABCD with equilateral triangle BCE outside the square, sharing side BC]\nBased on the diagram, we can see that:\n- ABCD being a square means all its angles are 90 degrees.\n- BCE being an equilateral triangle means all its angles are 60 degrees. \n- Triangle BCE shares side BC with the square. So angle BCD of the square coincides with angle BCE of the triangle.\nUsing this information, answer the question.",
            "Proposed Prompt Expected Output (VHP Step 2: Solution Generation)": "Angle BCD is 90 degrees since ABCD is a square. Angle BCE is 60 degrees since BCE is an equilateral triangle. Angle BCD and BCE coincide, which means angle DEC is the difference between them. So angle DEC is 90 - 60 = 30 degrees.",
            "Explanation": "The baseline prompt fails to leverage the key information conveyed by the diagram, leading to an incorrect answer. VHP first generates the visual hints, highlighting the important properties of the square and equilateral triangle. By incorporating these hints, VHP successfully solves the problem, demonstrating the benefit of visual reasoning."
        },
        "Fallback Plan": "If VHP does not significantly outperform the baselines, we can:\n1) Analyze the quality of the generated visual hints. If they are not accurately capturing the visual semantics, explore alternative prompting strategies for hint generation, e.g., using few-shot examples.\n2) Investigate the integration of visual hints into the problem solving process. Experiment with different prompt formats for combining the problem text and visual hints.\n3) Collect expert annotations on a subset of problems to create a dataset of high-quality visual hints. Use these to evaluate the generated hints and fine-tune the hint generation process.\n4) If the visual hints are reasonable but do not improve problem solving, it suggests limitations in the LLM's ability to effectively utilize visual information. In this case, focus the paper on analyzing these limitations and proposing future directions for integrating visual reasoning into language models."
    }
}