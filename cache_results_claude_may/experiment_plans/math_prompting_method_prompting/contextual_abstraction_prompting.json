{
    "topic_description": "novel prompting methods for large language models to improve mathematical problem solving",
    "idea_name": "Contextual Abstraction Prompting",
    "raw_idea": {
        "Problem": "Large language models often struggle with mathematical problem solving when the problems involve complex real-world contexts and require identifying relevant information from irrelevant details.",
        "Existing Methods": "Existing benchmarks like GSM8K and MATH contain mathematical word problems with varying levels of contextual complexity. Baseline methods include chain-of-thought prompting and program-of-thoughts prompting.",
        "Motivation": "Humans often solve complex contextualized math problems by first abstracting away irrelevant details to form a simplified problem statement, and then solving the simplified problem. We hypothesize that prompting LLMs to mimic this two-stage abstraction and solving process can improve their mathematical problem solving capabilities.",
        "Proposed Method": "We propose Contextual Abstraction Prompting (CAP) which consists of two stages: 1) Abstraction: Given a contextualized math problem, prompt the LLM to generate a simplified version of the problem that preserves only the relevant mathematical quantities and relationships, discarding irrelevant contextual details. 2) Solving: Prompt the LLM to solve the abstracted problem using chain-of-thought reasoning or program synthesis. The final answer is then mapped back to the original context.",
        "Experiment Plan": "Evaluate CAP on contextualized math problem benchmarks like GSM8K and MATH. Compare with baselines like chain-of-thought prompting and program-of-thoughts prompting in terms of answer accuracy. Perform ablations to study the impact of the abstraction stage."
    },
    "full_experiment_plan": {
        "Title": "Contextual Abstraction Prompting: Improving Mathematical Problem Solving in Large Language Models",
        "Problem Statement": "Large language models often struggle with mathematical problem solving when the problems involve complex real-world contexts and require identifying relevant information from irrelevant details.",
        "Motivation": "Existing methods like chain-of-thought prompting and program-of-thoughts prompting have shown promising results on mathematical problem solving benchmarks like GSM8K and MATH. However, these methods still struggle with problems that have complex contextual details, as the model can be distracted by irrelevant information. Humans often solve such problems by first abstracting away the irrelevant details to form a simplified problem statement, and then solving the simplified problem. We hypothesize that prompting LLMs to mimic this two-stage abstraction and solving process can improve their mathematical problem solving capabilities, especially on problems with complex contexts.",
        "Proposed Method": "We propose Contextual Abstraction Prompting (CAP) which consists of two stages:\n1. Abstraction: Given a contextualized math problem, prompt the LLM to generate a simplified version of the problem that preserves only the relevant mathematical quantities and relationships, discarding irrelevant contextual details.\n2. Solving: Prompt the LLM to solve the abstracted problem using chain-of-thought reasoning or program synthesis.\nThe final answer is then mapped back to the original context.",
        "Step-by-Step Experiment Plan": {
            "Step 1: Gather Datasets": "Evaluate CAP on the GSM8K and MATH datasets. These datasets contain mathematical word problems with varying levels of contextual complexity. Use the official train/test splits.",
            "Step 2: Construct Prompts": "1. Baseline Prompts:\n   a. Direct: Directly prompt the model with the question.\n   b. Chain-of-Thought (CoT): Append \"Let's solve this step-by-step:\" to the question.\n   c. Program-of-Thoughts (PoT): Prompt the model to generate a Python program to solve the problem.\n2. CAP Prompts:\n   a. Abstraction: Prompt the model to simplify the problem by preserving only the relevant quantities and relationships. Example prompt:\n      \"Simplify the problem by only keeping the relevant mathematical quantities and relationships:\\n\\nOriginal problem: {problem}\\n\\nSimplified problem:\"\n   b. Solving: Feed the abstracted problem to the model with CoT or PoT prompts.",
            "Step 3: Select Models": "Evaluate the prompts on GPT-3.5 (text-davinci-003) and GPT-4 via the OpenAI API.",
            "Step 4: Get Results": "For each combination of model and prompting method, generate answers for the test examples in GSM8K and MATH.",
            "Step 5: Analyze Results": "1. Calculate the answer accuracy for each combination of model and prompting method.\n2. Compare the accuracy of CAP with the baseline methods. Hypothesize that CAP will outperform the baselines, especially on problems with complex contexts.\n3. Perform an error analysis to understand where CAP helps and where it still struggles.\n4. Analyze the abstracted problems generated by CAP to assess their quality and relevance."
        },
        "Test Case Examples": {
            "Test Case 1": {
                "Input": "Jason is a student who enjoys playing video games. He has a collection of 52 games, which includes 18 action games, 12 adventure games, 10 role-playing games, and the rest are strategy games. If Jason decides to randomly pick 2 games to play during his summer break, what is the probability that both games will be strategy games? Give your answer as a simplified fraction.",
                "Baseline Prompt (CoT)": "Jason is a student who enjoys playing video games. He has a collection of 52 games, which includes 18 action games, 12 adventure games, 10 role-playing games, and the rest are strategy games. If Jason decides to randomly pick 2 games to play during his summer break, what is the probability that both games will be strategy games? Give your answer as a simplified fraction.\n\nLet's solve this step-by-step:",
                "Baseline Output (CoT)": "To find the probability that both games Jason picks are strategy games, we need to find the total number of strategy games and the total number of games.\n\nTotal games = 52\nAction games = 18\nAdventure games = 12\nRole-playing games = 10\nStrategy games = 52 - (18 + 12 + 10) = 12\n\nProbability of picking 2 strategy games = (12/52) * (11/51) = 132/2652 = 1/21\n\nSo the probability that both games Jason picks are strategy games is 1/21.",
                "CAP Prompt (Abstraction)": "Simplify the problem by only keeping the relevant mathematical quantities and relationships:\n\nOriginal problem: Jason is a student who enjoys playing video games. He has a collection of 52 games, which includes 18 action games, 12 adventure games, 10 role-playing games, and the rest are strategy games. If Jason decides to randomly pick 2 games to play during his summer break, what is the probability that both games will be strategy games? Give your answer as a simplified fraction.\n\nSimplified problem:",
                "CAP Output (Abstraction)": "Jason has a total of 52 games. There are 18 action games, 12 adventure games, 10 role-playing games, and the rest are strategy games. What is the probability of randomly picking 2 strategy games from the total collection? Give the answer as a simplified fraction.",
                "CAP Prompt (Solving)": "Let's solve this step-by-step:\n\nJason has a total of 52 games. There are 18 action games, 12 adventure games, 10 role-playing games, and the rest are strategy games. What is the probability of randomly picking 2 strategy games from the total collection? Give the answer as a simplified fraction.",
                "CAP Output (Solving)": "Total games = 52\nAction + Adventure + Role-playing = 18 + 12 + 10 = 40\nStrategy games = 52 - 40 = 12\n\nProbability of picking the first strategy game = 12/52\nProbability of picking the second strategy game = 11/51\n\nProbability of picking 2 strategy games = (12/52) * (11/51) = 132/2652 = 1/21\n\nTherefore, the probability of randomly picking 2 strategy games is 1/21.",
                "Explanation": "The baseline CoT method gets distracted by the irrelevant contextual details about Jason being a student who enjoys video games. It still arrives at the correct answer, but the reasoning is less clear and concise. In contrast, CAP first abstracts away the irrelevant details, leading to a simplified problem statement that focuses only on the essential mathematical quantities and relationships. This allows the model to generate a more focused and coherent solution in the solving stage."
            },
            "Test Case 2": {
                "Input": "A local bakery sells cupcakes in boxes of 6. On Monday morning, they had 12 boxes of vanilla cupcakes, 9 boxes of chocolate cupcakes, and 16 boxes of strawberry cupcakes. During the day, they sold 7 boxes of vanilla cupcakes, 5 boxes of chocolate cupcakes, and 3/4 of the strawberry cupcakes. After the sales, what fraction of the remaining cupcakes are chocolate?",
                "Baseline Prompt (PoT)": "A local bakery sells cupcakes in boxes of 6. On Monday morning, they had 12 boxes of vanilla cupcakes, 9 boxes of chocolate cupcakes, and 16 boxes of strawberry cupcakes. During the day, they sold 7 boxes of vanilla cupcakes, 5 boxes of chocolate cupcakes, and 3/4 of the strawberry cupcakes. After the sales, what fraction of the remaining cupcakes are chocolate?\n\nWrite a Python program to solve this problem:",
                "Baseline Output (PoT)": "vanilla_boxes = 12\nchocolate_boxes = 9\nstrawberry_boxes = 16\n\nvanilla_sold = 7\nchocolate_sold = 5\nstrawberry_sold = strawberry_boxes * 3/4\n\nvanilla_remaining = vanilla_boxes - vanilla_sold\nchocolate_remaining = chocolate_boxes - chocolate_sold\nstrawberry_remaining = strawberry_boxes - strawberry_sold\n\ntotal_remaining = vanilla_remaining + chocolate_remaining + strawberry_remaining\nchocolate_fraction = chocolate_remaining / total_remaining\n\nprint(chocolate_fraction)",
                "CAP Prompt (Abstraction)": "Simplify the problem by only keeping the relevant mathematical quantities and relationships:\n\nOriginal problem: A local bakery sells cupcakes in boxes of 6. On Monday morning, they had 12 boxes of vanilla cupcakes, 9 boxes of chocolate cupcakes, and 16 boxes of strawberry cupcakes. During the day, they sold 7 boxes of vanilla cupcakes, 5 boxes of chocolate cupcakes, and 3/4 of the strawberry cupcakes. After the sales, what fraction of the remaining cupcakes are chocolate?\n\nSimplified problem:",
                "CAP Output (Abstraction)": "Initially, there were 12 boxes of vanilla cupcakes, 9 boxes of chocolate cupcakes, and 16 boxes of strawberry cupcakes. 7 boxes of vanilla, 5 boxes of chocolate, and 3/4 of the strawberry boxes were sold. What fraction of the remaining boxes are chocolate?",
                "CAP Prompt (Solving)": "Write a Python program to solve this problem:\n\nInitially, there were 12 boxes of vanilla cupcakes, 9 boxes of chocolate cupcakes, and 16 boxes of strawberry cupcakes. 7 boxes of vanilla, 5 boxes of chocolate, and 3/4 of the strawberry boxes were sold. What fraction of the remaining boxes are chocolate?",
                "CAP Output (Solving)": "vanilla_initial = 12\nchocolate_initial = 9\nstrawberry_initial = 16\n\nvanilla_sold = 7\nchocolate_sold = 5\nstrawberry_sold = strawberry_initial * 3/4\n\nvanilla_remaining = vanilla_initial - vanilla_sold\nchocolate_remaining = chocolate_initial - chocolate_sold\nstrawberry_remaining = strawberry_initial - strawberry_sold\n\ntotal_remaining = vanilla_remaining + chocolate_remaining + strawberry_remaining\nchocolate_fraction = chocolate_remaining / total_remaining\n\nprint(f'{chocolate_remaining}/{total_remaining}')",
                "Explanation": "The baseline PoT method includes irrelevant details like the cupcakes being sold in boxes of 6, which are not necessary for solving the problem. It also outputs the fraction as a decimal, rather than a simplified fraction as requested. CAP first simplifies the problem statement to focus only on the relevant quantities and relationships. This leads to a more concise and targeted program that directly addresses the key question and outputs the result in the desired format."
            }
        },
        "Fallback Plan": "If the proposed CAP method does not outperform the baselines, we can perform the following analyses to gain insights and inform future directions:\n1. Analyze the quality of the abstracted problems generated by CAP. Are they preserving the relevant information and discarding irrelevant details as intended? If not, we may need to improve the abstraction prompts.\n2. Examine the solving stage of CAP. Are the abstracted problems being solved correctly? If not, the issue may lie in the solving prompts or the model's reasoning capabilities.\n3. Investigate whether the performance varies across different types of problems or contexts. This can help identify specific areas where CAP struggles and guide efforts to improve it.\n4. Conduct an error analysis to understand common failure modes of CAP and how they compare to the baselines. This can provide insights into the strengths and weaknesses of the approach.\n5. Explore variations of the CAP prompts, such as using different wordings or examples, to see if they lead to better results.\nIf the CAP method shows promise but does not consistently outperform the baselines, the project can be turned into an analysis paper that provides insights into the potential and limitations of using abstraction for mathematical problem solving in LLMs."
    }
}