{
    "topic_description": "novel prompting methods that can improve factuality and reduce hallucination of large language models",
    "idea_name": "Commonsense Grounding Prompting",
    "raw_idea": {
        "Problem": "LLMs can generate fluent but factually incorrect statements by hallucinating nonexistent or invalid concepts, due to lack of grounding in commonsense knowledge during generation.",
        "Existing Methods": "Datasets like CommonGen and aNLI evaluate generative commonsense reasoning. Baselines include standard language modeling and knowledge-augmented generation.",
        "Motivation": "LLMs should be guided to ground each generated sentence in commonsense facts to avoid hallucination. We can utilize LLMs' inherent commonsense knowledge by prompting them to state relevant commonsense facts before each sentence generation step.",
        "Proposed Method": "We propose commonsense grounding prompting, where before generating each sentence, we prompt the LLM to state a relevant commonsense fact that grounds the sentence to be generated. The fact can be about everyday concepts, relations between concepts, or possible events. The LLM then generates the next sentence conditioned on both the previous context and the commonsense fact. This encourages the LLM to generate sentences that are consistent with commonsense. The commonsense facts can be parsed from the LLM outputs and used to construct supporting evidence to make the generation process more transparent.",
        "Experiment Plan": "Evaluate on generative commonsense reasoning datasets like CommonGen and aNLI. Compare with baselines like standard autoregressive generation and knowledge-augmented generation. Metrics include automatic scoring of commonsense consistency and human evaluation of factual correctness."
    },
    "full_experiment_plan": {
        "Title": "Commonsense Grounding Prompting Improves Factuality of Language Models",
        "Problem Statement": "Large Language Models (LLMs) can generate fluent but factually incorrect statements by hallucinating nonexistent or invalid concepts, due to lack of grounding in commonsense knowledge during generation.",
        "Motivation": "Existing methods like using datasets such as CommonGen and aNLI to evaluate generative commonsense reasoning, and baselines like standard language modeling and knowledge-augmented generation, do not explicitly guide the LLM to ground each generated sentence in commonsense facts to avoid hallucination. We propose utilizing LLMs' inherent commonsense knowledge by prompting them to state relevant commonsense facts before each sentence generation step, to encourage the LLM to generate sentences that are consistent with commonsense.",
        "Proposed Method": "We propose commonsense grounding prompting, where before generating each sentence, we prompt the LLM to state a relevant commonsense fact that grounds the sentence to be generated. The fact can be about everyday concepts, relations between concepts, or possible events. The LLM then generates the next sentence conditioned on both the previous context and the commonsense fact. The commonsense facts can be parsed from the LLM outputs and used to construct supporting evidence to make the generation process more transparent.",
        "Step-by-Step Experiment Plan": {
            "Step 1: Gather Datasets": "Evaluate on generative commonsense reasoning datasets like CommonGen (generate a coherent sentence describing an everyday scenario based on a set of common concepts) and aNLI (generate a hypothesis that is entailed or contradicted by the given premise). Use BLEU score, ROUGE score, and BERTScore to evaluate CommonGen, and use accuracy and consistency score to evaluate aNLI.",
            "Step 2: Construct Prompts": "For CommonGen, the baseline prompt is to simply give the concept set and ask the model to generate a coherent sentence. The proposed commonsense grounding prompt will first ask the model to state a relevant commonsense fact about the concepts, and then generate the sentence. For aNLI, the baseline prompt is to give the premise and ask the model to generate a hypothesis that is entailed/contradicted by the premise. The proposed prompt will first ask the model to state a relevant commonsense fact that connects the premise and hypothesis, and then generate the hypothesis.",
            "Step 3: Select Models": "We test GPT-3.5 (Text-Davinci-003) and GPT-4 from the OpenAI API.",
            "Step 4: Get Results": "Get the generated sentences/hypotheses from the models on the datasets with both the baseline and proposed prompts. For CommonGen, calculate BLEU, ROUGE and BERTScore between the generated sentence and the reference sentence. For aNLI, calculate the accuracy of the entailment/contradiction labels, as well as the consistency score between the generated hypothesis and the premise.",
            "Step 5: Analyze Results": "Compare the scores of the proposed commonsense grounding prompting with the baseline prompting to see if grounding each sentence in a commonsense fact improves the factuality and commonsense consistency of the generated text. Analyze the generated commonsense facts to see if they are indeed relevant and factual."
        },
        "Test Case Examples": {
            "Baseline Prompt Input (CommonGen)": "Concepts: dog, frisbee, catch, throw\nTask: Generate a coherent sentence describing a common scenario using the given concepts.",
            "Baseline Prompt Expected Output (CommonGen)": "The dog jumped up to catch the frisbee that was thrown.",
            "Proposed Prompt Input (CommonGen)": "Concepts: dog, frisbee, catch, throw\nTask: First state a relevant commonsense fact about the concepts. Then generate a coherent sentence describing a common scenario using the given concepts.",
            "Proposed Prompt Expected Output (CommonGen)": "Commonsense fact: Dogs often play fetch with their owners, where the owner throws a toy and the dog retrieves it.\nGenerated sentence: The owner threw the frisbee and the dog ran to catch it.",
            "Baseline Prompt Input (aNLI)": "Premise: Alice was considering buying a new car. She had done a lot of research and decided on the one that she wanted.\nTask: Generate a hypothesis that is entailed by the premise.",
            "Baseline Prompt Expected Output (aNLI)": "Alice bought the car that she wanted.",
            "Proposed Prompt Input (aNLI)": "Premise: Alice was considering buying a new car. She had done a lot of research and decided on the one that she wanted.\nTask: First state a relevant commonsense fact that connects the premise and a potential entailed hypothesis. Then generate a hypothesis that is entailed by the premise.",
            "Proposed Prompt Expected Output (aNLI)": "Commonsense fact: When someone has decided on a product they want after doing research, they often end up purchasing that product.\nEntailed hypothesis: Alice purchased the car she had researched and decided on.",
            "Explanation": "The proposed commonsense grounding prompting encourages the model to generate sentences that are consistent with commonsense knowledge, by first explicitly stating a relevant commonsense fact. This can potentially reduce hallucination and improve factuality compared to the baseline prompting."
        },
        "Fallback Plan": "If the proposed commonsense grounding prompts do not significantly outperform the baselines, we can analyze the generated commonsense facts to see if they are indeed relevant and factual. If the generated facts are not of high quality, we can try alternative prompts to elicit better commonsense facts from the model. We can also conduct human evaluation to assess the factuality and commonsense consistency of the generated sentences, in addition to the automatic metrics. If the grounding still does not help, we can turn the project into an analysis to gain insights into the limitations of using prompting to extract and utilize the commonsense knowledge in LLMs for guided generation."
    }
}