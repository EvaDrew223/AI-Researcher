{
    "topic_description": "novel prompting methods that can improve factuality and reduce hallucination of large language models",
    "idea_name": "Embodied Prompting",
    "raw_idea": {
        "Problem": "Large language models struggle to reason about physical and spatial properties of objects and environments. This leads to non-sensical or inconsistent generations for tasks like visual storytelling, embodied QA, or robotic instructions that require an understanding of the physical world.",
        "Existing Methods": "Most prior work focuses on using visual grounding like images or videos to improve models' physical understanding. However, this requires aligned vision-language training data. Other approaches use knowledge graphs or simulations, but these have limited coverage or are hard to interface with language.",
        "Motivation": "Studies of child development show that humans learn about the physical world through interactive, embodied experience - moving around, manipulating objects, testing out physics, etc. This embodied learning builds rich intuitive knowledge that is critical for language understanding and generation. We propose prompting models to mimic embodied learning by imagining themselves as agents exploring and interacting with a physical environment.",
        "Proposed Method": "We develop a prompt chain that walks the model through an imagined embodied experience relevant to the task. For example, for visual storytelling, we may prompt the model to imagine itself as a character moving through the scene of the image, describing what it sees and does at each step. For a physical reasoning task, we may prompt the model to imagine performing a series of actions and physical tests to determine an object's properties. Critically, the prompt encourages the model to ground its imagination in physical laws, spatial relationships, and temporal dynamics. We also include a few-shot prompt demonstrating this kind of embodied imagination and physical grounding.",
        "Experiment Plan": "We will evaluate Embodied Prompting on a range of tasks that require physical and spatial reasoning, including visual storytelling (e.g. VIST), embodied QA (e.g. EQA), physical commonsense reasoning (e.g. PIQA), and robotic instruction following (e.g. R2R). We will compare to baselines like direct prompting, Chain-of-Thought prompting, and vision-language models. Evaluation will use both automatic metrics like perplexity, BLEU, and execution success rate, and human judgment of criteria like physical plausibility, temporal coherence, and consistency with task constraints. We will also collect human ratings of how well the generated imaginations capture relevant physical and spatial details."
    },
    "full_experiment_plan": {
        "Title": "Embodied Prompting: Improving Physical Reasoning in Language Models through Imagined Interactions",
        "Problem Statement": "Large language models struggle to reason about physical and spatial properties of objects and environments, leading to inconsistent or nonsensical outputs for tasks that require an understanding of the physical world, such as visual storytelling, embodied question answering, or generating instructions for robots.",
        "Motivation": "Most prior work has focused on using visual grounding like images or videos to improve models' physical understanding. However, this requires aligned vision-language training data which can be difficult to obtain at scale. Other approaches use knowledge graphs or simulations, but these have limited coverage or are hard to interface with natural language. Studies of child development show that humans learn about the physical world through interactive, embodied experience - moving around, manipulating objects, testing out physics, etc. This embodied learning builds rich intuitive knowledge that is critical for language understanding and generation. We propose prompting models to mimic embodied learning by imagining themselves as agents exploring and interacting with a physical environment.",
        "Proposed Method": "We develop a prompt chain that walks the model through an imagined embodied experience relevant to the task. For example, for visual storytelling, we may prompt the model to imagine itself as a character moving through the scene of the image, describing what it sees and does at each step. For a physical reasoning task, we may prompt the model to imagine performing a series of actions and physical tests to determine an object's properties. Critically, the prompt encourages the model to ground its imagination in physical laws, spatial relationships, and temporal dynamics. We also include a few-shot prompt demonstrating this kind of embodied imagination and physical grounding.",
        "Step-by-Step Experiment Plan": {
            "Step 1: Gather Datasets": "We will evaluate Embodied Prompting on a range of tasks that require physical and spatial reasoning, including visual storytelling (VIST dataset), embodied question answering (EQA dataset), physical commonsense reasoning (PIQA dataset), and robotic instruction following (R2R dataset).",
            "Step 2: Construct Prompts": "For each task, we will design a set of Embodied Prompting templates that guide the model to imagine an embodied experience relevant to the task. The prompts will include instructions for the model to imagine itself as an agent in the environment, to describe its imagined sensory observations, actions, and physical interactions, and to ground its outputs in physical and spatial constraints. We will also include a few-shot example in each prompt to demonstrate the desired style of embodied imagination and physical grounding. As a baseline, we will use direct prompting where the model is simply given the task input and asked to generate an output.",
            "Step 3: Select Models": "We will evaluate Embodied Prompting on state-of-the-art large language models including GPT-3.5 (text-davinci-003), GPT-4, and PaLM. These models have shown strong performance on language tasks but still struggle with physical reasoning.",
            "Step 4: Collect Model Outputs": "For each task and dataset, we will prompt the models using both direct prompting and Embodied Prompting templates. We will generate outputs from the models on the full test sets of each dataset.",
            "Step 5: Evaluate Results": "We will evaluate the model-generated outputs using both automatic metrics and human judgments. Automatic metrics will include perplexity, BLEU, ROUGE, and CIDEr for language quality, and task-specific metrics like goal progress for EQA and navigation error for R2R. We will also have human raters assess the outputs on criteria like physical plausibility, temporal coherence, and consistency with task constraints. Additionally, we will have humans rate how well the generated imaginations in Embodied Prompting capture relevant physical and spatial details."
        },
        "Test Case Examples": {
            "Example 1": {
                "Task": "Visual Storytelling",
                "Image": "(Include URL or description of an example image from the VIST dataset)",
                "Baseline Prompt": "Write a story about the following image: (image)",
                "Baseline Output": "(Include an example baseline story that has some physical inconsistencies)",
                "Embodied Prompt": "Imagine you are a character in the following scene. Describe your embodied experience exploring the environment, moving around, and interacting with objects, making sure to ground your descriptions in physical details and spatial relationships. Use your imagined experience to tell a coherent story. Here is the scene: (image)",
                "Embodied Output": "(Include an example Embodied Prompting story that is more physically grounded and consistent)",
                "Explanation": "The Embodied Prompting output should demonstrate a more physically grounded narrative where the character's imagined interactions with the environment lead to a story that is more consistent with the spatial and physical constraints of the depicted scene."
            },
            "Example 2": {
                "Task": "Physical Commonsense Reasoning",
                "Question": "A book is placed on a table. A ruler is placed on top of the book. If someone quickly pulls the book out from under the ruler, what will happen to the ruler?",
                "Baseline Prompt": "Answer the following question: (question)",
                "Baseline Output": "The ruler will stay in place floating in the air.",
                "Embodied Prompt": "Imagine the following scenario in detail, grounding your imagination in physical laws. Visualize the objects, their materials, and their relative positions. Mentally simulate what would happen if the described action is performed, paying attention to physical dynamics. After you've imagined through the scenario, use your embodied reasoning to answer the question. Here is the scenario and question: (question)",
                "Embodied Output": "Based on my imagined mental simulation, when the book is quickly pulled out from under the ruler, the ruler will fall and clatter onto the table. This is because the ruler was initially supported by the book against gravity. When that support is suddenly removed, gravity will immediately pull the unsupported ruler straight down onto the table surface. The ruler is likely light enough that it won't have enough horizontal momentum to slide along the table - it will just drop in place. The specific sound it makes when hitting the table will depend on the ruler's material (e.g. wood, metal, plastic) but there will likely be an audible clatter or thud.",
                "Explanation": "The Embodied Prompting output should demonstrate a more accurate physical prediction, grounded in an imagined mental simulation of the scenario that takes into account objects, positions, materials, forces, and dynamics over time. The language should reflect this embodied reasoning rather than naive folk physics misconceptions."
            }
        },
        "Fallback Plan": "If the proposed Embodied Prompting method does not show significant improvements over baselines, we can analyze the failure cases to understand why. Potential issues could include: (1) The prompts are not effectively eliciting embodied imagination and physical grounding from the models. We could try iterating on the prompt design, e.g. by providing more detailed instructions, examples, or constraints. (2) The models lack the necessary physical knowledge to ground their imaginations effectively, even when prompted. We could try augmenting the prompts with relevant physical facts or rules. (3) The tasks or datasets require physical knowledge that is too specialized or complex to be captured by imagined interactions alone. We could try combining Embodied Prompting with other methods like knowledge retrieval or simulation. If Embodied Prompting still underperforms, we could pivot to an analysis of its limitations and the challenges of physical reasoning for language models. The project could aim to characterize the kinds of physical knowledge that are easy or hard to elicit from models through prompting, and how this compares to human physical reasoning. This could yield insights into the cognitive mechanisms underlying physical understanding and suggest new paths for imbuing models with such abilities."
    }
}