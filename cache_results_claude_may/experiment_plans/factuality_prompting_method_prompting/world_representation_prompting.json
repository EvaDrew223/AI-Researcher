{
    "topic_description": "novel prompting methods that can improve factuality and reduce hallucination of large language models",
    "idea_name": "World Representation Prompting",
    "raw_idea": {
        "Problem": "Large language models can generate statements that are inconsistent with how the real world works, as they do not have an explicit representation of the world state during generation.",
        "Existing Methods": "Datasets like bAbI and ProPara evaluate world state tracking in generated text. Baselines include standard language modeling and knowledge-augmented generation.",
        "Motivation": "We can prompt LLMs to generate an explicit world state representation after each sentence generation step, and use it to guide future generation to avoid inconsistencies with the world state.",
        "Proposed Method": "We propose world representation prompting, where after generating each sentence, we prompt the LLM to generate a world state representation in a structured format (e.g., a set of logical predicates or a scene graph). The world state is then used as an additional input to the LLM when generating the next sentence, by constructing a prompt like 'Given the current world state [...], what happens next?'. This encourages the LLM to generate sentences that are consistent with the current world state. To handle multi-step reasoning, we can also prompt the LLM to update the world state representation based on each generated sentence. The generated world states can be used to visualize the reasoning process.",
        "Experiment Plan": "Evaluate on world state tracking datasets like bAbI and ProPara. Compare with baselines like standard language modeling and knowledge-augmented generation. Metrics include accuracy of the generated world states and consistency of the generated text."
    },
    "full_experiment_plan": {
        "Title": "World Representation Prompting: Improving Factuality and Consistency in Language Models via Explicit World State Tracking",
        "Problem Statement": "Large language models can generate statements that are inconsistent with how the real world works, as they do not have an explicit representation of the world state during generation.",
        "Motivation": "Datasets like bAbI and ProPara evaluate world state tracking in generated text. Existing methods like standard language modeling and knowledge-augmented generation still struggle with maintaining consistency with the world state. We hypothesize that prompting LLMs to generate an explicit world state representation after each sentence generation step, and using it to guide future generation, can help avoid inconsistencies with the world state.",
        "Proposed Method": "We propose world representation prompting, where after generating each sentence, we prompt the LLM to generate a world state representation in a structured format (e.g., a set of logical predicates or a scene graph). The world state is then used as an additional input to the LLM when generating the next sentence, by constructing a prompt like 'Given the current world state [...], what happens next?'. This encourages the LLM to generate sentences that are consistent with the current world state. To handle multi-step reasoning, we can also prompt the LLM to update the world state representation based on each generated sentence. The generated world states can be used to visualize the reasoning process.",
        "Step-by-Step Experiment Plan": {
            "Step 1: Gather Datasets": "Evaluate on world state tracking datasets like bAbI and ProPara. bAbI is a set of 20 tasks for evaluating text understanding, with each task requiring a different type of reasoning (e.g., tracking the location of objects). ProPara is a dataset of procedural text (e.g., science processes) with annotated entity states (e.g., location, existence) after each sentence.",
            "Step 2: Construct Prompts": "For each dataset, construct a prompt template that includes: 1) the input text, 2) a prompt to generate the world state representation after each sentence, and 3) a prompt to generate the next sentence given the current world state. The world state prompt should be tailored to each dataset (e.g., tracking entity states for ProPara, tracking object locations for bAbI). Here are some example prompts:\n\nProPara:\nInput: A seed is planted in the ground. The seed grows into a tree. The tree produces fruit.\nPrompt: After each sentence, represent the state of each entity mentioned so far, in the format of 'Entity: State'.\nSentence 1: A seed is planted in the ground.\nWorld State 1: Seed: planted in ground\nSentence 2: The seed grows into a tree.\nWorld State 2: Seed: grew into tree, Tree: exists\nSentence 3: The tree produces fruit.\nWorld State 3: Seed: grew into tree, Tree: exists, Fruit: produced by tree\n\nbAbI:\nInput: John picked up the apple. John went to the office.\nPrompt: After each sentence, represent the location of each object and person, in the format of 'Entity: Location'.\nSentence 1: John picked up the apple.\nWorld State 1: John: has apple, Apple: with John\nSentence 2: John went to the office.\nWorld State 2: John: in office, Apple: with John\n\nThen for generation, prompt the model with 'Given the current world state of [World State], what happens next in the story?'",
            "Step 3: Select Models": "Evaluate the proposed method on GPT-3 (davinci) and GPT-4 via the OpenAI API. For comparison, also evaluate baseline methods like standard language modeling (i.e., no world state prompting) and knowledge-augmented generation (e.g., retrieving relevant knowledge from Wikipedia for each sentence).",
            "Step 4: Metrics": "For bAbI, report the accuracy of answering the reasoning questions after each story. For ProPara, report the precision, recall, and F1 of the predicted entity states after each sentence, compared to the gold annotations.",
            "Step 5: Analyze Results": "Compare the performance of world representation prompting with the baselines. Analyze the types of reasoning that the proposed method helps with the most (e.g., tracking location vs. existence of entities). Qualitatively examine the generated world states to see if they capture the key information needed for consistent generation. Visualize the world states to see if they provide interpretable reasoning traces."
        },
        "Test Case Examples": {
            "Test Case 1 - Baseline": {
                "Input": "John picked up the apple. John went to the office. Where is the apple?",
                "Expected Output": "John picked up the apple and went to the office. Therefore, the apple is with John in the office.",
                "Explanation": "The baseline language model is able to correctly answer the question by implicitly tracking the location of the apple with John. However, it does not explicitly represent the world state, so it may fail on more complex reasoning tasks."
            },
            "Test Case 2 - Proposed Method": {
                "Input": "John picked up the apple. John went to the office. Sandra picked up the milk. Sandra went to the kitchen. Where is the apple? Where is the milk?",
                "World State Prompts": "After each sentence, represent the location of each object and person, in the format of 'Entity: Location'.",
                "Expected World States": [
                    "Sentence 1: John picked up the apple.\nWorld State 1: John: has apple, Apple: with John",
                    "Sentence 2: John went to the office.\nWorld State 2: John: in office, Apple: with John",
                    "Sentence 3: Sandra picked up the milk.\nWorld State 3: John: in office, Apple: with John, Sandra: has milk, Milk: with Sandra",
                    "Sentence 4: Sandra went to the kitchen.\nWorld State 4: John: in office, Apple: with John, Sandra: in kitchen, Milk: with Sandra"
                ],
                "Expected Output": "Based on the world states, the apple is with John in the office, and the milk is with Sandra in the kitchen.",
                "Explanation": "By explicitly prompting the model to generate world states that track the location of each entity after each sentence, the model can more robustly handle questions that require tracking multiple entities across multiple locations. The generated world states provide a clear reasoning trace to arrive at the final answer."
            }
        },
        "Fallback Plan": "If the proposed world representation prompting does not outperform the baselines, there are a few alternative analyses and experiments to try:\n\n1. Analyze the quality of the generated world states. Are they accurately capturing the key information from each sentence? If not, the prompts may need to be improved to elicit more precise and complete world states from the model.\n\n2. Break down the results by the type of reasoning required (e.g., tracking location, existence, attributes of entities). This can help identify which types of reasoning the proposed method is helping with or struggling with, which can inform further prompt engineering.\n\n3. Experiment with alternative world state representations, such as graph or table structures, to see if they are more effective than the current logical predicate format.\n\n4. Conduct a few-shot experiment where the model is given a small number of annotated examples of world states for each dataset. This can help the model learn the desired format and granularity of the world states.\n\n5. Collect human annotations of world states on a subset of each dataset. Analyze how well the generated world states match the human annotations, and use them to finetune the model to generate more human-like world states."
    }
}