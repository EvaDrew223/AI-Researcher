{
    "topic_description": "novel prompting methods that can improve factuality and reduce hallucination of large language models",
    "idea_name": "Epistemic State Tracking Prompting",
    "raw_idea": {
        "Problem": "Large language models can easily lose track of what information is factual vs. hypothetical or uncertain when generating long sequences, leading to subtle inconsistencies and hallucinations. This is especially challenging for tasks like story generation, open-ended QA, and dialogues.",
        "Existing Methods": "Most existing methods focus on grounding the generation with retrieved evidence. However, even with grounding, models can still hallucinate by confusing the epistemic status of information over a long context.",
        "Motivation": "We take inspiration from the cognitive science concept of epistemic state tracking, which posits that humans maintain a mental state of the epistemic status of information (e.g., factual, uncertain, hypothetical, false) and use it to guide reasoning and communication. For example, when telling a story, humans keep track of what events definitely happened vs. might have happened. Explicitly tracking epistemic state helps maintain consistency.",
        "Proposed Method": "We propose augmenting prompts with annotations of epistemic state, and having the model generate its own epistemic state annotations during the generation process. For example, the prompt could include tags like <fact>, <uncertain>, <hypothesis>, <counterfactual> to mark the epistemic state of information, which the model must generate when producing its own response. This forces the model to more explicitly consider the epistemic state of the information it's generating and use that to maintain consistency. To guide the model to track epistemic state, we include a few-shot chain-of-thought prompt that steps through the reasoning of determining what information to mark with each epistemic state.",
        "Experiment Plan": "We will evaluate Epistemic State Tracking Prompting on story generation (e.g. WritingPrompts, WorldFlaws), open-ended QA (e.g. NarrativeQA, OpenBookQA), and dialogue (e.g. SocialIQA, DialogueCOPA) tasks. Baselines will include standard prompting, Chain-of-Thought prompting, and knowledge-augmented generation. We will measure automatic metrics like perplexity, GED, and FactCC, and also do human evaluation studies of coherence, consistency, factual accuracy, and level of hallucination."
    },
    "full_experiment_plan": {
        "Title": "Epistemic State Tracking Prompting Improves Factuality and Reduces Hallucination in Large Language Models",
        "Problem Statement": "Large language models can easily lose track of what information is factual vs. hypothetical or uncertain when generating long sequences, leading to subtle inconsistencies and hallucinations. This is especially challenging for tasks like story generation, open-ended QA, and dialogues.",
        "Motivation": "Most existing methods focus on grounding the generation with retrieved evidence. However, even with grounding, models can still hallucinate by confusing the epistemic status of information over a long context. We take inspiration from the cognitive science concept of epistemic state tracking, which posits that humans maintain a mental state of the epistemic status of information (e.g., factual, uncertain, hypothetical, false) and use it to guide reasoning and communication. For example, when telling a story, humans keep track of what events definitely happened vs. might have happened. Explicitly tracking epistemic state helps maintain consistency.",
        "Proposed Method": "We propose augmenting prompts with annotations of epistemic state, and having the model generate its own epistemic state annotations during the generation process. For example, the prompt could include tags like <fact>, <uncertain>, <hypothesis>, <counterfactual> to mark the epistemic state of information, which the model must generate when producing its own response. This forces the model to more explicitly consider the epistemic state of the information it's generating and use that to maintain consistency. To guide the model to track epistemic state, we include a few-shot chain-of-thought prompt that steps through the reasoning of determining what information to mark with each epistemic state.",
        "Step-by-Step Experiment Plan": {
            "Step 1: Gather Datasets": "Evaluate Epistemic State Tracking Prompting on story generation (e.g. WritingPrompts, WorldFlaws), open-ended QA (e.g. NarrativeQA, OpenBookQA), and dialogue (e.g. SocialIQA, DialogueCOPA) tasks.",
            "Step 2: Construct Prompts": "Baselines include standard prompting, Chain-of-Thought prompting, and knowledge-augmented generation. For Epistemic State Tracking Prompting, augment prompts with epistemic state annotations (e.g. <fact>, <uncertain>, <hypothesis>, <counterfactual>) and include a few-shot chain-of-thought prompt that demonstrates reasoning about epistemic state.",
            "Step 3: Select Models": "Evaluate GPT-3.5 (text-davinci-003), GPT-4, and open-source models like Llama and MPT.",
            "Step 4: Get Results": "Generate outputs from the models on the selected datasets using the baseline and Epistemic State Tracking prompts.",
            "Step 5: Analyze Results": "Measure automatic metrics like perplexity, GED, and FactCC. Also conduct human evaluation studies of coherence, consistency, factual accuracy, and level of hallucination. Compare performance of Epistemic State Tracking Prompting to the baselines."
        },
        "Test Case Examples": {
            "Baseline Prompt Input (Standard Prompting)": "<prompt>John woke up excited for his big hiking trip. He had been planning it for weeks. The weather forecast predicted a small chance of rain. John hoped it would stay dry, but he packed his rain gear just in case. As he drove to the mountain, he noticed some dark clouds on the horizon.</prompt> What happened next in the story?",
            "Baseline Prompt Expected Output (Standard Prompting)": "John arrived at the trailhead and started hiking under overcast skies. A light rain began to fall, but John's rain jacket kept him dry. However, the rain got heavier as he climbed higher. The trail became muddy and slippery. John lost his footing and tumbled down a steep slope, badly injuring his leg. Unable to walk, John had to activate the emergency beacon on his satellite messenger. A rescue helicopter eventually spotted him and airlifted him to a hospital. John's hiking trip was ruined and he faced a long recovery.",
            "Proposed Prompt Input (Epistemic State Tracking Prompting)": "<prompt>John woke up excited for his big hiking trip. <fact>He had been planning it for weeks.</fact> <uncertain>The weather forecast predicted a small chance of rain.</uncertain> <hypothesis>John hoped it would stay dry,</hypothesis> <fact>but he packed his rain gear just in case.</fact> <fact>As he drove to the mountain, he noticed some dark clouds on the horizon.</fact></prompt> What happened next in the story? Annotate each sentence you generate with its epistemic state (<fact>, <uncertain>, <hypothesis>, <counterfactual>).",
            "Proposed Prompt Expected Output (Epistemic State Tracking Prompting)": "<fact>John arrived at the trailhead and started hiking under overcast skies.</fact> <fact>A light rain began to fall, but John's rain jacket kept him dry.</fact> <uncertain>However, the rain got heavier as he climbed higher.</uncertain> <fact>The trail became muddy and slippery.</fact> <hypothesis>John worried he might lose his footing.</hypothesis> <counterfactual>If he hadn't packed his rain gear, he would have been soaked.</counterfactual> <fact>John slowed his pace and stepped carefully.</fact> <fact>The rain eased off after an hour, and the sun peeked out from behind the clouds.</fact> <fact>John reached the summit safely and enjoyed the view.</fact> <hypothesis>He was glad he had persevered through the bad weather.</hypothesis>",
            "Explanation": "The standard prompting baseline generates a story that starts out reasonable but then hallucinates an injury and rescue that are inconsistent with the initial prompt. The Epistemic State Tracking prompt forces the model to explicitly annotate and track the epistemic state of the information, resulting in a story that is coherent and consistent with the initial facts, while clearly distinguishing hypotheticals and counterfactuals."
        },
        "Fallback Plan": "If Epistemic State Tracking Prompting does not improve factuality and reduce hallucination compared to the baselines, analyze the generated epistemic state annotations to see if they are accurate and relevant. It may be that the model struggles to correctly identify the epistemic state of information. In that case, the project could pivot to developing better few-shot prompts or fine-tuning techniques to teach the model epistemic state tracking. Alternatively, the project could analyze whether the model is able to use the epistemic state annotations correctly during generation to maintain consistency, even if it can recognize them. This could lead to insights about the model's reasoning abilities and point to architectural changes. If Epistemic State Tracking Prompting works well for some tasks but not others, comparisons between the tasks could yield insights about what kinds of consistency and factuality challenges are most important for different applications."
    }
}