{
    "topic_description": "novel prompting methods that can improve factuality and reduce hallucination of large language models",
    "idea_name": "Temporal Coherence Prompting",
    "raw_idea": {
        "Problem": "LLMs often generate responses that lack temporal coherence, leading to inconsistencies and hallucinations when dealing with events or stories that unfold over time.",
        "Existing Methods": "Current approaches to improve temporal coherence in LLMs include fine-tuning on temporally annotated datasets or using prompts that encourage maintaining a consistent timeline. However, these methods often fail to capture the nuances of temporal relationships between events.",
        "Motivation": "Temporal coherence is essential for understanding and generating coherent narratives, as well as reasoning about cause-and-effect relationships. By explicitly prompting LLMs to consider the temporal aspects of a given scenario, we can improve their ability to generate more factual and consistent responses.",
        "Proposed Method": "We propose Temporal Coherence Prompting (TCP), a multi-step prompting approach that guides LLMs to maintain temporal consistency in their responses. The steps include: 1) Identifying key events in the given scenario; 2) Constructing a temporal graph that captures the relationships between these events; 3) Generating a response that adheres to the temporal constraints imposed by the graph; 4) Verifying the temporal coherence of the generated response by comparing it with the temporal graph; 5) Iteratively refining the response to resolve any temporal inconsistencies.",
        "Experiment Plan": "Evaluate TCP on datasets that require temporal reasoning, such as TimeTravel and MCTaco. Compare performance with baselines such as zero-shot prompting and fine-tuning on temporally annotated datasets. Assess the temporal coherence of generated responses using metrics like TimeML and human evaluation."
    },
    "full_experiment_plan": {
        "Title": "Temporal Coherence Prompting: Improving Factual Consistency in Event-Centric Text Generation",
        "Problem Statement": "Large Language Models (LLMs) often generate responses that lack temporal coherence, leading to inconsistencies and hallucinations when dealing with events or stories that unfold over time.",
        "Motivation": "Current approaches to improve temporal coherence in LLMs, such as fine-tuning on temporally annotated datasets or using prompts that encourage maintaining a consistent timeline, often fail to capture the nuances of temporal relationships between events. Temporal coherence is essential for understanding and generating coherent narratives, as well as reasoning about cause-and-effect relationships. By explicitly prompting LLMs to consider the temporal aspects of a given scenario, we can improve their ability to generate more factual and consistent responses.",
        "Proposed Method": "We propose Temporal Coherence Prompting (TCP), a multi-step prompting approach that guides LLMs to maintain temporal consistency in their responses. The steps include:\n1. Identifying key events in the given scenario\n2. Constructing a temporal graph that captures the relationships between these events\n3. Generating a response that adheres to the temporal constraints imposed by the graph\n4. Verifying the temporal coherence of the generated response by comparing it with the temporal graph\n5. Iteratively refining the response to resolve any temporal inconsistencies",
        "Step-by-Step Experiment Plan": {
            "Step 1: Gather Datasets": "Evaluate TCP on datasets that require temporal reasoning, such as TimeTravel, MCTaco, TORQUE, and NarrativeQA. These datasets cover a range of tasks, including question answering, story generation, and event ordering.",
            "Step 2: Construct Prompts": "Design a set of prompts for each step of the TCP approach:\n1. Event Identification Prompt: Guide the model to identify and extract key events from the given scenario (e.g., \"List the main events in the following text:\").\n2. Temporal Graph Construction Prompt: Instruct the model to construct a temporal graph representing the relationships between the identified events (e.g., \"Create a graph showing the temporal order and connections between the events:\").\n3. Response Generation Prompt: Prompt the model to generate a response that adheres to the temporal constraints of the graph (e.g., \"Generate a response to the following question, ensuring that the events follow the temporal order in the graph:\").\n4. Temporal Coherence Verification Prompt: Ask the model to compare the generated response with the temporal graph and identify any inconsistencies (e.g., \"Check if the generated response follows the temporal order in the graph and list any inconsistencies:\").\n5. Response Refinement Prompt: Guide the model to refine the response based on the identified inconsistencies (e.g., \"Revise the response to resolve the temporal inconsistencies identified in the previous step:\").",
            "Step 3: Select Models": "Evaluate TCP using state-of-the-art LLMs, such as GPT-3.5 (text-davinci-003), GPT-4, and open-source models like Flan-T5 and LLaMA. Compare the performance of these models with and without TCP.",
            "Step 4: Establish Baselines": "Compare the performance of TCP with the following baselines:\n1. Zero-shot prompting: Directly prompt the model with the task without any additional guidance.\n2. Fine-tuning on temporally annotated datasets: Fine-tune the models on datasets with temporal annotations and evaluate their performance on the target datasets.\n3. Temporal prompting: Use prompts that encourage the model to maintain a consistent timeline (e.g., \"Ensure that the events in your response follow a chronological order.\").",
            "Step 5: Evaluate Results": "Assess the performance of TCP and the baselines using the following metrics:\n1. Temporal coherence: Measure the percentage of generated responses that maintain a consistent temporal order of events.\n2. Factual consistency: Evaluate the factual accuracy of the generated responses using dataset-specific metrics (e.g., F1 score, BLEU, ROUGE).\n3. Human evaluation: Conduct a human evaluation to assess the coherence, fluency, and overall quality of the generated responses.",
            "Step 6: Analyze and Iterate": "Analyze the results to identify strengths and weaknesses of the TCP approach. Iterate on the prompts and the overall method based on the findings to further improve performance."
        },
        "Test Case Examples": {
            "Test Case 1": {
                "Input": "John woke up at 7 AM. He had breakfast and then went for a run. After returning home, he took a shower and got dressed for work. He drove to the office and arrived at 9 AM. Question: What did John do before going for a run?",
                "Baseline Output": "Based on the given information, John went for a run before having breakfast.",
                "TCP Output": "Event Identification:\n1. John woke up at 7 AM\n2. He had breakfast\n3. He went for a run\n4. He returned home\n5. He took a shower\n6. He got dressed for work\n7. He drove to the office\n8. He arrived at the office at 9 AM\n\nTemporal Graph:\n1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8\n\nResponse: According to the temporal order of events, John had breakfast before going for a run.",
                "Explanation": "The baseline output fails to capture the correct temporal order of events, leading to an inconsistent response. TCP, on the other hand, identifies the key events, constructs a temporal graph, and generates a response that adheres to the temporal constraints, resulting in a more accurate and coherent answer."
            },
            "Test Case 2": {
                "Input": "Sarah and Tom were classmates in high school. They started dating during their senior year. After graduation, Sarah moved to New York for college, while Tom stayed in their hometown to work. They tried a long-distance relationship but eventually broke up. Five years later, they met at a reunion and rekindled their relationship. They got married a year later and had two children. Question: Did Sarah and Tom date before or after they graduated from high school?",
                "Baseline Output": "Based on the information provided, it is unclear whether Sarah and Tom dated before or after they graduated from high school.",
                "TCP Output": "Event Identification:\n1. Sarah and Tom were classmates in high school\n2. They started dating during their senior year\n3. They graduated from high school\n4. Sarah moved to New York for college\n5. Tom stayed in their hometown to work\n6. They tried a long-distance relationship\n7. They broke up\n8. Five years later, they met at a reunion\n9. They rekindled their relationship\n10. They got married a year later\n11. They had two children\n\nTemporal Graph:\n1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11\n\nResponse: According to the temporal order of events, Sarah and Tom started dating during their senior year in high school, which was before they graduated.",
                "Explanation": "The baseline output fails to provide a definitive answer to the question, as it does not effectively reason about the temporal relationship between the events. TCP, however, identifies the relevant events, constructs a temporal graph, and generates a response that directly addresses the question by correctly inferring the temporal order of the events."
            }
        },
        "Fallback Plan": "If the proposed TCP approach does not yield significant improvements over the baselines, consider the following alternative plans:\n1. Analyze the generated temporal graphs and responses to identify potential weaknesses in the prompts or the overall method. Refine the prompts and iterate on the approach based on these findings.\n2. Investigate the impact of different temporal representation techniques, such as temporal logic or interval algebra, on the performance of the TCP approach.\n3. Explore the integration of external knowledge sources, such as temporal knowledge graphs or temporal common sense databases, to enhance the model's temporal reasoning capabilities.\n4. Conduct a thorough error analysis to understand the types of temporal inconsistencies that the model struggles with and develop targeted strategies to address these challenges.\n5. Consider combining TCP with other techniques, such as reinforcement learning or adversarial training, to further improve the model's temporal coherence and factual consistency.\n\nIf the TCP approach fails to yield meaningful results after these iterations, focus on analyzing the factors that contribute to the model's temporal inconsistencies and present these findings as valuable insights for future research in this area."
    },
    "novelty_queries": [
        "KeywordQuery(\"temporal coherence prompting language models\")",
        "KeywordQuery(\"temporal reasoning language models\")",
        "KeywordQuery(\"event-centric text generation language models\")",
        "KeywordQuery(\"factual consistency language models\")",
        "KeywordQuery(\"Temporal Coherence Prompting NLP\")"
    ],
    "novelty_papers": [
        {
            "id": "066dc4d3550dce456856344acb1434a5ef46ac5d",
            "paperId": "066dc4d3550dce456856344acb1434a5ef46ac5d",
            "title": "Towards Robust Temporal Reasoning of Large Language Models via a Multi-Hop QA Dataset and Pseudo-Instruction Tuning",
            "abstract": "Knowledge in the real world is being updated constantly. However, it is costly to frequently update large language models (LLMs). Therefore, it is crucial for LLMs to understand the concept of temporal knowledge. However, prior works on temporal question answering did not emphasize multi-answer and multi-hop types of temporal reasoning. In this paper, we propose a complex temporal question-answering (QA) dataset Complex-TR that focuses on multi-answer and multi-hop temporal reasoning. Besides, we also propose a novel data augmentation strategy to improve the complex temporal reasoning capability and robustness of LLMs. We conducted experiments on multiple temporal QA datasets. Experimental results show that our method is able to improve LLMs' performance on temporal QA benchmarks by significant margins.",
            "year": 2023,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A complex temporal question-answering (QA) dataset Complex-TR that focuses on multi-answer and multi-hop temporal reasoning and a novel data augmentation strategy to improve the complex temporal reasoning capability and robustness of LLMs is proposed."
            },
            "score": 7,
            "novelty_score": "The research problem in the proposal is improving the temporal coherence and factual consistency of large language models in event-centric text generation. The proposed approach is Temporal Coherence Prompting (TCP), a multi-step prompting method that guides LLMs to maintain temporal consistency in their responses.\n\nThe research problem in the paper is improving the complex temporal reasoning capability and robustness of large language models. The proposed approach is a novel data augmentation strategy and a complex temporal question-answering dataset (Complex-TR) that focuses on multi-answer and multi-hop temporal reasoning.\n\nWhile both the proposal and the paper aim to improve the temporal reasoning capabilities of large language models, their specific focus and proposed methods differ. The proposal focuses on improving temporal coherence and factual consistency in event-centric text generation using a multi-step prompting approach, while the paper focuses on improving complex temporal reasoning in question-answering tasks using a new dataset and data augmentation strategy.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "078f4efd448822b0e25d3ee0aec842ced606a595",
            "paperId": "078f4efd448822b0e25d3ee0aec842ced606a595",
            "title": "Go Back in Time: Generating Flashbacks in Stories with Event Temporal Prompts",
            "abstract": "Stories or narratives are comprised of a sequence of events. To compose interesting stories, professional writers often leverage a creative writing technique called *flashback* that inserts past events into current storylines as we commonly observe in novels and plays. However, it is challenging for machines to generate *flashback* as it requires a solid understanding of event **temporal order** (e.g. *feeling hungry* before *eat*, not vice versa), and the creativity to arrange storylines so that earlier events do not always appear first in **narrative order**. Two major issues in existing systems that exacerbate the challenges: 1) temporal bias in pertaining and story datasets that leads to monotonic event temporal orders; 2) lack of explicit guidance that helps machines decide where to insert *flashbacks*. We propose to address these issues using structured storylines to encode events and their pair-wise temporal relations (before, after and vague) as **temporal prompts** that guide how stories should unfold temporally. We leverage a Plan-and-Write framework enhanced by reinforcement learning to generate storylines and stories end-to-end. Evaluation results show that the proposed method can generate more interesting stories with *flashbacks* while maintaining textual diversity, fluency, and temporal coherence.",
            "year": 2022,
            "citationCount": 14,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A Plan-and-Write framework enhanced by reinforcement learning to generate storylines and stories end-to-end using structured storylines to encode events and their pair-wise temporal relations as **temporal prompts** that guide how stories should unfold temporally."
            },
            "score": 7,
            "novelty_score": "The research problem in the project proposal is improving the temporal coherence and factual consistency of event-centric text generation in large language models. The proposed approach is Temporal Coherence Prompting (TCP), a multi-step prompting method that guides LLMs to maintain temporal consistency in their responses.\n\nThe research problem in the paper is generating flashbacks in stories while maintaining temporal coherence. The proposed approach is using structured storylines with event temporal relations as prompts to guide the temporal unfolding of the story.\n\nWhile both the project proposal and the paper aim to improve temporal coherence in text generation, the project proposal focuses on factual consistency in event-centric text generation, while the paper specifically addresses generating flashbacks in stories. The approaches also differ, with the project proposal using a multi-step prompting method and the paper using structured storylines with temporal relations as prompts.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "944b983ee059503c53afef772052d065d662527c",
            "paperId": "944b983ee059503c53afef772052d065d662527c",
            "title": "Set the Clock: Temporal Alignment of Pretrained Language Models",
            "abstract": "Language models (LMs) are trained on web text originating from many points in time and, in general, without any explicit temporal grounding. This work investigates the temporal chaos of pretrained LMs and explores various methods to align their internal knowledge to a target time, which we call\"temporal alignment.\"To do this, we first automatically construct a dataset containing 20K time-sensitive questions and their answers for each year from 2000 to 2023. Based on this dataset, we empirically show that pretrained LMs (e.g., LLaMa2), despite having a recent pretraining cutoff (e.g., 2022), mostly answer questions using earlier knowledge (e.g., in 2019). We then develop several methods, from prompting to finetuning, to align LMs to use their most recent knowledge when answering questions, and investigate various factors in this alignment. Our experiments show that aligning LLaMa2 to the year 2022 can boost its performance by up to 62% relatively as measured by that year, even without mentioning time information explicitly, indicating the possibility of aligning models' internal sense of time after pretraining. Finally, we find that alignment to a historical time is also possible, with up to 2.8$\\times$ the performance of the unaligned LM in 2010 if finetuning models to that year. These findings hint at the sophistication of LMs' internal knowledge organization and the necessity of tuning them properly.",
            "year": 2024,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work develops several methods, from prompting to finetuning, to align LMs to use their most recent knowledge when answering questions, and investigates various factors in this alignment."
            },
            "score": 6,
            "novelty_score": "The research problem in the proposal is improving the temporal coherence and factual consistency of large language models in event-centric text generation. The proposed approach is Temporal Coherence Prompting (TCP), a multi-step prompting method that guides LLMs to maintain temporal consistency in their responses.\n\nThe research problem in the paper is aligning the internal knowledge of pretrained language models to a target time. The approach involves constructing a dataset of time-sensitive questions and answers, and developing methods such as prompting and finetuning to align LMs to use their most recent knowledge when answering questions.\n\nWhile both the proposal and the paper deal with temporal aspects of language models, the specific research problems and approaches are different. The proposal focuses on improving temporal coherence in event-centric text generation, while the paper aims to align the internal knowledge of LMs to a specific time period.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "11daaaedd317ae23c7de7df506572d9155017ae3",
            "paperId": "11daaaedd317ae23c7de7df506572d9155017ae3",
            "title": "Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models",
            "abstract": "Reasoning about time is of fundamental importance. Many facts are time-dependent. For example, athletes change teams from time to time, and different government officials are elected periodically. Previous time-dependent question answering (QA) datasets tend to be biased in either their coverage of time spans or question types. In this paper, we introduce a comprehensive probing dataset TempReason to evaluate the temporal reasoning capability of large language models. Our dataset includes questions of three temporal reasoning levels. In addition, we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning. We conducted experiments in closed book QA, open book QA, and reasoning QA settings and demonstrated the effectiveness of our approach.",
            "year": 2023,
            "citationCount": 10,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper introduces a comprehensive probing dataset TempReason and proposes a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning."
            },
            "score": 6,
            "novelty_score": "The research problem in the proposal is improving the temporal coherence and factual consistency of large language models in event-centric text generation. The proposed approach is Temporal Coherence Prompting (TCP), a multi-step prompting method that guides LLMs to maintain temporal consistency in their responses.\n\nThe research problem in the paper is evaluating and improving the temporal reasoning capability of large language models. The proposed approach is a comprehensive probing dataset called TempReason and a novel learning framework based on temporal span extraction and time-sensitive reinforcement learning.\n\nWhile both the proposal and the paper focus on temporal reasoning in large language models, the specific research problems and approaches differ. The proposal aims to improve text generation, while the paper focuses on question answering and reasoning. The proposal uses a prompting-based approach, while the paper introduces a new dataset and a learning framework.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "5ff337e94bb710bab34c340e06b0618612126961",
            "paperId": "5ff337e94bb710bab34c340e06b0618612126961",
            "title": "Large Language Models Can Learn Temporal Reasoning",
            "abstract": "While large language models (LLMs) have demonstrated remarkable reasoning capabilities, they are not without their flaws and inaccuracies. Recent studies have introduced various methods to mitigate these limitations. Temporal reasoning (TR), in particular, presents a significant challenge for LLMs due to its reliance on diverse temporal expressions and intricate temporal logic. In this paper, we propose TG-LLM, a novel framework towards language-based TR. Instead of reasoning over the original context, we adopt a latent representation, temporal graph (TG) that facilitates the TR learning. A synthetic dataset (TGQA), which is fully controllable and requires minimal supervision, is constructed for fine-tuning LLMs on this text-to-TG translation task. We confirmed in experiments that the capability of TG translation learned on our dataset can be transferred to other TR tasks and benchmarks. On top of that, we teach LLM to perform deliberate reasoning over the TGs via Chain of Thought (CoT) bootstrapping and graph data augmentation. We observed that those strategies, which maintain a balance between usefulness and diversity, bring more reliable CoTs and final results than the vanilla CoT distillation.",
            "year": 2024,
            "citationCount": 3,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper proposes TG-LLM, a novel framework towards language-based TR that teaches LLM to perform deliberate reasoning over the TGs via Chain of Thought bootstrapping and graph data augmentation, and observed that those strategies, which maintain a balance between usefulness and diversity, bring more reliable CoTs and final results than the vanilla CoT distillation."
            },
            "score": 6,
            "novelty_score": "The project proposal aims to improve the temporal coherence and factual consistency of large language models (LLMs) in event-centric text generation by using a multi-step prompting approach called Temporal Coherence Prompting (TCP). The paper, on the other hand, proposes TG-LLM, a framework that uses a latent representation called temporal graph (TG) to facilitate temporal reasoning learning in LLMs, and employs Chain of Thought (CoT) bootstrapping and graph data augmentation to perform deliberate reasoning over the TGs.\n\nWhile both the project proposal and the paper address the challenge of temporal reasoning in LLMs, their approaches differ significantly. The project proposal focuses on a prompting-based method to guide LLMs in maintaining temporal consistency, whereas the paper introduces a latent representation and uses CoT bootstrapping and data augmentation to improve temporal reasoning.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "a77f498235f12be4173f87bfca503b597c00f30e",
            "paperId": "a77f498235f12be4173f87bfca503b597c00f30e",
            "title": "Factuality Enhanced Language Models for Open-Ended Text Generation",
            "abstract": "Pretrained language models (LMs) are susceptible to generate text with nonfactual information. In this work, we measure and improve the factual accuracy of large-scale LMs for open-ended text generation. We design the FactualityPrompts test set and metrics to measure the factuality of LM generations. Based on that, we study the factual accuracy of LMs with parameter sizes ranging from 126M to 530B. Interestingly, we find that larger LMs are more factual than smaller ones, although a previous study suggests that larger LMs can be less truthful in terms of misconceptions. In addition, popular sampling algorithms (e.g., top-p) in open-ended text generation can harm the factuality due to the ''uniform randomness'' introduced at every sampling step. We propose the factual-nucleus sampling algorithm that dynamically adapts the randomness to improve the factuality of generation while maintaining quality. Furthermore, we analyze the inefficiencies of the standard training method in learning correct associations between entities from factual text corpus (e.g., Wikipedia). We propose a factuality-enhanced training method that uses TopicPrefix for better awareness of facts and sentence completion as the training objective, which can vastly reduce the factual errors. We release our code and FactualityPrompts benchmark at: https://github.com/nayeon7lee/FactualityPrompt.",
            "year": 2022,
            "citationCount": 100,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work measures and improves the factual accuracy of large-scale LMs for open-ended text generation, and proposes a factuality-enhanced training method that uses TopicPrefix for better awareness of facts and sentence completion as the training objective, which can vastly reduce the factual errors."
            },
            "score": 6,
            "novelty_score": "The research problem in the proposal is improving the temporal coherence and factual consistency of large language models in event-centric text generation. The proposed approach is Temporal Coherence Prompting (TCP), a multi-step prompting method that guides LLMs to maintain temporal consistency in their responses.\n\nThe research problem in the paper is improving the factual accuracy of large-scale language models for open-ended text generation. The proposed approaches are the factual-nucleus sampling algorithm and a factuality-enhanced training method using TopicPrefix.\n\nWhile both the proposal and the paper aim to improve the factual accuracy of language models, the proposal focuses specifically on temporal coherence in event-centric text generation, while the paper addresses general factual accuracy in open-ended text generation. The proposed methods are also different, with the proposal using a multi-step prompting approach and the paper using a sampling algorithm and a training method.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "3e339698ea21a9010401c197a63d604d0b58f959",
            "paperId": "3e339698ea21a9010401c197a63d604d0b58f959",
            "title": "Dual Semantic Enhanced Event Causality Identification with Derivative Temporal Prompt",
            "abstract": "Event causality identification (ECI) is a crucial task in natural language processing (NLP) that aims to identify the causal relation between a pair of events in a sentence. However, the existing methods still face two main challenges: a deficiency in causal reasoning capabilities, particularly in detecting implicit causality, and a scarcity of adequately annotated data for training causal relation patterns. In this paper, we propose an innovative approach to address these challenges. On the one hand, we introduce a derivative temporal relation identification task to enhance the model's capability to capture temporal information, which can be utilized to improve the identification of implicit causality. On the other hand, our method incorporates dual semantic information to enhance the representation of events. Firstly, we leverage semantic knowledge relevant to event pairs from external knowledge bases. Secondly, we utilize a dependency-based semantic enhancement module to extract comprehensive semantic information from events within the sentence. We evaluate our method on two benchmark datasets, and the results demonstrate its superior performance compared to previous state-of-the-art methods.",
            "year": 2023,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper introduces a derivative temporal relation identification task to enhance the model's capability to capture temporal information, which can be utilized to improve the identification of implicit causality and incorporates dual semantic information to enhanced the representation of events."
            },
            "score": 6,
            "novelty_score": "The project proposal aims to improve the temporal coherence and factual consistency of event-centric text generation in large language models using a multi-step prompting approach called Temporal Coherence Prompting (TCP).\n\nThe paper focuses on enhancing event causality identification by introducing a derivative temporal relation identification task and incorporating dual semantic information from external knowledge bases and a dependency-based semantic enhancement module.\n\nWhile both the project proposal and the paper deal with temporal aspects of events, their research problems and approaches differ. The project proposal targets text generation, while the paper focuses on event causality identification. The project proposal uses prompting techniques, whereas the paper employs semantic enhancements and a derivative task.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "490d8006851b1562cfd9ec1f057471f2868289d1",
            "paperId": "490d8006851b1562cfd9ec1f057471f2868289d1",
            "title": "Rethinking with Retrieval: Faithful Large Language Model Inference",
            "abstract": "Despite the success of large language models (LLMs) in various natural language processing (NLP) tasks, the stored knowledge in these models may inevitably be incomplete, out-of-date, or incorrect. This motivates the need to utilize external knowledge to assist LLMs. Unfortunately, current methods for incorporating external knowledge often require additional training or fine-tuning, which can be costly and may not be feasible for LLMs. To address this issue, we propose a novel post-processing approach, rethinking with retrieval (RR), which retrieves relevant external knowledge based on the decomposed reasoning steps obtained from the chain-of-thought (CoT) prompting. This lightweight approach does not require additional training or fine-tuning and is not limited by the input length of LLMs. We evaluate the effectiveness of RR through extensive experiments with GPT-3 on three complex reasoning tasks: commonsense reasoning, temporal reasoning, and tabular reasoning. Our results show that RR can produce more faithful explanations and improve the performance of LLMs.",
            "year": 2022,
            "citationCount": 101,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work proposes a novel post-processing approach, rethinking with retrieval (RR), which retrieves relevant external knowledge based on the decomposed reasoning steps obtained from the chain-of-thought (CoT) prompting, which can produce more faithful explanations and improve the performance of LLMs."
            },
            "score": 6,
            "novelty_score": "The research problem in the proposal is improving the temporal coherence and factual consistency of large language models in event-centric text generation. The proposed approach is Temporal Coherence Prompting (TCP), a multi-step prompting method that guides LLMs to maintain temporal consistency in their responses.\n\nThe research problem in the paper is utilizing external knowledge to assist LLMs in complex reasoning tasks, as the stored knowledge in these models may be incomplete, out-of-date, or incorrect. The proposed approach is rethinking with retrieval (RR), a post-processing method that retrieves relevant external knowledge based on the decomposed reasoning steps obtained from the chain-of-thought (CoT) prompting.\n\nWhile both the proposal and the paper aim to improve the performance of LLMs, they focus on different aspects. The proposal addresses temporal coherence and factual consistency in event-centric text generation, while the paper focuses on incorporating external knowledge for complex reasoning tasks.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "f37d1ef3c4fd85f608439d239306a3b3302e3add",
            "paperId": "f37d1ef3c4fd85f608439d239306a3b3302e3add",
            "title": "TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models",
            "abstract": "Understanding time is a pivotal aspect of human cognition, crucial in the broader framework of grasping the intricacies of the world. Previous studies typically focus on specific aspects of time, lacking a comprehensive temporal reasoning benchmark. To address this issue, we propose TimeBench, a comprehensive hierarchical temporal reasoning benchmark that covers a broad spectrum of temporal reasoning phenomena, which provides a thorough evaluation for investigating the temporal reasoning capabilities of large language models. We conduct extensive experiments on popular LLMs, such as GPT-4, LLaMA2, and Mistral, incorporating chain-of-thought prompting. Our experimental results indicate a significant performance gap between the state-of-the-art LLMs and humans, highlighting that there is still a considerable distance to cover in temporal reasoning. We aspire for TimeBench to serve as a comprehensive benchmark, fostering research in temporal reasoning for LLMs. Our resource is available at https://github.com/zchuz/TimeBench",
            "year": 2023,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work proposes TimeBench, a comprehensive hierarchical temporal reasoning benchmark that covers a broad spectrum of temporal reasoning phenomena, which provides a thorough evaluation for investigating the temporal reasoning capabilities of large language models."
            },
            "score": 5,
            "novelty_score": "The research problem in the proposal is improving the temporal coherence and factual consistency of large language models in event-centric text generation. The proposed approach is Temporal Coherence Prompting (TCP), a multi-step prompting method that guides LLMs to maintain temporal consistency in their responses.\n\nThe research problem in the paper is evaluating the temporal reasoning abilities of large language models. The approach is proposing TimeBench, a comprehensive hierarchical temporal reasoning benchmark that covers a broad spectrum of temporal reasoning phenomena.\n\nThe proposal focuses on improving LLMs' temporal coherence in text generation, while the paper aims to evaluate LLMs' temporal reasoning abilities using a benchmark. Although both deal with temporal aspects, the research problems and approaches are different.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "740c783ac07039cf30b6d8a8f95e775b3297c79e",
            "paperId": "740c783ac07039cf30b6d8a8f95e775b3297c79e",
            "title": "Language Models Represent Space and Time",
            "abstract": "The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a set of more coherent and grounded representations that reflect the real world. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual\"space neurons\"and\"time neurons\"that reliably encode spatial and temporal coordinates. While further investigation is needed, our results suggest modern LLMs learn rich spatiotemporal representations of the real world and possess basic ingredients of a world model.",
            "year": 2023,
            "citationCount": 33,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Today's LLMs learn rich spatiotemporal representations of the real world and possess basic ingredients of a world model, according to a analysis of three spatial and temporal datasets in the Llama-2 family of models."
            },
            "score": 5,
            "novelty_score": "The research problem in the proposal is improving the temporal coherence and factual consistency of large language models in event-centric text generation. The proposed approach is Temporal Coherence Prompting (TCP), a multi-step prompting method that guides LLMs to maintain temporal consistency in their responses.\n\nThe research problem in the paper is analyzing whether large language models learn coherent and grounded representations of space and time. The approach is probing the learned representations of spatial and temporal datasets in the Llama-2 family of models.\n\nThe proposal focuses on improving LLMs' temporal reasoning capabilities in text generation, while the paper investigates the spatiotemporal representations learned by LLMs. Although both deal with temporal aspects, the research problems and approaches are different.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "5b9bf4a82da690e738821ac0460b96c2770ed5dd",
            "paperId": "5b9bf4a82da690e738821ac0460b96c2770ed5dd",
            "title": "Are Large Language Models Temporally Grounded?",
            "abstract": "Are Large language models (LLMs) temporally grounded? Since LLMs cannot perceive and interact with the environment, it is impossible to answer this question directly. Instead, we provide LLMs with textual narratives and probe them with respect to their common-sense knowledge of the structure and duration of events, their ability to order events along a timeline, and self-consistency within their temporal model (e.g., temporal relations such as after and before are mutually exclusive for any pair of events). We evaluate state-of-the-art LLMs (such as LLaMA 2 and GPT-4) on three tasks reflecting these abilities. Generally, we find that LLMs lag significantly behind both human performance as well as small-scale, specialised LMs. In-context learning, instruction tuning, and chain-of-thought prompting reduce this gap only to a limited degree. Crucially, LLMs struggle the most with self-consistency, displaying incoherent behaviour in at least 27.23% of their predictions. Contrary to expectations, we also find that scaling the model size does not guarantee positive gains in performance. To explain these results, we study the sources from which LLMs may gather temporal information: we find that sentence ordering in unlabelled texts, available during pre-training, is only weakly correlated with event ordering. Moreover, public instruction tuning mixtures contain few temporal tasks. Hence, we conclude that current LLMs lack a consistent temporal model of textual narratives. Code, datasets, and LLM outputs are available at https://github.com/yfqiu-nlp/temporal-llms.",
            "year": 2023,
            "citationCount": 5,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "It is concluded that current LLMs lack a consistent temporal model of textual narratives, and study the sources from which LLMs may gather temporal information finds that sentence ordering in unlabelled texts is only weakly correlated with event ordering."
            },
            "score": 5
        },
        {
            "id": "ff2eecb21972eb287064f98db1a4487c62bd7566",
            "paperId": "ff2eecb21972eb287064f98db1a4487c62bd7566",
            "title": "MenatQA: A New Dataset for Testing the Temporal Comprehension and Reasoning Abilities of Large Language Models",
            "abstract": "Large language models (LLMs) have shown nearly saturated performance on many natural language processing (NLP) tasks. As a result, it is natural for people to believe that LLMs have also mastered abilities such as time understanding and reasoning. However, research on the temporal sensitivity of LLMs has been insufficiently emphasized. To fill this gap, this paper constructs Multiple Sensitive Factors Time QA (MenatQA), which encompasses three temporal factors (scope factor, order factor, counterfactual factor) with total 2,853 samples for evaluating the time comprehension and reasoning abilities of LLMs. This paper tests current mainstream LLMs with different parameter sizes, ranging from billions to hundreds of billions. The results show most LLMs fall behind smaller temporal reasoning models with different degree on these factors. In specific, LLMs show a significant vulnerability to temporal biases and depend heavily on the temporal information provided in questions. Furthermore, this paper undertakes a preliminary investigation into potential improvement strategies by devising specific prompts and leveraging external tools. These approaches serve as valuable baselines or references for future research endeavors.",
            "year": 2023,
            "citationCount": 2,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "MenatQA constructs Multiple Sensitive Factors Time QA, which encompasses three temporal factors (scope factor, order factor, counterfactual factor) with total 2,853 samples for evaluating the time comprehension and reasoning abilities of LLMs."
            },
            "score": 5
        },
        {
            "id": "811f451f1991ec5508e67d00375ca4f5d05e0eeb",
            "paperId": "811f451f1991ec5508e67d00375ca4f5d05e0eeb",
            "title": "TRAM: Benchmarking Temporal Reasoning for Large Language Models",
            "abstract": "Reasoning about time is essential for understanding the nuances of events described in natural language. Previous research on this topic has been limited in scope, characterized by a lack of standardized benchmarks that would allow for consistent evaluations across different studies. In this paper, we introduce TRAM, a temporal reasoning benchmark composed of ten datasets, encompassing various temporal aspects of events such as order, arithmetic, frequency, and duration, designed to facilitate a comprehensive evaluation of the temporal reasoning capabilities of large language models (LLMs). We conduct an extensive evaluation using popular LLMs, such as GPT-4 and Llama2, in both zero-shot and few-shot learning scenarios. Additionally, we employ BERT-based models to establish the baseline evaluations. Our findings indicate that these models still trail human performance in temporal reasoning tasks. It is our aspiration that TRAM will spur further progress in enhancing the temporal reasoning abilities of LLMs.",
            "year": 2023,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "TRAM is introduced, a temporal reasoning benchmark composed of ten datasets, encompassing various temporal aspects of events such as order, arithmetic, frequency, and duration, designed to facilitate a comprehensive evaluation of the temporal reasoning capabilities of large language models (LLMs)."
            },
            "score": 5
        },
        {
            "id": "46137166084af64a7d115c7a731a1ce0da4c066e",
            "paperId": "46137166084af64a7d115c7a731a1ce0da4c066e",
            "title": "Do Language Models Have a Common Sense regarding Time? Revisiting Temporal Commonsense Reasoning in the Era of Large Language Models",
            "abstract": null,
            "year": 2023,
            "citationCount": 2,
            "tldr": null,
            "score": 5
        },
        {
            "id": "3d2035edd4dd48e1e638279409e11bf689c461e1",
            "paperId": "3d2035edd4dd48e1e638279409e11bf689c461e1",
            "title": "Temporal Reasoning in Natural Language Inference",
            "abstract": "We introduce five new natural language inference (NLI) datasets focused on temporal reasoning. We recast four existing datasets annotated for event duration\u2014how long an event lasts\u2014and event ordering\u2014how events are temporally arranged\u2014into more than one million NLI examples. We use these datasets to investigate how well neural models trained on a popular NLI corpus capture these forms of temporal reasoning.",
            "year": 2020,
            "citationCount": 36,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Five new natural language inference (NLI) datasets focused on temporal reasoning are introduced and four existing datasets annotated for event duration and event ordering are recast into more than one million NLI examples."
            },
            "score": 5
        },
        {
            "id": "bd5deadc58ee45b5e004378ba1d54a96bc947b4a",
            "paperId": "bd5deadc58ee45b5e004378ba1d54a96bc947b4a",
            "title": "FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation",
            "abstract": "Evaluating the factuality of long-form text generated by large language models (LMs) is non-trivial because (1) generations often contain a mixture of supported and unsupported pieces of information, making binary judgments of quality inadequate, and (2) human evaluation is time-consuming and costly. In this paper, we introduce FACTSCORE, a new evaluation that breaks a generation into a series of atomic facts and computes the percentage of atomic facts supported by a reliable knowledge source. We conduct an extensive human evaluation to obtain FACTSCOREs of people biographies generated by several state-of-the-art commercial LMs -- InstructGPT, ChatGPT, and the retrieval-augmented PerplexityAI -- and report new analysis demonstrating the need for such a fine-grained score (e.g., ChatGPT only achieves 58%). Since human evaluation is costly, we also introduce an automated model that estimates FACTSCORE using retrieval and a strong language model, with less than a 2% error rate. Finally, we use this automated metric to evaluate 6,500 generations from a new set of 13 recent LMs that would have cost $26K if evaluated by humans, with various findings: GPT-4 and ChatGPT are more factual than public models, and Vicuna and Alpaca are some of the best public models. FACTSCORE is available for public use via `pip install factscore`.",
            "year": 2023,
            "citationCount": 189,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "An automated model is introduced that estimates FACTSCORE using retrieval and a strong language model, and is used to evaluate 6,500 generations from a new set of 13 recent LMs that would have cost $26K if evaluated by humans, with various findings."
            },
            "score": 5
        },
        {
            "id": "56373d3fd0f1354a61f9e577db039cdb187d8d43",
            "paperId": "56373d3fd0f1354a61f9e577db039cdb187d8d43",
            "title": "Evaluating the Factual Consistency of Large Language Models Through News Summarization",
            "abstract": "While large language models (LLMs) have proven to be effective on a large variety of tasks, they are also known to hallucinate information. To measure whether an LLM prefers factually consistent continuations of its input, we propose a new benchmark called FIB(Factual Inconsistency Benchmark) that focuses on the task of summarization. Specifically, our benchmark involves comparing the scores an LLM assigns to a factually consistent versus a factually inconsistent summary for an input news article. For factually consistent summaries, we use human-written reference summaries that we manually verify as factually consistent. To generate summaries that are factually inconsistent, we generate summaries from a suite of summarization models that we have manually annotated as factually inconsistent. A model's factual consistency is then measured according to its accuracy, i.e.\\ the proportion of documents where it assigns a higher score to the factually consistent summary. To validate the usefulness of FIB, we evaluate 23 large language models ranging from 1B to 176B parameters from six different model families including BLOOM and OPT. We find that existing LLMs generally assign a higher score to factually consistent summaries than to factually inconsistent summaries. However, if the factually inconsistent summaries occur verbatim in the document, then LLMs assign a higher score to these factually inconsistent summaries than factually consistent summaries. We validate design choices in our benchmark including the scoring method and source of distractor summaries. Our code and benchmark data can be found at https://github.com/r-three/fib.",
            "year": 2022,
            "citationCount": 51,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A new benchmark called FIB(Factual Inconsistency Benchmark) that focuses on the task of summarization, and finds that existing LLMs generally assign a higher score to factually consistent summaries than tofactually inconsistent summaries."
            },
            "score": 5
        },
        {
            "id": "d998ff93b2e58c9b219a9103f8c2ad714a41e4b9",
            "paperId": "d998ff93b2e58c9b219a9103f8c2ad714a41e4b9",
            "title": "The Effect of Scaling, Retrieval Augmentation and Form on the Factual Consistency of Language Models",
            "abstract": "Large Language Models (LLMs) make natural interfaces to factual knowledge, but their usefulness is limited by their tendency to deliver inconsistent answers to semantically equivalent questions. For example, a model might predict both\"Anne Redpath passed away in Edinburgh.\"and\"Anne Redpath's life ended in London.\"In this work, we identify potential causes of inconsistency and evaluate the effectiveness of two mitigation strategies: up-scaling and augmenting the LM with a retrieval corpus. Our results on the LLaMA and Atlas models show that both strategies reduce inconsistency while retrieval augmentation is considerably more efficient. We further consider and disentangle the consistency contributions of different components of Atlas. For all LMs evaluated we find that syntactical form and other evaluation task artifacts impact consistency. Taken together, our results provide a better understanding of the factors affecting the factual consistency of language models.",
            "year": 2023,
            "citationCount": 4,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work identifies potential causes of inconsistency and evaluates the effectiveness of two mitigation strategies: up-scaling and augmenting the LM with a retrieval corpus, showing that both strategies reduce inconsistency while retrieval augmentation is considerably more efficient."
            },
            "score": 5
        },
        {
            "id": "152d9a231c00d4495c9bc4a466f42165ce2e2164",
            "paperId": "152d9a231c00d4495c9bc4a466f42165ce2e2164",
            "title": "Evaluating Factual Consistency of Summaries with Large Language Models",
            "abstract": "Detecting factual errors in summaries has been an important and challenging subject in summarization research. Inspired by the emergent ability of large language models (LLMs), we explore evaluating factual consistency of summaries by directly prompting LLMs. We present a comprehensive empirical study to assess the ability of LLMs as factual consistency evaluators, which consists of (1) analyzing different LLMs such as the GPT model series and Flan-T5; (2) investigating a variety of prompting methods including vanilla prompting, chain-of-thought prompting, and a sentence-by-sentence prompting method to tackle long summaries; and (3) evaluating on diverse summaries generated by multiple summarization systems, ranging from pre-transformer methods to SOTA pretrained models. Our experiments demonstrate that prompting LLMs is able to outperform the previous best factuality systems in all settings, by up to 12.2 absolute points in terms of the binary classification accuracy on inconsistency detection.",
            "year": 2023,
            "citationCount": 4,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A comprehensive empirical study to assess the ability of LLMs as factual consistency evaluators, which consists of analyzing different LLMs such as the GPT model series and Flan-T5 and investigating a variety of prompting methods including vanilla prompting, chain-of-thought prompting, and a sentence-by-sentence prompting method to tackle long summaries."
            },
            "score": 5
        },
        {
            "id": "f33d19614d78f4a6e107e768ccd0a2d4244fc89a",
            "paperId": "f33d19614d78f4a6e107e768ccd0a2d4244fc89a",
            "title": "Evaluating the Factual Consistency of Large Language Models Through Summarization",
            "abstract": "While large language models (LLMs) have proven to be effective on a large variety of tasks, they are also known to hallucinate information. To measure whether an LLM prefers factually consistent continuations of its input, we propose a new benchmark called FIB ( F actual I nconsistency B enchmark) that focuses on the task of summarization. Specifically, our benchmark involves comparing the scores an LLM assigns to a factually consistent versus a factually inconsistent summary for an input news article. For factually consistent summaries, we use human-written reference summaries that we manually verify as fac-tually consistent. To generate summaries that are factually inconsistent, we generate summaries from a suite of summarization models that we have manually annotated as fac-tually inconsistent. A model\u2019s factual consistency is then measured according to its accuracy, i.e. the proportion of documents where it assigns a higher score to the factually consistent summary. To validate the usefulness of FIB , we evaluate 23 large language models ranging from 1B to 176B parameters from six different model families including BLOOM and OPT. We \ufb01nd that existing LLMs generally assign a higher score to factually consistent summaries than to factually inconsistent summaries. However, if the factually inconsistent summaries occur verbatim in the document, then LLMs assign a higher score to these factually inconsistent summaries than factually consistent summaries. We validate design choices in our benchmark including the scoring method and source of distractor summaries. Our code and",
            "year": 2022,
            "citationCount": 12,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A new benchmark called FIB is proposed that focuses on the task of summarization and shows that existing LLMs generally assign a higher score to factually consistent summaries than to factually inconsistent summaries, and that existing LLMs generally assign a higher score to factually consistent summaries than to factually inconsistent summaries."
            },
            "score": 5
        },
        {
            "id": "a9467f3581fdf4d2bea9673d198177a76d133071",
            "paperId": "a9467f3581fdf4d2bea9673d198177a76d133071",
            "title": "Improving Language Generation with Sentence Coherence Objective",
            "abstract": "Conditional story generation and contextual text continuation have become increasingly popular topics in NLP community. Existing models are often prone to output paragraphs of texts that gradually diverge from the given prompt. Although the generated text may have a reasonable perplexity and diversity, it could easily be identified by human as gibberish. The goal of our project is to improve the coherence and consistency across sentences in a language-generation model. We aim to solve this issue by first training a sentence pair coherence classifier with GPT-2 pretrained model, and then co-train the GPT-2 language model with this new coherence objective using a method analogous to the REINFORCE algorithm. This fine-tuned language model is able to generate lengthy paragraph conditioned on a given topic without diverging too much. The simplicity of this model allows it to be applicable to a variety of underlying language model architecture since it only modifies the final layer of the pre-trained model.",
            "year": 2020,
            "citationCount": 7,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The goal of this project is to improve the coherence and consistency across sentences in a language-generation model by first training a sentence pair coherence classifier with GPT-2 pretrained model, and then co-train the G PT-2 language model with this new coherence objective using a method analogous to the REINFORCE algorithm."
            },
            "score": 5
        },
        {
            "id": "b908824639d18f11883abcab21efeb22e315ab9c",
            "paperId": "b908824639d18f11883abcab21efeb22e315ab9c",
            "title": "Multimodal Procedural Planning via Dual Text-Image Prompting",
            "abstract": "Embodied agents have achieved prominent performance in following human instructions to complete tasks. However, the potential of providing instructions informed by texts and images to assist humans in completing tasks remains underexplored. To uncover this capability, we present the multimodal procedural planning (MPP) task, in which models are given a high-level goal and generate plans of paired text-image steps, providing more complementary and informative guidance than unimodal plans. The key challenges of MPP are to ensure the informativeness, temporal coherence,and accuracy of plans across modalities. To tackle this, we propose Text-Image Prompting (TIP), a dual-modality prompting method that jointly leverages zero-shot reasoning ability in large language models (LLMs) and compelling text-to-image generation ability from diffusion-based models. TIP improves the interaction in the dual modalities using Text-to-Image Bridge and Image-to-Text Bridge, allowing LLMs to guide the textual-grounded image plan generation and leveraging the descriptions of image plans to ground the textual plan reversely. To address the lack of relevant datasets, we collect WIKIPLAN and RECIPEPLAN as a testbed for MPP. Our results show compelling human preferences and automatic scores against unimodal and multimodal baselines on WIKIPLAN and RECIPEPLAN in terms of informativeness, temporal coherence, and plan accuracy. Our code and data: https://github.com/YujieLu10/MPP.",
            "year": 2023,
            "citationCount": 23,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Text-Image Prompting (TIP) is proposed, a dual-modality prompting method that jointly leverages zero-shot reasoning ability in large language models (LLMs) and compelling text-to-image generation ability from diffusion-based models to tackle the key challenges of MPP."
            },
            "score": 4
        },
        {
            "id": "831b87798ceeee4e5f600a45bce717111ecefa06",
            "paperId": "831b87798ceeee4e5f600a45bce717111ecefa06",
            "title": "Can Large Language Models be Good Path Planners? A Benchmark and Investigation on Spatial-temporal Reasoning",
            "abstract": "Large language models (LLMs) have achieved remarkable success across a wide spectrum of tasks; however, they still face limitations in scenarios that demand long-term planning and spatial reasoning. To facilitate this line of research, in this work, we propose a new benchmark, termed $\\textbf{P}$ath $\\textbf{P}$lanning from $\\textbf{N}$atural $\\textbf{L}$anguage ($\\textbf{PPNL}$). Our benchmark evaluates LLMs' spatial-temporal reasoning by formulating ''path planning'' tasks that require an LLM to navigate to target locations while avoiding obstacles and adhering to constraints. Leveraging this benchmark, we systematically investigate LLMs including GPT-4 via different few-shot prompting methodologies as well as BART and T5 of various sizes via fine-tuning. Our experimental results show the promise of few-shot GPT-4 in spatial reasoning, when it is prompted to reason and act interleavedly, although it still fails to perform long-term temporal reasoning. In contrast, while fine-tuned LLMs achieved impressive results on in-distribution reasoning tasks, they struggled to generalize to larger environments or environments with more obstacles.",
            "year": 2023,
            "citationCount": 4,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The experimental results show the promise of few-shot GPT-4 in spatial reasoning, when it is prompted to reason and act interleavedly, although it still fails to perform long-term temporal reasoning."
            },
            "score": 4
        },
        {
            "id": "d1e813e2880dd8974d09d393fb50be9f9df209db",
            "paperId": "d1e813e2880dd8974d09d393fb50be9f9df209db",
            "title": "LLM4DyG: Can Large Language Models Solve Spatial-Temporal Problems on Dynamic Graphs?",
            "abstract": "In an era marked by the increasing adoption of Large Language Models (LLMs) for various tasks, there is a growing focus on exploring LLMs' capabilities in handling web data, particularly graph data. Dynamic graphs, which capture temporal network evolution patterns, are ubiquitous in real-world web data. Evaluating LLMs' competence in understanding spatial-temporal information on dynamic graphs is essential for their adoption in web applications, which remains unexplored in the literature. In this paper, we bridge the gap via proposing to evaluate LLMs' spatial-temporal understanding abilities on dynamic graphs, to the best of our knowledge, for the first time. Specifically, we propose the LLM4DyG benchmark, which includes nine specially designed tasks considering the capability evaluation of LLMs from both temporal and spatial dimensions. Then, we conduct extensive experiments to analyze the impacts of different data generators, data statistics, prompting techniques, and LLMs on the model performance. Finally, we propose Disentangled Spatial-Temporal Thoughts (DST2) for LLMs on dynamic graphs to enhance LLMs' spatial-temporal understanding abilities. Our main observations are: 1) LLMs have preliminary spatial-temporal understanding abilities on dynamic graphs, 2) Dynamic graph tasks show increasing difficulties for LLMs as the graph size and density increase, while not sensitive to the time span and data generation mechanism, 3) the proposed DST2 prompting method can help to improve LLMs' spatial-temporal understanding abilities on dynamic graphs for most tasks. The data and codes will be open-sourced at publication time.",
            "year": 2023,
            "citationCount": 4,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper proposes the LLM4DyG benchmark, which includes nine specially designed tasks considering the capability evaluation of LLMs from both temporal and spatial dimensions, and proposes Disentangled Spatial-Temporal Thoughts (DST2) for LLMs on dynamic graphs to enhance LLMs' spatial-temporal understanding abilities."
            },
            "score": 4
        },
        {
            "id": "f197bf0fc2f228483f6af3285000d54d8d97f9eb",
            "paperId": "f197bf0fc2f228483f6af3285000d54d8d97f9eb",
            "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models",
            "abstract": "We introduce Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention. Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement. Voyager interacts with GPT-4 via blackbox queries, which bypasses the need for model parameter fine-tuning. The skills developed by Voyager are temporally extended, interpretable, and compositional, which compounds the agent's abilities rapidly and alleviates catastrophic forgetting. Empirically, Voyager shows strong in-context lifelong learning capability and exhibits exceptional proficiency in playing Minecraft. It obtains 3.3x more unique items, travels 2.3x longer distances, and unlocks key tech tree milestones up to 15.3x faster than prior SOTA. Voyager is able to utilize the learned skill library in a new Minecraft world to solve novel tasks from scratch, while other techniques struggle to generalize. We open-source our full codebase and prompts at https://voyager.minedojo.org/.",
            "year": 2023,
            "citationCount": 336,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": null
            },
            "score": 4
        },
        {
            "id": "d5342fce96175f83550cfae471a0a46d16401481",
            "paperId": "d5342fce96175f83550cfae471a0a46d16401481",
            "title": "ST-LLM: Large Language Models Are Effective Temporal Learners",
            "abstract": "Large Language Models (LLMs) have showcased impressive capabilities in text comprehension and generation, prompting research efforts towards video LLMs to facilitate human-AI interaction at the video level. However, how to effectively encode and understand videos in video-based dialogue systems remains to be solved. In this paper, we investigate a straightforward yet unexplored question: Can we feed all spatial-temporal tokens into the LLM, thus delegating the task of video sequence modeling to the LLMs? Surprisingly, this simple approach yields significant improvements in video understanding. Based upon this, we propose ST-LLM, an effective video-LLM baseline with Spatial-Temporal sequence modeling inside LLM. Furthermore, to address the overhead and stability issues introduced by uncompressed video tokens within LLMs, we develop a dynamic masking strategy with tailor-made training objectives. For particularly long videos, we have also designed a global-local input module to balance efficiency and effectiveness. Consequently, we harness LLM for proficient spatial-temporal modeling, while upholding efficiency and stability. Extensive experimental results attest to the effectiveness of our method. Through a more concise model and training pipeline, ST-LLM establishes a new state-of-the-art result on VideoChatGPT-Bench and MVBench. Codes have been available at https://github.com/TencentARC/ST-LLM.",
            "year": 2024,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper proposes ST-LLM, an effective video-LLM baseline with Spatial-Temporal sequence modeling inside LLM, and develops a dynamic masking strategy with tailor-made training objectives to address the overhead and stability issues introduced by uncompressed video tokens within LLMs."
            },
            "score": 4
        },
        {
            "id": "0b778079946764292de3771a489d5ce9e1868a8b",
            "paperId": "0b778079946764292de3771a489d5ce9e1868a8b",
            "title": "The first step is the hardest: Pitfalls of Representing and Tokenizing Temporal Data for Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated remarkable generalization across diverse tasks, leading individuals to increasingly use them as personal assistants and universal computing engines. Nevertheless, a notable obstacle emerges when feeding numerical/temporal data into these models, such as data sourced from wearables or electronic health records. LLMs employ tokenizers in their input that break down text into smaller units. However, tokenizers are not designed to represent numerical values and might struggle to understand repetitive patterns and context, treating consecutive values as separate tokens and disregarding their temporal relationships. Here, we discuss recent works that employ LLMs for human-centric tasks such as in mobile health sensing and present a case study showing that popular LLMs tokenize temporal data incorrectly. To address that, we highlight potential solutions such as prompt tuning with lightweight embedding layers as well as multimodal adapters, that can help bridge this\"modality gap\". While the capability of language models to generalize to other modalities with minimal or no finetuning is exciting, this paper underscores the fact that their outputs cannot be meaningful if they stumble over input nuances.",
            "year": 2023,
            "citationCount": 4,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Recent works that employ LLMs for human-centric tasks are discussed and a case study showing that popular LLMs tokenize temporal data incorrectly is presented, highlighting potential solutions that can help bridge this \"modality gap\"."
            },
            "score": 4
        },
        {
            "id": "6eee69031d2e11aa03a5a8fcb219cff4562863be",
            "paperId": "6eee69031d2e11aa03a5a8fcb219cff4562863be",
            "title": "ECONET: Effective Continual Pretraining of Language Models for Event Temporal Reasoning",
            "abstract": "While pre-trained language models (PTLMs) have achieved noticeable success on many NLP tasks, they still struggle for tasks that require event temporal reasoning, which is essential for event-centric applications. We present a continual pre-training approach that equips PTLMs with targeted knowledge about event temporal relations. We design self-supervised learning objectives to recover masked-out event and temporal indicators and to discriminate sentences from their corrupted counterparts (where event or temporal indicators got replaced). By further pre-training a PTLM with these objectives jointly, we reinforce its attention to event and temporal information, yielding enhanced capability on event temporal reasoning. This **E**ffective **CON**tinual pre-training framework for **E**vent **T**emporal reasoning (ECONET) improves the PTLMs\u2019 fine-tuning performances across five relation extraction and question answering tasks and achieves new or on-par state-of-the-art performances in most of our downstream tasks.",
            "year": 2020,
            "citationCount": 36,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A continual pre-training approach that equips PTLMs with targeted knowledge about event temporal relations and design self-supervised learning objectives to recover masked-out event and temporal indicators and to discriminate sentences from their corrupted counterparts."
            },
            "score": 4
        },
        {
            "id": "ba7849b5d9f0ca70011411230fabcdaf2ef8fd83",
            "paperId": "ba7849b5d9f0ca70011411230fabcdaf2ef8fd83",
            "title": "Enhancing Temporal Knowledge Graph Forecasting with Large Language Models via Chain-of-History Reasoning",
            "abstract": "Temporal Knowledge Graph (TKG) forecasting aims to predict future facts based on given histories. Most recent graph-based models excel at capturing structural information within TKGs but lack semantic comprehension abilities. Nowadays, with the surge of LLMs, the LLM-based TKG prediction model has emerged. However, the existing LLM-based model exhibits three shortcomings: (1) It only focuses on the first-order history for prediction while ignoring high-order historical information, resulting in the provided information for LLMs being extremely limited. (2) LLMs struggle with optimal reasoning performance under heavy historical information loads. (3) For TKG prediction, the temporal reasoning capability of LLM alone is limited. To address the first two challenges, we propose Chain-of-History (CoH) reasoning which explores high-order histories step-by-step, achieving effective utilization of high-order historical information for LLMs on TKG prediction. To address the third issue, we design CoH as a paly-and-plug module to enhance the performance of graph-based models for TKG prediction. Extensive experiments on three datasets and backbones demonstrate the effectiveness of CoH.",
            "year": 2024,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Chain-of-History (CoH) reasoning is proposed which explores high-order histories step-by-step, achieving effective utilization of high-order historical information for LLMs on TKG prediction."
            },
            "score": 4
        },
        {
            "id": "220cb18e8e005024a7ed1c1d41b4b6fa4774847f",
            "paperId": "220cb18e8e005024a7ed1c1d41b4b6fa4774847f",
            "title": "Unlocking Temporal Question Answering for Large Language Models Using Code Execution",
            "abstract": "Large language models (LLMs) have made significant progress in natural language processing (NLP), and are utilized extensively in various applications. Recent works, such as chain-of-thought (CoT), have shown that intermediate reasoning steps can improve the performance of LLMs for complex reasoning tasks, such as math problems and symbolic question-answering tasks. However, we notice the challenge that LLMs face when it comes to temporal reasoning. Our preliminary experiments show that generating intermediate reasoning steps does not always boost the performance of complex temporal question-answering tasks. Therefore, we propose a novel framework that combines the extraction capability of LLMs and the logical reasoning capability of a Python solver to tackle this issue. Extensive experiments and analysis demonstrate the effectiveness of our framework in handling intricate time-bound reasoning tasks.",
            "year": 2023,
            "citationCount": 6,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work proposes a novel framework that combines the extraction capability of LLMs and the logical reasoning capability of a Python solver to tackle the challenge that LLMs face when it comes to temporal reasoning."
            },
            "score": 4
        },
        {
            "id": "5309e53a67834dcb2db3ddd75ce5a1128da97d40",
            "paperId": "5309e53a67834dcb2db3ddd75ce5a1128da97d40",
            "title": "Two-stage Generative Question Answering on Temporal Knowledge Graph Using Large Language Models",
            "abstract": "Temporal knowledge graph question answering (TKGQA) poses a significant challenge task, due to the temporal constraints hidden in questions and the answers sought from dynamic structured knowledge. Although large language models (LLMs) have made considerable progress in their reasoning ability over structured data, their application to the TKGQA task is a relatively unexplored area. This paper first proposes a novel generative temporal knowledge graph question answering framework, GenTKGQA, which guides LLMs to answer temporal questions through two phases: Subgraph Retrieval and Answer Generation. First, we exploit LLM's intrinsic knowledge to mine temporal constraints and structural links in the questions without extra training, thus narrowing down the subgraph search space in both temporal and structural dimensions. Next, we design virtual knowledge indicators to fuse the graph neural network signals of the subgraph and the text representations of the LLM in a non-shallow way, which helps the open-source LLM deeply understand the temporal order and structural dependencies among the retrieved facts through instruction tuning. Experimental results demonstrate that our model outperforms state-of-the-art baselines, even achieving 100\\% on the metrics for the simple question type.",
            "year": 2024,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A novel generative temporal knowledge graph question answering framework, GenTKGQA, is proposed, which guides LLMs to answer temporal questions through two phases: Subgraph Retrieval and Answer Generation, and design virtual knowledge indicators to fuse the graph neural network signals of the subgraph and the text representations of the LLM in a non-shallow way."
            },
            "score": 4
        },
        {
            "id": "9793b07ba09d9f2ac9cabd8117daa93bf3db4346",
            "paperId": "9793b07ba09d9f2ac9cabd8117daa93bf3db4346",
            "title": "DEER: A Data Efficient Language Model for Event Temporal Reasoning",
            "abstract": "Pretrained language models (LMs) such as BERT, RoBERTa, and ELECTRA are effective at improving the performances of a variety of downstream NLP tasks. Recently, researchers have incorporated domain and task-specific knowledge in these LMs' training objectives and further enhanced models' capability of handling downstream tasks. However, none of these LMs are designed specifically for event temporal reasoning. We propose DEER, a language model that is trained to focus on event temporal relations and performs better under low-resource settings than original LMs. More specifically, we create a large number of training samples to simulate the machine reading comprehension and information extraction tasks for event temporal understanding and leverage a generator-discriminator structure to reinforce the LMs' capability of event temporal reasoning. Our experimental results show that DEER can achieve SOTA results and works particularly well in low-resource settings across 5 widely used datasets.",
            "year": 2020,
            "citationCount": 15,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work proposes DEER, a language model that is trained to focus on event temporal relations and performs better under low-resource settings than original LMs and uses a generator-discriminator structure to reinforce the LMs' capability of event temporal reasoning."
            },
            "score": 4
        },
        {
            "id": "298dd87e00fe54c683aa9231902d3e4ad5d8f239",
            "paperId": "298dd87e00fe54c683aa9231902d3e4ad5d8f239",
            "title": "Attribute Alignment: Controlling Text Generation from Pre-trained Language Models",
            "abstract": "Large language models benefit from training with a large amount of unlabeled text, which gives them increasingly fluent and diverse generation capabilities. However, using these models for text generation that takes into account target attributes, such as sentiment polarity or specific topics, remains a challenge. We propose a simple and flexible method for controlling text generation by aligning disentangled attribute representations. In contrast to recent efforts on training a discriminator to perturb the token level distribution for an attribute, we use the same data to learn an alignment function to guide the pre-trained, non-controlled language model to generate texts with the target attribute without changing the original language model parameters. We evaluate our method on sentiment- and topic-controlled generation, and show large performance gains over previous methods while retaining fluency and diversity.",
            "year": 2021,
            "citationCount": 30,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A simple and flexible method for controlling text generation by aligning disentangled attribute representations to guide the pre-trained, non-controlled language model to generate texts with the target attribute without changing the original language model parameters."
            },
            "score": 4
        },
        {
            "id": "e04a80263d252a3d8a382ba37a249b9345620570",
            "paperId": "e04a80263d252a3d8a382ba37a249b9345620570",
            "title": "Plug and Play Language Models: A Simple Approach to Controlled Text Generation",
            "abstract": "Large transformer-based language models (LMs) trained on huge text corpora have shown unparalleled generation capabilities. However, controlling attributes of the generated language (e.g. switching topic or sentiment) is difficult without modifying the model architecture or fine-tuning on attribute-specific data and entailing the significant cost of retraining. We propose a simple alternative: the Plug and Play Language Model (PPLM) for controllable language generation, which combines a pretrained LM with one or more simple attribute classifiers that guide text generation without any further training of the LM. In the canonical scenario we present, the attribute models are simple classifiers consisting of a user-specified bag of words or a single learned layer with 100,000 times fewer parameters than the LM. Sampling entails a forward and backward pass in which gradients from the attribute model push the LM's hidden activations and thus guide the generation. Model samples demonstrate control over a range of topics and sentiment styles, and extensive automated and human annotated evaluations show attribute alignment and fluency. PPLMs are flexible in that any combination of differentiable attribute models may be used to steer text generation, which will allow for diverse and creative applications beyond the examples given in this paper.",
            "year": 2019,
            "citationCount": 736,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The Plug and Play Language Model (PPLM) for controllable language generation is proposed, which combines a pretrained LM with one or more simple attribute classifiers that guide text generation without any further training of the LM."
            },
            "score": 4
        },
        {
            "id": "d2d16333a4b0dc7e3463b280b9945e5ee6c53396",
            "paperId": "d2d16333a4b0dc7e3463b280b9945e5ee6c53396",
            "title": "TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models",
            "abstract": "Factual consistency evaluation is often conducted using Natural Language Inference (NLI) models, yet these models exhibit limited success in evaluating summaries. Previous work improved such models with synthetic training data. However, the data is typically based on perturbed human-written summaries, which often differ in their characteristics from real model-generated summaries and have limited coverage of possible factual errors. Alternatively, large language models (LLMs) have recently shown promising results in directly evaluating generative tasks, but are too computationally expensive for practical use. Motivated by these limitations, we introduce TrueTeacher, a method for generating synthetic data by annotating diverse model-generated summaries using a LLM. Unlike prior work, TrueTeacher does not rely on human-written summaries, and is multilingual by nature. Experiments on the TRUE benchmark show that a student model trained using our data, substantially outperforms both the state-of-the-art model with similar capacity, and the LLM teacher. In a systematic study, we compare TrueTeacher to existing synthetic data generation methods and demonstrate its superiority and robustness to domain-shift. We also show that our method generalizes to multilingual scenarios. Lastly, we release our large scale synthetic dataset (1.4M examples), generated using TrueTeacher, and a checkpoint trained on this data.",
            "year": 2023,
            "citationCount": 31,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work introduces TrueTeacher, a method for generating synthetic data by annotating diverse model-generated summaries using a LLM, which does not rely on human-written summaries, and is multilingual by nature."
            },
            "score": 4
        },
        {
            "id": "e96348576b682e709b2ee06ea28cd81f8bfa102b",
            "paperId": "e96348576b682e709b2ee06ea28cd81f8bfa102b",
            "title": "Exploring the Factual Consistency in Dialogue Comprehension of Large Language Models",
            "abstract": "LLMs (Large Language Models) usually interact with users in the form of dialogue and generate responses following their instructions, which naturally require dialogue comprehension abilities. However, dialogue comprehension is a general language ability which is hard to be evaluated directly. In this work, we propose to perform the evaluation focusing on the factual consistency issue with the help of the dialogue summarization task. Besides evaluating and analyzing the dialogue summarization performance (DIAC-Sum) of different LLMs, we also derive factual questions from the generated summaries and use them as a more flexible measurement of dialogue comprehension (DIAC-QA). Our evaluation shows that, on average, 26.8% of the summaries generated by LLMs contain factual inconsistency. Even ChatGPT, the strongest model evaluated, has such errors in 16% of its summaries. For answering the factual questions, which is more challenging, the average error rate of all evaluated LLMs is 36.1%. Both results indicate serious deficiencies. Detailed analysis shows that the understanding of subject/object of the conversation is still challenging for LLMs. Furthermore, to stimulate and enhance the dialogue comprehension ability of LLMs, we propose a fine-tuning paradigm with auto-constructed multi-task data, which achieved a relative error rate reduction of 11% on DIAC-QA.",
            "year": 2023,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "To stimulate and enhance the dialogue comprehension ability of LLMs, a fine-tuning paradigm with auto-constructed multi-task data is proposed, which achieved a relative error rate reduction of 11% on DIAC-QA."
            },
            "score": 4
        },
        {
            "id": "36870ac7332b45edf59e5c111dc5bd24139dc1ce",
            "paperId": "36870ac7332b45edf59e5c111dc5bd24139dc1ce",
            "title": "Factual Consistency of Multilingual Pretrained Language Models",
            "abstract": "Pretrained language models can be queried for factual knowledge, with potential applications in knowledge base acquisition and tasks that require inference. However, for that, we need to know how reliable this knowledge is, and recent work has shown that monolingual English language models lack consistency when predicting factual knowledge, that is, they fill-in-the-blank differently for paraphrases describing the same fact. In this paper, we extend the analysis of consistency to a multilingual setting. We introduce a resource, mParaRel, and investigate (i) whether multilingual language models such as mBERT and XLM-R are more consistent than their monolingual counterparts;and (ii) if such models are equally consistent across languages.We find that mBERT is as inconsistent as English BERT in English paraphrases, but that both mBERT and XLM-R exhibit a high degree of inconsistency in English and even more so for all the other 45 languages.",
            "year": 2022,
            "citationCount": 7,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "MBERT is as inconsistent as English BERT in English paraphrases, but that both mBERT and XLM-R exhibit a high degree of inconsistency in English and even more so for all the other 45 languages."
            },
            "score": 4
        },
        {
            "id": "f3cd3a0e1a0a29193fd88178ef75946dfe756622",
            "paperId": "f3cd3a0e1a0a29193fd88178ef75946dfe756622",
            "title": "Factual Consistency Evaluation of Summarisation in the Era of Large Language Models",
            "abstract": "Factual inconsistency with source documents in automatically generated summaries can lead to misinformation or pose risks. Existing factual consistency(FC) metrics are constrained by their performance, efficiency, and explainability. Recent advances in Large language models (LLMs) have demonstrated remarkable potential in text evaluation but their effectiveness in assessing FC in summarisation remains underexplored. Prior research has mostly focused on proprietary LLMs, leaving essential factors that affect their assessment capabilities unexplored. Additionally, current FC evaluation benchmarks are restricted to news articles, casting doubt on the generality of the FC methods tested on them. In this paper, we first address the gap by introducing TreatFact a dataset of LLM-generated summaries of clinical texts, annotated for FC by domain experts. Moreover, we benchmark 11 LLMs for FC evaluation across news and clinical domains and analyse the impact of model size, prompts, pre-training and fine-tuning data. Our findings reveal that despite proprietary models prevailing on the task, open-source LLMs lag behind. Nevertheless, there is potential for enhancing the performance of open-source LLMs through increasing model size, expanding pre-training data, and developing well-curated fine-tuning data. Experiments on TreatFact suggest that both previous methods and LLM-based evaluators are unable to capture factual inconsistencies in clinical summaries, posing a new challenge for FC evaluation.",
            "year": 2024,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "TreatFact, a dataset of LLM-generated summaries of clinical texts, annotated for FC by domain experts, is introduced and it is revealed that despite proprietary models prevailing on the task, open-source LLMs lag behind."
            },
            "score": 4
        },
        {
            "id": "f727f928e7e179307d8d4a1da2387393f2bd7915",
            "paperId": "f727f928e7e179307d8d4a1da2387393f2bd7915",
            "title": "Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models",
            "abstract": "Language models can memorize a considerable amount of factual information during pretraining that can be elicited through prompting or finetuning models on tasks like question answering. In this paper, we discuss approaches to measuring model factual beliefs, updating incorrect factual beliefs in models, and visualizing graphical relationships between factual beliefs. Our main contributions include: (1) new metrics for evaluating belief-updating methods focusing on the logical consistency of beliefs, (2) a training objective for Sequential, Local, and Generalizing updates (SLAG) that improves the performance of existing hypernetwork approaches, and (3) the introduction of the belief graph, a new form of visualization for language models that shows relationships between stored model beliefs. Our experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency. Although off-the-shelf optimizers are surprisingly strong belief-updating baselines, our learned optimizers can outperform them in more difficult settings than have been considered in past work.",
            "year": 2023,
            "citationCount": 31,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency, and off-the-shelf optimizers can outperform them in more difficult settings than have been considered in past work."
            },
            "score": 4
        },
        {
            "id": "6af460d34bfc8e955e43fbe15cedcf329b48bc19",
            "paperId": "6af460d34bfc8e955e43fbe15cedcf329b48bc19",
            "title": "SAC3: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency",
            "abstract": "Hallucination detection is a critical step toward understanding the trustworthiness of modern language models (LMs). To achieve this goal, we re-examine existing detection approaches based on the self-consistency of LMs and uncover two types of hallucinations resulting from 1) question-level and 2) model-level, which cannot be effectively identified through self-consistency check alone. Building upon this discovery, we propose a novel sampling-based method, i.e., semantic-aware cross-check consistency (SAC3) that expands on the principle of self-consistency checking. Our SAC3 approach incorporates additional mechanisms to detect both question-level and model-level hallucinations by leveraging advances including semantically equivalent question perturbation and cross-model response consistency checking. Through extensive and systematic empirical analysis, we demonstrate that SAC3 outperforms the state of the art in detecting both non-factual and factual statements across multiple question-answering and open-domain generation benchmarks.",
            "year": 2023,
            "citationCount": 15,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work proposes a novel sampling-based method, i.e., semantic-aware cross-check consistency (SAC3) that expands on the principle of self-consistency checking and demonstrates that SAC3 outperforms the state of the art in detecting both non-factual and factual statements across multiple question-answering and open-domain generation benchmarks."
            },
            "score": 4
        },
        {
            "id": "73b6de24eb0e5f6ff4f9c3bdd9257f4554faca19",
            "paperId": "73b6de24eb0e5f6ff4f9c3bdd9257f4554faca19",
            "title": "Measuring and Improving Consistency in Pretrained Language Models",
            "abstract": "Abstract Consistency of a model\u2014that is, the invariance of its behavior under meaning-preserving alternations in its input\u2014is a highly desirable property in natural language processing. In this paper we study the question: Are Pretrained Language Models (PLMs) consistent with respect to factual knowledge? To this end, we create ParaRel\ud83e\udd18, a high-quality resource of cloze-style query English paraphrases. It contains a total of 328 paraphrases for 38 relations. Using ParaRel\ud83e\udd18, we show that the consistency of all PLMs we experiment with is poor\u2014 though with high variance between relations. Our analysis of the representational spaces of PLMs suggests that they have a poor structure and are currently not suitable for representing knowledge robustly. Finally, we propose a method for improving model consistency and experimentally demonstrate its effectiveness.1",
            "year": 2021,
            "citationCount": 226,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The creation of PARAREL, a high-quality resource of cloze-style query English paraphrases, and analysis of the representational spaces of PLMs suggest that they have a poor structure and are currently not suitable for representing knowledge in a robust way."
            },
            "score": 4
        },
        {
            "id": "3867d999b550b57e6762f9d4b0114ee7551b2e2f",
            "paperId": "3867d999b550b57e6762f9d4b0114ee7551b2e2f",
            "title": "Predicting Question-Answering Performance of Large Language Models through Semantic Consistency",
            "abstract": "Semantic consistency of a language model is broadly defined as the model\u2019s ability to produce semantically-equivalent outputs, given semantically-equivalent inputs. We address the task of assessing question-answering (QA) semantic consistency of contemporary large language models (LLMs) by manually creating a benchmark dataset with high-quality paraphrases for factual questions, and release the dataset to the community.We further combine the semantic consistency metric with additional measurements suggested in prior work as correlating with LLM QA accuracy, for building and evaluating a framework for factual QA reference-less performance prediction \u2013 predicting the likelihood of a language model to accurately answer a question. Evaluating the framework on five contemporary LLMs, we demonstrate encouraging, significantly outperforming baselines, results.",
            "year": 2023,
            "citationCount": 3,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work addresses the task of assessing question-answering (QA) semantic consistency of contemporary large language models (LLMs) by manually creating a benchmark dataset with high-quality paraphrases for factual questions, and releases the dataset to the community."
            },
            "score": 4
        },
        {
            "id": "4780d0a027c5c5a8e01d7cf697f6296880ffc945",
            "paperId": "4780d0a027c5c5a8e01d7cf697f6296880ffc945",
            "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
            "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in language generation, understanding, and few-shot learning in recent years. An extensive body of work has explored how their performance may be further improved through the tools of prompting, ranging from verification, self-consistency, or intermediate scratchpads. In this paper, we present a complementary approach to improve language responses where multiple language model instances propose and debate their individual responses and reasoning processes over multiple rounds to arrive at a common final answer. Our findings indicate that this approach significantly enhances mathematical and strategic reasoning across a number of tasks. We also demonstrate that our approach improves the factual validity of generated content, reducing fallacious answers and hallucinations that contemporary models are prone to. Our approach may be directly applied to existing black-box models and uses identical procedure and prompts for all tasks we investigate. Overall, our findings suggest that such\"society of minds\"approach has the potential to significantly advance the capabilities of LLMs and pave the way for further breakthroughs in language generation and understanding.",
            "year": 2023,
            "citationCount": 206,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A complementary approach to improve language responses where multiple language model instances propose and debate their individual responses and reasoning processes over multiple rounds to arrive at a common final answer is presented, indicating that this approach significantly enhances mathematical and strategic reasoning across a number of tasks."
            },
            "score": 4
        },
        {
            "id": "3a89e289e2dd29f5e52a2bf354a637762b661257",
            "paperId": "3a89e289e2dd29f5e52a2bf354a637762b661257",
            "title": "Fine-tuning Language Models for Factuality",
            "abstract": "The fluency and creativity of large pre-trained language models (LLMs) have led to their widespread use, sometimes even as a replacement for traditional search engines. Yet language models are prone to making convincing but factually inaccurate claims, often referred to as 'hallucinations.' These errors can inadvertently spread misinformation or harmfully perpetuate misconceptions. Further, manual fact-checking of model responses is a time-consuming process, making human factuality labels expensive to acquire. In this work, we fine-tune language models to be more factual, without human labeling and targeting more open-ended generation settings than past work. We leverage two key recent innovations in NLP to do so. First, several recent works have proposed methods for judging the factuality of open-ended text by measuring consistency with an external knowledge base or simply a large model's confidence scores. Second, the direct preference optimization algorithm enables straightforward fine-tuning of language models on objectives other than supervised imitation, using a preference ranking over possible model responses. We show that learning from automatically generated factuality preference rankings, generated either through existing retrieval systems or our novel retrieval-free approach, significantly improves the factuality (percent of generated claims that are correct) of Llama-2 on held-out topics compared with RLHF or decoding strategies targeted at factuality. At 7B scale, compared to Llama-2-chat, we observe 58% and 40% reduction in factual error rate when generating biographies and answering medical questions, respectively.",
            "year": 2023,
            "citationCount": 56,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "It is shown that learning from automatically generated factuality preference rankings, generated either through existing retrieval systems or the novel retrieval-free approach, significantly improves the factuality of Llama-2 on held-out topics compared with RLHF or decoding strategies targeted at factuality."
            },
            "score": 4
        },
        {
            "id": "a5a13071e3f834ec90c0c69087b84363abc2fb38",
            "paperId": "a5a13071e3f834ec90c0c69087b84363abc2fb38",
            "title": "XLTime: A Cross-Lingual Knowledge Transfer Framework for Temporal Expression Extraction",
            "abstract": "Temporal Expression Extraction (TEE) is essential for understanding time in natural language. It has applications in Natural Language Processing (NLP) tasks such as question answering, information retrieval, and causal inference. To date, work in this area has mostly focused on English as there is a scarcity of labeled data for other languages. We propose XLTime, a novel framework for multilingual TEE. XLTime works on top of pre-trained language models and leverages multi-task learning to prompt cross-language knowledge transfer both from English and within the non-English languages. XLTime alleviates problems caused by a shortage of data in the target language. We apply XLTime with different language models and show that it outperforms the previous automatic SOTA methods on French, Spanish, Portuguese, and Basque, by large margins. XLTime also closes the gap considerably on the handcrafted HeidelTime method.",
            "year": 2022,
            "citationCount": 12,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work proposes XLTime, a novel framework for multilingual TEE that works on top of pre-trained language models and leverages multi-task learning to prompt cross-language knowledge transfer both from English and within the non-English languages."
            },
            "score": 4
        },
        {
            "id": "00798ebc314dcbd6f56c55187e7238ba47768dfb",
            "paperId": "00798ebc314dcbd6f56c55187e7238ba47768dfb",
            "title": "Developing a visual temporal modeller: applying an extensible nlp system to support learners\u2019 understanding of tense and aspect in English",
            "abstract": "Abstract This paper reports on the development of a prototype tool which shows how learners can be helped to reflect upon the accuracy of their writing. Analysis of samples of freely written texts by intermediate and advanced learners of English as a foreign language (EFL) showed evidence of weakness in the use of tense and aspect. Computational discourse modelling techniques were applied to the data to generate semantic models of fragments of the narratives with particular focus on their temporal structure. These models have been converted into dynamic graphical representations of the temporal relationships between discourse events as the narratives are written. The system also provides access to the ontology devised to model individual events and this offers learners insights into the events\u2019 semantic properties. These techniques provide the basis for a stimulating learning tool capable of capturing key elements of written narratives, and prompting learners\u2019 awareness of language use, particularly tense and aspect.",
            "year": 2012,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Development of a prototype tool which shows how learners can be helped to reflect upon the accuracy of their writing, and prompting learners\u2019 awareness of language use, particularly tense and aspect is reported on."
            },
            "score": 4
        },
        {
            "id": "03d0f82f43deaafbc0ba1b4bcd6a9d70b756f6f7",
            "paperId": "03d0f82f43deaafbc0ba1b4bcd6a9d70b756f6f7",
            "title": "XLTime: A Cross-Lingual Knowledge Transfer Framework for Zero-Shot Low-Resource Language Temporal Expression Extraction",
            "abstract": "Temporal Expression Extraction (TEE) is es-001 sential for understanding time in natural lan-002 guage. It has applications in Natural Lan-003 guage Processing (NLP) tasks such as question 004 answering, information retrieval, and causal 005 inference. To date, work in this area has 006 mostly focused on English as TEE for low-007 resource languages is hindered by a scarcity 008 of training data. We propose XLTime, a 009 novel framework for zero-shot low-resource 010 language TEE. XLTime works on top of pre-011 trained language models and leverages multi-012 task learning to prompt cross-language knowl-013 edge transfer both from English and within the 014 low-resource languages. It alleviates the prob-015 lems caused by the shortage in low-resource 016 language training data. We apply XLTime 017 with different language models and show that 018 it outperforms the previous automatic SOTA 019 methods on four low-resource languages, i.e., 020 French, Spanish, Portuguese, and Basque, by 021 large margins. It also closes the gap consider-022 ably on the handcrafted HeidelTime tool. 023",
            "year": 2021,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "XLTime works on top of pre-011 trained language models and leverages multi-012 task learning to prompt cross-language edge transfer both from English and within the 014 low-resource languages, alleviating the shortage in low-resource 016 language training data."
            },
            "score": 4
        },
        {
            "id": "d8bf2fe6005113d7144e00c7dd823d0fc58a2ad4",
            "paperId": "d8bf2fe6005113d7144e00c7dd823d0fc58a2ad4",
            "title": "Prompting Large Language Models to Reformulate Queries for Moment Localization",
            "abstract": "The task of moment localization is to localize a temporal moment in an untrimmed video for a given natural language query. Since untrimmed video contains highly redundant contents, the quality of the query is crucial for accurately localizing moments, i.e., the query should provide precise information about the target moment so that the localization model can understand what to look for in the videos. However, the natural language queries in current datasets may not be easy to understand for existing models. For example, the Ego4D dataset uses question sentences as the query to describe relatively complex moments. While being natural and straightforward for humans, understanding such question sentences are challenging for mainstream moment localization models like 2D-TAN. Inspired by the recent success of large language models, especially their ability of understanding and generating complex natural language contents, in this extended abstract, we make early attempts at reformulating the moment queries into a set of instructions using large language models and making them more friendly to the localization models.",
            "year": 2023,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Inspired by the recent success of large language models, especially their ability of understanding and generating complex natural language contents, in this extended abstract, early attempts are made at reformulating the moment queries into a set of instructions using largelanguage models and making them more friendly to the localization models."
            },
            "score": 3
        },
        {
            "id": "b66d962f92abc0e7a6a2509d3e911f9b3127128a",
            "paperId": "b66d962f92abc0e7a6a2509d3e911f9b3127128a",
            "title": "Zero-Shot Temporal Action Detection via Vision-Language Prompting",
            "abstract": "Existing temporal action detection (TAD) methods rely on large training data including segment-level annotations, limited to recognizing previously seen classes alone during inference. Collecting and annotating a large training set for each class of interest is costly and hence unscalable. Zero-shot TAD (ZS-TAD) resolves this obstacle by enabling a pre-trained model to recognize any unseen action classes. Meanwhile, ZS-TAD is also much more challenging with significantly less investigation. Inspired by the success of zero-shot image classification aided by vision-language (ViL) models such as CLIP, we aim to tackle the more complex TAD task. An intuitive method is to integrate an off-the-shelf proposal detector with CLIP style classification. However, due to the sequential localization (e.g, proposal generation) and classification design, it is prone to localization error propagation. To overcome this problem, in this paper we propose a novel zero-Shot Temporal Action detection model via Vision-LanguagE prompting (STALE). Such a novel design effectively eliminates the dependence between localization and classification by breaking the route for error propagation in-between. We further introduce an interaction mechanism between classification and localization for improved optimization. Extensive experiments on standard ZS-TAD video benchmarks show that our STALE significantly outperforms state-of-the-art alternatives. Besides, our model also yields superior results on supervised TAD over recent strong competitors. The PyTorch implementation of STALE is available at https://github.com/sauradip/STALE.",
            "year": 2022,
            "citationCount": 38,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A novel zero-Shot Temporal Action detection model via Vision-LanguagE prompting (STALE) is proposed, which effectively eliminates the dependence between localization and classification by breaking the route for error propagation in-between and introduces an interaction mechanism between classification and localization for improved optimization."
            },
            "score": 3
        },
        {
            "id": "7b98955b8a088784ae9170ddbfc2b38888b82acb",
            "paperId": "7b98955b8a088784ae9170ddbfc2b38888b82acb",
            "title": "Language Models are Causal Knowledge Extractors for Zero-shot Video Question Answering",
            "abstract": "Causal Video Question Answering (CVidQA) queries not only association or temporal relations but also causal relations in a video. Existing question synthesis methods pretrained question generation (QG) systems on reading comprehension datasets with text descriptions as inputs. However, QG models only learn to ask association questions (e.g., \"what is someone doing\u2026\") and result in inferior performance due to the poor transfer of association knowledge to CVidQA, which focuses on causal questions like \"why is someone doing \u2026\". Observing this, we proposed to exploit causal knowledge to generate question-answer pairs, and proposed a novel framework, Causal Knowledge Extraction from Language Models (CaKE-LM), leveraging causal commonsense knowledge from language models to tackle CVidQA. To extract knowledge from LMs, CaKE-LM generates causal questions containing two events with one triggering another (e.g., \"score a goal\" triggers \"soccer player kicking ball\") by prompting LM with the action (soccer player kicking ball) to retrieve the intention (to score a goal). CaKE-LM significantly outperforms conventional methods by 4% to 6% of zero-shot CVidQA accuracy on NExT-QA and Causal-VidQA datasets. We also conduct comprehensive analyses and provide key findings for future research.",
            "year": 2023,
            "citationCount": 6,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Causal Knowledge Extraction from Language Models (CaKE-LM) is proposed, leveraging causal commonsense knowledge from language models to tackle CVidQA, and significantly outperforms conventional methods by 4% to 6% of zero-shot CVidZA accuracy on NExT-QA and Causal-Vid QA datasets."
            },
            "score": 3
        },
        {
            "id": "80ce53797207cfef954a5af495dfcc9ce5650c44",
            "paperId": "80ce53797207cfef954a5af495dfcc9ce5650c44",
            "title": "Large Language Models guided Generative Prompt for Dialogue Generation",
            "abstract": "The applications of large language models (LLMs) such as ChatGPT exhibit impressive comprehension and generative capabilities in dialogue task. LLMs require massive high-quality data and computational cost, which limits their application to low-resource tasks. Dialogue generation when using smaller language models like GPT-2 encounters difficulties in maintaining context consistency. To address the problem of dialogue generation under resource constraints, we propose an LLM-guided Generative Prompt method (LGP). LGP enhances the relevance and coherence of generated dialogues through a smaller model GPT-2 and generative prompt (GP). GP is produced by the proposed Prompt Network, which leverages prompt encoder to learn dialogue history features and utilizes LSTM to extract contextual temporal features. Therefore, GP shown as the simple fixed-length learnable embeddings can replace the original complex and redundant context in GPT-2. The few-shot training of GP is guided by the LLM\u2019s responses, which facilitates GPT-2 in generating more contextually consistent and comprehensive responses. Experiments on the DailyDialog and MultiWOZ datasets show that LGP achieves high improvements in BLEU, NIST, METEOR and ROUGE-L metrics. Remarkably, LGP achieves these results with approximately 18% of the training data, surpassing other full-data-finetuning methods in automatic evaluation metrics.",
            "year": 2023,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "LGP enhances the relevance and coherence of generated dialogues through a smaller model GPT-2 and generative prompt and achieves high improvements in BLEU, NIST, METEOR and ROUGE-L metrics."
            },
            "score": 3
        },
        {
            "id": "866d5f8b1c70f9cf32993ee525dca5002436fffe",
            "paperId": "866d5f8b1c70f9cf32993ee525dca5002436fffe",
            "title": "Multi-modal Prompting for Low-Shot Temporal Action Localization",
            "abstract": "In this paper, we consider the problem of temporal action localization under low-shot (zero-shot&few-shot) scenario, with the goal of detecting and classifying the action instances from arbitrary categories within some untrimmed videos, even not seen at training time. We adopt a Transformer-based two-stage action localization architecture with class-agnostic action proposal, followed by open-vocabulary classification. We make the following contributions. First, to compensate image-text foundation models with temporal motions, we improve category-agnostic action proposal by explicitly aligning embeddings of optical flows, RGB and texts, which has largely been ignored in existing low-shot methods. Second, to improve open-vocabulary action classification, we construct classifiers with strong discriminative power, i.e., avoid lexical ambiguities. To be specific, we propose to prompt the pre-trained CLIP text encoder either with detailed action descriptions (acquired from large-scale language models), or visually-conditioned instance-specific prompt vectors. Third, we conduct thorough experiments and ablation studies on THUMOS14 and ActivityNet1.3, demonstrating the superior performance of our proposed model, outperforming existing state-of-the-art approaches by one significant margin.",
            "year": 2023,
            "citationCount": 8,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper adopts a Transformer-based two-stage action localization architecture with class-agnostic action proposal, followed by open-vocabulary classification, and proposes to prompt the pre-trained CLIP text encoder either with detailed action descriptions, or visually-conditioned instance-specific prompt vectors."
            },
            "score": 3
        },
        {
            "id": "bb4516ad6eb7adda97d81f09d4bb92b3ad056c42",
            "paperId": "bb4516ad6eb7adda97d81f09d4bb92b3ad056c42",
            "title": "Large Language Models are Temporal and Causal Reasoners for Video Question Answering",
            "abstract": "Large Language Models (LLMs) have shown remarkable performances on a wide range of natural language understanding and generation tasks. We observe that the LLMs provide effective priors in exploiting $\\textit{linguistic shortcuts}$ for temporal and causal reasoning in Video Question Answering (VideoQA). However, such priors often cause suboptimal results on VideoQA by leading the model to over-rely on questions, $\\textit{i.e.}$, $\\textit{linguistic bias}$, while ignoring visual content. This is also known as `ungrounded guesses' or `hallucinations'. To address this problem while leveraging LLMs' prior on VideoQA, we propose a novel framework, Flipped-VQA, encouraging the model to predict all the combinations of $\\langle$V, Q, A$\\rangle$ triplet by flipping the source pair and the target label to understand their complex relationships, $\\textit{i.e.}$, predict A, Q, and V given a VQ, VA, and QA pairs, respectively. In this paper, we develop LLaMA-VQA by applying Flipped-VQA to LLaMA, and it outperforms both LLMs-based and non-LLMs-based models on five challenging VideoQA benchmarks. Furthermore, our Flipped-VQA is a general framework that is applicable to various LLMs (OPT and GPT-J) and consistently improves their performances. We empirically demonstrate that Flipped-VQA not only enhances the exploitation of linguistic shortcuts but also mitigates the linguistic bias, which causes incorrect answers over-relying on the question. Code is available at https://github.com/mlvlab/Flipped-VQA.",
            "year": 2023,
            "citationCount": 10,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "LLaMA-VQA is developed by applying Flipped-V QA to LLaMA, and it outperforms both LLMs- based and non-LLMs-based models on five challenging VideoQA benchmarks."
            },
            "score": 3
        },
        {
            "id": "fcf1da955e1e0831727b1bf9c791c3971535aa35",
            "paperId": "fcf1da955e1e0831727b1bf9c791c3971535aa35",
            "title": "Conformal Temporal Logic Planning using Large Language Models: Knowing When to Do What and When to Ask for Help",
            "abstract": "This paper addresses a new motion planning problem for mobile robots tasked with accomplishing multiple high-level sub-tasks, expressed using natural language (NL). These sub-tasks should be accomplished in a temporal and logical order. To formally define the overarching mission, we leverage Linear Temporal Logic (LTL) defined over atomic predicates modeling these NL-based sub-tasks. This is in contrast to related planning approaches that define LTL tasks over atomic predicates capturing desired low-level system configurations. Our goal is to design robot plans that satisfy LTL tasks defined over NL-based atomic propositions. A novel technical challenge arising in this setup lies in reasoning about correctness of a robot plan with respect to such LTL-encoded tasks. To address this problem, we propose HERACLEs, a hierarchical conformal natural language planner, that relies on (i) automata theory to determine what NL-specified sub-tasks should be accomplished next to make mission progress; (ii) Large Language Models to design robot plans satisfying these sub-tasks; and (iii) conformal prediction to reason probabilistically about correctness of the designed plans and to determine if external assistance is required. We provide theoretical probabilistic mission satisfaction guarantees as well as extensive comparative experiments on mobile manipulation tasks.",
            "year": 2023,
            "citationCount": 7,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "HerACLEs is proposed, a hierarchical conformal natural language planner that relies on automata theory to determine what NL-specified sub-tasks should be accomplished next to make mission progress and theoretical probabilistic mission satisfaction guarantees."
            },
            "score": 3
        },
        {
            "id": "237bfa636f1a575f4784d2ae81a47ac29fa38522",
            "paperId": "237bfa636f1a575f4784d2ae81a47ac29fa38522",
            "title": "Momentor: Advancing Video Large Language Model with Fine-Grained Temporal Reasoning",
            "abstract": "Large Language Models (LLMs) demonstrate remarkable proficiency in comprehending and handling text-based tasks. Many efforts are being made to transfer these attributes to video modality, which are termed Video-LLMs. However, existing Video-LLMs can only capture the coarse-grained semantics and are unable to effectively handle tasks related to comprehension or localization of specific video segments. In light of these challenges, we propose Momentor, a Video-LLM capable of accomplishing fine-grained temporal understanding tasks. To support the training of Momentor, we design an automatic data generation engine to construct Moment-10M, a large-scale video instruction dataset with segment-level instruction data. We train Momentor on Moment-10M, enabling it to perform segment-level reasoning and localization. Zero-shot evaluations on several tasks demonstrate that Momentor excels in fine-grained temporally grounded comprehension and localization.",
            "year": 2024,
            "citationCount": 2,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The proposed Momentor, a Video-LLM capable of accomplishing fine-grained temporal understanding tasks, is designed and trained on Moment-10M, a large-scale video instruction dataset with segment-level instruction data, enabling it to perform segment-level reasoning and localization."
            },
            "score": 3
        },
        {
            "id": "02791e807dc9a91f854a1f3d5f6005122a546109",
            "paperId": "02791e807dc9a91f854a1f3d5f6005122a546109",
            "title": "Object-based attention for spatio-temporal reasoning: Outperforming neuro-symbolic models with flexible distributed architectures",
            "abstract": "Neural networks have achieved success in a wide array of perceptual tasks, but it is often stated that they are incapable of solving tasks that require higher-level reasoning. Two new task domains, CLEVRER and CATER, have recently been developed to focus on reasoning, as opposed to perception, in the context of spatio-temporal interactions between objects. Initial experiments on these domains found that neuro-symbolic approaches, which couple a logic engine and language parser with a neural perceptual front-end, substantially outperform fully-learned distributed networks, a finding that was taken to support the above thesis. Here, we show on the contrary that a fully-learned neural network with the right inductive biases can perform substantially better than all previous neural-symbolic models on both of these tasks, particularly on questions that most emphasize reasoning over perception. Our model makes critical use of both self-attention and learned \"soft\" object-centric representations, as well as BERT-style semi-supervised predictive losses. These flexible biases allow our model to surpass the previous neuro-symbolic state-of-the-art using less than 60% of available labelled data. Together, these results refute the neuro-symbolic thesis laid out by previous work involving these datasets, and they provide evidence that neural networks can indeed learn to reason effectively about the causal, dynamic structure of physical events.",
            "year": 2020,
            "citationCount": 29,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "It is shown that a fully-learned neural network with the right inductive biases can perform substantially better than all previous neural-symbolic models on both of these tasks, particularly on questions that most emphasize reasoning over perception."
            },
            "score": 3
        },
        {
            "id": "33864bf364ab17b231054f5d8a199bc5d2225918",
            "paperId": "33864bf364ab17b231054f5d8a199bc5d2225918",
            "title": "TaskLAMA: Probing the Complex Task Understanding of Language Models",
            "abstract": "Structured Complex Task Decomposition (SCTD) is the problem of breaking down a complex real-world task (such as planning a wedding) into a directed acyclic graph over individual steps that contribute to achieving the task, with edges specifying temporal dependencies between steps. SCTD is an important component of assistive planning tools, and a challenge for commonsense reasoning systems. We probe how accurately SCTD can be done with the knowledge extracted from pre-trained Large Language Models (LLMs). We introduce a new high-quality human-annotated dataset for this problem and novel metrics to fairly assess performance of LLMs against several baselines. Our experiments reveal that LLMs are able to decompose complex tasks into individual steps effectively, with a relative improvement of 15% to 280% over the best baseline. We also propose a number of approaches to further improve their performance, with a relative improvement of 7% to 37%. However, we find that LLMs still struggle to predict pairwise temporal dependencies, which reveals a gap in their understanding of complex tasks.",
            "year": 2023,
            "citationCount": 3,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work introduces a new high-quality human-annotated dataset for this problem and novel metrics to fairly assess performance of LLMs against several baselines, and finds that LLMs still struggle to predict pairwise temporal dependencies, which reveals a gap in their understanding of complex tasks."
            },
            "score": 3
        },
        {
            "id": "05bcf9999525656cfaa59bc71f8572d771ff3776",
            "paperId": "05bcf9999525656cfaa59bc71f8572d771ff3776",
            "title": "Language Models Can See: Plugging Visual Controls in Text Generation",
            "abstract": "Generative language models (LMs) such as GPT-2/3 can be prompted to generate text with remarkable quality. While they are designed for text-prompted generation, it remains an open question how the generation process could be guided by modalities beyond text such as images. In this work, we propose a training-free framework, called MAGIC (iMAge-Guided text generatIon with CLIP), for plugging in visual controls in the generation process and enabling LMs to perform multimodal tasks (e.g., image captioning) in a zero-shot manner. MAGIC is a simple yet efficient plug-and-play framework, which directly combines an off-the-shelf LM (i.e., GPT-2) and an image-text matching model (i.e., CLIP) for image-grounded text generation. During decoding, MAGIC influences the generation of the LM by introducing a CLIP-induced score, called magic score, which regularizes the generated result to be semantically related to a given image while being coherent to the previously generated context. Notably, the proposed decoding scheme does not involve any gradient update operation, therefore being computationally efficient. On the challenging task of zero-shot image captioning, MAGIC outperforms the state-of-the-art method by notable margins with a nearly 27 times decoding speedup. MAGIC is a flexible framework and is theoretically compatible with any text generation tasks that incorporate image grounding. In the experiments, we showcase that it is also capable of performing visually grounded story generation given both an image and a text prompt.",
            "year": 2022,
            "citationCount": 72,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A training-free framework for plugging in visual controls in the generation process and enabling LMs to perform multimodal tasks (e.g., image captioning) in a zero-shot manner, which outperforms the state-of-the-art method by notable margins with a nearly 27 times decoding speedup."
            },
            "score": 3
        },
        {
            "id": "a1675f47125aa409525c5f759b5e6bcc1c8831aa",
            "paperId": "a1675f47125aa409525c5f759b5e6bcc1c8831aa",
            "title": "Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy",
            "abstract": "Large language models are powerful text processors and reasoners, but are still subject to limitations including outdated knowledge and hallucinations, which necessitates connecting them to the world. Retrieval-augmented large language models have raised extensive attention for grounding model generation on external knowledge. However, retrievers struggle to capture relevance, especially for queries with complex information needs. Recent work has proposed to improve relevance modeling by having large language models actively involved in retrieval, i.e., to improve retrieval with generation. In this paper, we show that strong performance can be achieved by a method we call Iter-RetGen, which synergizes retrieval and generation in an iterative manner. A model output shows what might be needed to finish a task, and thus provides an informative context for retrieving more relevant knowledge which in turn helps generate a better output in the next iteration. Compared with recent work which interleaves retrieval with generation when producing an output, Iter-RetGen processes all retrieved knowledge as a whole and largely preserves the flexibility in generation without structural constraints. We evaluate Iter-RetGen on multi-hop question answering, fact verification, and commonsense reasoning, and show that it can flexibly leverage parametric knowledge and non-parametric knowledge, and is superior to or competitive with state-of-the-art retrieval-augmented baselines while causing fewer overheads of retrieval and generation. We can further improve performance via generation-augmented retrieval adaptation.",
            "year": 2023,
            "citationCount": 42,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper shows that strong performance can be achieved by a method, called Iter-RetGen, which synergizes retrieval and generation in an iterative manner, and shows that it can flexibly leverage parametric knowledge and non-parametric knowledge, and is superior to or competitive with state-of-the-art retrieval-augmented baselines while causing fewer overheads of retrieval andgeneration."
            },
            "score": 3
        },
        {
            "id": "29f07e73b7aaa7e9e950c59710472c62316be74a",
            "paperId": "29f07e73b7aaa7e9e950c59710472c62316be74a",
            "title": "Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations",
            "abstract": "The collection and curation of high-quality training data is crucial for developing text classification models with superior performance, but it is often associated with significant costs and time investment. Researchers have recently explored using large language models (LLMs) to generate synthetic datasets as an alternative approach. However, the effectiveness of the LLM-generated synthetic data in supporting model training is inconsistent across different classification tasks. To better understand factors that moderate the effectiveness of the LLM-generated synthetic data, in this study, we look into how the performance of models trained on these synthetic data may vary with the subjectivity of classification. Our results indicate that subjectivity, at both the task level and instance level, is negatively associated with the performance of the model trained on synthetic data. We conclude by discussing the implications of our work on the potential and limitations of leveraging LLM for synthetic data generation.",
            "year": 2023,
            "citationCount": 4,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This study looks into how the performance of models trained on these synthetic data may vary with the subjectivity of classification, and indicates that subjectivity, at both the task level and instance level, is negatively associated with theperformance of the model trained on synthetic data."
            },
            "score": 3
        },
        {
            "id": "468d1e2d75a23fecaf96fe65d8b01ff35ea5d0bd",
            "paperId": "468d1e2d75a23fecaf96fe65d8b01ff35ea5d0bd",
            "title": "Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models",
            "abstract": "Multilingual large-scale Pretrained Language Models (PLMs) have been shown to store considerable amounts of factual knowledge, but large variations are observed across languages. With the ultimate goal of ensuring that users with different language backgrounds obtain consistent feedback from the same model, we study the cross-lingual consistency (CLC) of factual knowledge in various multilingual PLMs. To this end, we propose a Ranking-based Consistency (RankC) metric to evaluate knowledge consistency across languages independently from accuracy. Using this metric, we conduct an in-depth analysis of the determining factors for CLC, both at model level and at language-pair level. Among other results, we find that increasing model size leads to higher factual probing accuracy in most languages, but does not improve cross-lingual consistency. Finally, we conduct a case study on CLC when new factual associations are inserted in the PLMs via model editing. Results on a small sample of facts inserted in English reveal a clear pattern whereby the new piece of knowledge transfers only to languages with which English has a high RankC score.",
            "year": 2023,
            "citationCount": 11,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work proposes a Ranking-based Consistency (RankC) metric to evaluate knowledge consistency across languages independently from accuracy, and conducts an in-depth analysis of the determining factors for CLC, both at model level and at language-pair level."
            },
            "score": 3
        },
        {
            "id": "4ea413e5a21a743d68c92e7f169535d0543f6051",
            "paperId": "4ea413e5a21a743d68c92e7f169535d0543f6051",
            "title": "On Improving Summarization Factual Consistency from Natural Language Feedback",
            "abstract": "Despite the recent progress in language generation models, their outputs may not always meet user expectations. In this work, we study whether informational feedback in natural language can be leveraged to improve generation quality and user preference alignment. To this end, we consider factual consistency in summarization, the quality that the summary should only contain information supported by the input documents, as the user-expected preference. We collect a high-quality dataset, DeFacto, containing human demonstrations and informational natural language feedback consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary. Using our dataset, we study three natural language generation tasks: (1) editing a summary by following the human feedback, (2) generating human feedback for editing the original summary, and (3) revising the initial summary to correct factual errors by generating both the human feedback and edited summary. We show that DeFacto can provide factually consistent human-edited summaries and further insights into summarization factual consistency thanks to its informational natural language feedback. We further demonstrate that fine-tuned language models can leverage our dataset to improve the summary factual consistency, while large language models lack the zero-shot learning ability in our proposed tasks that require controllable text generation.",
            "year": 2022,
            "citationCount": 22,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "DeFacto can provide factually consistent human-edited summaries and further insights into summarization factual consistency thanks to its informational natural language feedback, and it is demonstrated that fine-tuned language models can leverage the dataset to improve the summary factual consistency."
            },
            "score": 3
        },
        {
            "id": "663d743272e9ab04f54d9105a3c3a3f6e22dd1dd",
            "paperId": "663d743272e9ab04f54d9105a3c3a3f6e22dd1dd",
            "title": "FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge",
            "abstract": "Evaluating the factual consistency of automatically generated summaries is essential for the progress and adoption of reliable summarization systems. Despite recent advances, existing factuality evaluation models are not robust, being especially prone to entity and relation errors in new domains. We propose FactKB, a simple new approach to factuality evaluation that is generalizable across domains, in particular with respect to entities and relations. FactKB is based on language models pretrained using facts extracted from external knowledge bases. We introduce three types of complementary factuality pretraining objectives based on direct entity facts, facts grounded in auxiliary knowledge about entities, and facts constructed compositionally through knowledge base walks. The resulting factuality evaluation model achieves state-of-the-art performance on two in-domain news summarization benchmarks as well as on three out-of-domain scientific literature datasets. Further analysis of FactKB shows improved ability to detect erroneous entities and relations in summaries and is robust and generalizable across domains.",
            "year": 2023,
            "citationCount": 24,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "FactKB is a simple new approach to factuality evaluation that is generalizable across domains, in particular with respect to entities and relations and shows improved ability to detect erroneous entities and relation in summaries."
            },
            "score": 3
        },
        {
            "id": "f5d581e916613838cbadc05ab8c35ee4ea78da32",
            "paperId": "f5d581e916613838cbadc05ab8c35ee4ea78da32",
            "title": "Fine-grained Factual Consistency Assessment for Abstractive Summarization Models",
            "abstract": "Factual inconsistencies existed in the output of abstractive summarization models with original documents are frequently presented. Fact consistency assessment requires the reasoning capability to find subtle clues to identify whether a model-generated summary is consistent with the original document. This paper proposes a fine-grained two-stage Fact Consistency assessment framework for Summarization models (SumFC). Given a document and a summary sentence, in the first stage, SumFC selects the top-K most relevant sentences with the summary sentence from the document. In the second stage, the model performs fine-grained consistency reasoning at the sentence level, and then aggregates all sentences\u2019 consistency scores to obtain the final assessment result. We get the training data pairs by data synthesis and adopt contrastive loss of data pairs to help the model identify subtle cues. Experiment results show that SumFC has made a significant improvement over the previous state-of-the-art methods. Our experiments also indicate that SumFC distinguishes detailed differences better.",
            "year": 2021,
            "citationCount": 5,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A fine-grained two-stage Fact Consistency assessment framework for Summarization models (SumFC), which selects the top-K most relevant sentences with the summary sentence from the document and aggregates all sentences\u2019 consistency scores to obtain the final assessment result."
            },
            "score": 3
        },
        {
            "id": "99ad11764421bfff6261c9df8526c8b5af82d794",
            "paperId": "99ad11764421bfff6261c9df8526c8b5af82d794",
            "title": "Improving Logical Consistency in Pre-Trained Language Models using Natural Language Inference",
            "abstract": "Current state-of-the-art pre-trained language models (PTLMs) contain rich and vast amounts of world knowledge, demonstrating an ability to extrapolate information from contextual texts and to accurately answer questions [1]. However, the latent factual understanding captured by PTLMs can be irrational and inconsistent, causing PTLMs to be prone to generating contradictory statements [2]. We demonstrate that natural language inference (NLI) can provide additional signal about contradictory statements output by a PTLM. We explore several approaches for aggregating the entailment and contradiction probabilities acquired through NLI on a batch of PTLM predicted answers and define a scoring heuristic that balances between the NLI output and the PTLM\u2019s confidence in its answers. Predictions whose scores are below a tuned threshold are revised before outputting final answers. In addition, we investigate methods for using these NLI probabilities to define a MaxSAT problem that, when optimized, yields corrected predictions. Our results demonstrate that a system that uses either of our approaches to revise PTLM answers has better accuracy and logical consistency than a vanilla PTLM.",
            "year": 2022,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "It is demonstrated that natural language inference (NLI) can provide additional signal about contradictory statements output by a PTLM and that a system that uses either of these approaches to revise PTLM answers has better accuracy and logical consistency than a vanilla PTLM."
            },
            "score": 3
        },
        {
            "id": "95a1305f252f53d5d7bed8cf9d9091d6dbdeb0ab",
            "paperId": "95a1305f252f53d5d7bed8cf9d9091d6dbdeb0ab",
            "title": "Upscale-A-Video: Temporal-Consistent Diffusion Model for Real-World Video Super-Resolution",
            "abstract": "Text-based diffusion models have exhibited remarkable success in generation and editing, showing great promise for enhancing visual content with their generative prior. However, applying these models to video super-resolution remains challenging due to the high demands for output fidelity and temporal consistency, which is complicated by the inherent randomness in diffusion models. Our study introduces Upscale-A-Video, a text-guided latent diffusion framework for video upscaling. This framework ensures temporal coherence through two key mechanisms: locally, it integrates temporal layers into U-Net and VAE-Decoder, maintaining consistency within short sequences; globally, without training, a flow-guided recurrent latent propagation module is introduced to enhance overall video stability by propagating and fusing latent across the entire sequences. Thanks to the diffusion paradigm, our model also offers greater flexibility by allowing text prompts to guide texture creation and adjustable noise levels to balance restoration and generation, enabling a trade-off between fidelity and quality. Extensive experiments show that Upscale-A-Video surpasses existing methods in both synthetic and real-world benchmarks, as well as in AI-generated videos, showcasing impressive visual realism and temporal consistency.",
            "year": 2023,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Upscale-A-Video is introduced, a text-guided latent diffusion framework for video upscaling that surpasses existing methods in both synthetic and real-world benchmarks, as well as in AI-generated videos, showcasing impressive visual realism and temporal consistency."
            },
            "score": 3
        },
        {
            "id": "d1f9b4bd75b758a736d5f83e52f5993e3a086f43",
            "paperId": "d1f9b4bd75b758a736d5f83e52f5993e3a086f43",
            "title": "Temporal organization in narratives texts of 8-11-years-olds",
            "abstract": "The present work focuses on the temporal organization of narratives written by pupils aged 8-11. In this paper, we analyze 180 texts produced by elementary school children (60 texts from pupils aged 8-9, 60 texts from pupils aged 9-10, 60 texts from pupils aged 10-11) in response to a common writing instruction prompt in which the beginning and end of the text are given. The different temporal movements (chronological succession, backward and forward movements) are cataloged, categorized, and analyzed. The study reveals, on the one hand, that all pupils, regardless of their grade level, integrate temporal movements in their texts. On the other hand, it shows that differences appear according to class level: as class level increases the different movements tend to develop with their own specificity conveying more thickness and coherence to the text.\u00a0",
            "year": 2023,
            "citationCount": 0,
            "tldr": null,
            "score": 3
        },
        {
            "id": "947bc6a61287e015c3f7237153bd56482da20037",
            "paperId": "947bc6a61287e015c3f7237153bd56482da20037",
            "title": "Spatial, Temporal, and Semantic Crime Analysis Using Information Extraction From Online News",
            "abstract": "Crime is a behavioral disorder with various scales that are intimately linked to a variety of circumstances such as spatial, temporal, sociological, and ecological aspects. The massive amounts of crime-related data, which is being published and grows with each passing day, in the form of online news reports have prompted researchers to pursue studies in the field of violence and criminal investigations. In this work, we developed a semantic approach to extract spatiotemporal and crime-related information from news reports to detect crime spatial distribution. The proposed method, in particular, aims to extract geographical and temporal information to detect regions with a high number of criminal cases, as well as to represent semantic knowledge of criminal incidents by annotating spatiotemporal information from their web domains. This approach incorporates the use of Natural Language Processing (NLP) techniques and a crime domain ontology into the information extraction process to automatically retrieve spatial, temporal, and other relevant information about criminal behavior from news reports. Our proposal consists of a comprehensive solution built on a fully functional architecture that has been tested in a use case scenario for the crime news reported in London, United Kingdom.",
            "year": 2022,
            "citationCount": 2,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This approach incorporates the use of Natural Language Processing (NLP) techniques and a crime domain ontology into the information extraction process to automatically retrieve spatial, temporal, and other relevant information about criminal behavior from news reports."
            },
            "score": 3
        },
        {
            "id": "d85118424790f6c6aed4f81db48a690f9f27b5d1",
            "paperId": "d85118424790f6c6aed4f81db48a690f9f27b5d1",
            "title": "Prompting Visual-Language Models for Dynamic Facial Expression Recognition",
            "abstract": "This paper presents a novel visual-language model called DFER-CLIP, which is based on the CLIP model and designed for in-the-wild Dynamic Facial Expression Recognition (DFER). Specifically, the proposed DFER-CLIP consists of a visual part and a textual part. For the visual part, based on the CLIP image encoder, a temporal model consisting of several Transformer encoders is introduced for extracting temporal facial expression features, and the final feature embedding is obtained as a learnable\"class\"token. For the textual part, we use as inputs textual descriptions of the facial behaviour that is related to the classes (facial expressions) that we are interested in recognising -- those descriptions are generated using large language models, like ChatGPT. This, in contrast to works that use only the class names and more accurately captures the relationship between them. Alongside the textual description, we introduce a learnable token which helps the model learn relevant context information for each expression during training. Extensive experiments demonstrate the effectiveness of the proposed method and show that our DFER-CLIP also achieves state-of-the-art results compared with the current supervised DFER methods on the DFEW, FERV39k, and MAFW benchmarks. Code is publicly available at https://github.com/zengqunzhao/DFER-CLIP.",
            "year": 2023,
            "citationCount": 5,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper presents a novel visual-language model called DFER-CLIP, which is based on the CLIP model and designed for in-the-wild Dynamic Facial Expression Recognition (DFER), and introduces a learnable token which helps the model learn relevant context information for each expression during training."
            },
            "score": 2
        },
        {
            "id": "3aa200f562346a5e312767e5e9c1333a4f2c951b",
            "paperId": "3aa200f562346a5e312767e5e9c1333a4f2c951b",
            "title": "Large Language Models, scientific knowledge and factuality: A systematic analysis in antibiotic discovery",
            "abstract": "Inferring over and extracting information from Large Language Models (LLMs) trained on a large corpus of scientific literature can potentially drive a new era in biomedical research, reducing the barriers for accessing existing medical evidence. This work examines the potential of LLMs for dialoguing with biomedical background knowledge, using the context of antibiotic discovery. The systematic analysis is applied to ten state-of-the-art models, from models specialised on biomedical scientific corpora to general models such as ChatGPT, GPT-4 and Llama 2 in two prompting-based tasks: chemical compound definition generation and chemical compound-fungus relation determination. The work provides a systematic assessment on the ability of LLMs to encode and express these relations, verifying for fluency, prompt-alignment, semantic coherence, factual knowledge and specificity of generated responses. Results show that while recent models have improved in fluency, factual accuracy is still low and models are biased towards over-represented entities. The ability of LLMs to serve as biomedical knowledge bases is questioned, and the need for additional systematic evaluation frameworks is highlighted. The best performing GPT-4 produced a factual definition for 70% of chemical compounds and 43.6% factual relations to fungi, whereas the best open source model BioGPT-large 30% of the compounds and 30% of the relations for the best-performing prompt. The results show that while LLMs are currently not fit for purpose to be used as biomedical factual knowledge bases, there is a promising emerging property in the direction of factuality as the models become domain specialised, scale-up in size and level of human feedback.",
            "year": 2023,
            "citationCount": 5,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work examines the potential of LLMs for dialoguing with biomedical background knowledge, using the context of antibiotic discovery, and shows a promising emerging property in the direction of factuality as the models become domain specialised, scale-up in size and level of human feedback."
            },
            "score": 2
        },
        {
            "id": "1e6345a73372f593a0bab78e66ee6c98a44feaed",
            "paperId": "1e6345a73372f593a0bab78e66ee6c98a44feaed",
            "title": "EventNarrative: A large-scale Event-centric Dataset for Knowledge Graph-to-Text Generation",
            "abstract": "We introduce EventNarrative, a knowledge graph-to-text dataset from publicly available open-world knowledge graphs. Given the recent advances in event-driven Information Extraction (IE), and that prior research on graph-to-text only focused on entity-driven KGs, this paper focuses on event-centric data. However, our data generation system can still be adapted to other other types of KG data. Existing large-scale datasets in the graph-to-text area are non-parallel, meaning there is a large disconnect between the KGs and text. The datasets that have a paired KG and text, are small scale and manually generated or generated without a rich ontology, making the corresponding graphs sparse. Furthermore, these datasets contain many unlinked entities between their KG and text pairs. EventNarrative consists of approximately 230,000 graphs and their corresponding natural language text, 6 times larger than the current largest parallel dataset. It makes use of a rich ontology, all of the KGs entities are linked to the text, and our manual annotations confirm a high data quality. Our aim is two-fold: help break new ground in event-centric research where data is lacking, and to give researchers a well-defined, large-scale dataset in order to better evaluate existing and future knowledge graph-to-text models. We also evaluate two types of baseline on EventNarrative: a graph-to-text specific model and two state-of-the-art language models, which previous work has shown to be adaptable to the knowledge graph-to-text domain.",
            "year": 2021,
            "citationCount": 15,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The aim of this paper is to help break new ground in event-centric research where data is lacking, and to give researchers a well-defined, large-scale dataset in order to better evaluate existing and future knowledge graph-to-text models."
            },
            "score": 2
        },
        {
            "id": "0269664dbaebc427b1a0860526f5ea3aac811e31",
            "paperId": "0269664dbaebc427b1a0860526f5ea3aac811e31",
            "title": "ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models",
            "abstract": "Data-to-text generation is challenging due to the great variety of the input data in terms of domains (e.g., finance vs sports) or schemata (e.g., diverse predicates). Recent end-to-end neural methods thus require substantial training examples to learn to disambiguate and describe the data. Yet, real-world data-to-text problems often suffer from various data-scarce issues: one may have access to only a handful of or no training examples, and/or have to rely on examples in a different domain or schema. To fill this gap, we propose Any-Shot Data-to-Text (ASDOT), a new approach flexibly applicable to diverse settings by making efficient use of any given (or no) examples. ASDOT consists of two steps, data disambiguation and sentence fusion, both of which are amenable to be solved with off-the-shelf pretrained language models (LMs) with optional finetuning. In the data disambiguation stage, we employ the prompted GPT-3 model to understand possibly ambiguous triples from the input data and convert each into a short sentence with reduced ambiguity. The sentence fusion stage then uses an LM like T5 to fuse all the resulting sentences into a coherent paragraph as the final description. We evaluate extensively on various datasets in different scenarios, including the zero-/few-/full-shot settings, and generalization to unseen predicates and out-of-domain data. Experimental results show that ASDOT consistently achieves significant improvement over baselines, e.g., a 30.81 BLEU gain on the DART dataset under the zero-shot setting.",
            "year": 2022,
            "citationCount": 12,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Any-Shot Data-to-Text (ASDOT) is proposed, a new approach flexibly applicable to diverse settings by making efficient use of any given (or no) examples, which is amenable to be solved with off-the-shelf pretrained language models (LMs) with optional finetuning."
            },
            "score": 2
        },
        {
            "id": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb",
            "paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb",
            "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models",
            "abstract": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models. This paper proposes BLIP-2, a generic and efficient pre-training strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pre-trained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
            "year": 2023,
            "citationCount": 1580,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods, and is demonstrated's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions."
            },
            "score": 2
        },
        {
            "id": "de3e8a9bf62bfe52adcfea026393d9fc4c6e16c6",
            "paperId": "de3e8a9bf62bfe52adcfea026393d9fc4c6e16c6",
            "title": "TextBox 2.0: A Text Generation Library with Pre-trained Language Models",
            "abstract": "To facilitate research on text generation, this paper presents a comprehensive and unified library, TextBox 2.0, focusing on the use of pre-trained language models (PLMs). To be comprehensive, our library covers $13$ common text generation tasks and their corresponding $83$ datasets and further incorporates $45$ PLMs covering general, translation, Chinese, dialogue, controllable, distilled, prompting, and lightweight PLMs. We also implement $4$ efficient training strategies and provide $4$ generation objectives for pre-training new PLMs from scratch. To be unified, we design the interfaces to support the entire research pipeline (from data loading to training and evaluation), ensuring that each step can be fulfilled in a unified way. Despite the rich functionality, it is easy to use our library, either through the friendly Python API or command line. To validate the effectiveness of our library, we conduct extensive experiments and exemplify four types of research scenarios. The project is released at the link: https://github.com/RUCAIBox/TextBox.",
            "year": 2022,
            "citationCount": 5,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper presents a comprehensive and unified library, TextBox 2.0, focusing on the use of pre-trained language models (PLMs), and designs the interfaces to support the entire research pipeline (from data loading to training and evaluation), ensuring that each step can be fulfilled in a unified way."
            },
            "score": 2
        },
        {
            "id": "ca6a2bc279be5a3349a22bfd6866ed633d18734b",
            "paperId": "ca6a2bc279be5a3349a22bfd6866ed633d18734b",
            "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models",
            "abstract": "The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images. These features are rarely observed in previous vision-language models. However, the technical details behind GPT-4 continue to remain undisclosed. We believe that the enhanced multi-modal generation capabilities of GPT-4 stem from the utilization of sophisticated large language models (LLM). To examine this phenomenon, we present MiniGPT-4, which aligns a frozen visual encoder with a frozen advanced LLM, Vicuna, using one projection layer. Our work, for the first time, uncovers that properly aligning the visual features with an advanced large language model can possess numerous advanced multi-modal abilities demonstrated by GPT-4, such as detailed image description generation and website creation from hand-drawn drafts. Furthermore, we also observe other emerging capabilities in MiniGPT-4, including writing stories and poems inspired by given images, teaching users how to cook based on food photos, and so on. In our experiment, we found that the model trained on short image caption pairs could produce unnatural language outputs (e.g., repetition and fragmentation). To address this problem, we curate a detailed image description dataset in the second stage to finetune the model, which consequently improves the model's generation reliability and overall usability. Our code, pre-trained model, and collected dataset are available at https://minigpt-4.github.io/.",
            "year": 2023,
            "citationCount": 790,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "MiniGPT-4 is presented, which aligns a frozen visual encoder with a frozen advanced LLM, Vicuna, using one projection layer to uncovers that properly aligning the visual features with an advanced large language model can possess numerous advanced multi-modal abilities demonstrated by G PT-4."
            },
            "score": 2
        },
        {
            "id": "43bab902791fc844d80b005e2c54bbbbe9e64f26",
            "paperId": "43bab902791fc844d80b005e2c54bbbbe9e64f26",
            "title": "Structural Adapters in Pretrained Language Models for AMR-to-Text Generation",
            "abstract": "Pretrained language models (PLM) have recently advanced graph-to-text generation, where the input graph is linearized into a sequence and fed into the PLM to obtain its representation. However, efficiently encoding the graph structure in PLMs is challenging because such models were pretrained on natural language, and modeling structured data may lead to catastrophic forgetting of distributional knowledge. In this paper, we propose StructAdapt, an adapter method to encode graph structure into PLMs. Contrary to prior work, StructAdapt effectively models interactions among the nodes based on the graph connectivity, only training graph structure-aware adapter parameters. In this way, we incorporate task-specific knowledge while maintaining the topological structure of the graph. We empirically show the benefits of explicitly encoding graph structure into PLMs using StructAdapt, outperforming the state of the art on two AMR-to-text datasets, training only 5.1% of the PLM parameters.",
            "year": 2021,
            "citationCount": 56,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The benefits of explicitly encoding graph structure into PLMs using StructAdapt are empirically shown, outperforming the state of the art on two AMR-to-text datasets, training only 5.1% of the PLM parameters."
            },
            "score": 2
        },
        {
            "id": "7e32aac43e9f1df49e116add03327ee6f365dbf3",
            "paperId": "7e32aac43e9f1df49e116add03327ee6f365dbf3",
            "title": "mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality",
            "abstract": "Large language models (LLMs) have demonstrated impressive zero-shot abilities on a variety of open-ended tasks, while recent research has also explored the use of LLMs for multi-modal generation. In this study, we introduce mPLUG-Owl, a novel training paradigm that equips LLMs with multi-modal abilities through modularized learning of foundation LLM, a visual knowledge module, and a visual abstractor module. This approach can support multiple modalities and facilitate diverse unimodal and multimodal abilities through modality collaboration. The training paradigm of mPLUG-Owl involves a two-stage method for aligning image and text, which learns visual knowledge with the assistance of LLM while maintaining and even improving the generation abilities of LLM. In the first stage, the visual knowledge module and abstractor module are trained with a frozen LLM module to align the image and text. In the second stage, language-only and multi-modal supervised datasets are used to jointly fine-tune a low-rank adaption (LoRA) module on LLM and the abstractor module by freezing the visual knowledge module. We carefully build a visually-related instruction evaluation set OwlEval. Experimental results show that our model outperforms existing multi-modal models, demonstrating mPLUG-Owl's impressive instruction and visual understanding ability, multi-turn conversation ability, and knowledge reasoning ability. Besides, we observe some unexpected and exciting abilities such as multi-image correlation and scene text understanding, which makes it possible to leverage it for harder real scenarios, such as vision-only document comprehension. Our code, pre-trained model, instruction-tuned models, and evaluation set are available at https://github.com/X-PLUG/mPLUG-Owl. The online demo is available at https://www.modelscope.cn/studios/damo/mPLUG-Owl.",
            "year": 2023,
            "citationCount": 419,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": null
            },
            "score": 2
        },
        {
            "id": "19af8292ff3cc10aad6f190490f0d34691658179",
            "paperId": "19af8292ff3cc10aad6f190490f0d34691658179",
            "title": "Investigating Pretrained Language Models for Graph-to-Text Generation",
            "abstract": "Graph-to-text generation aims to generate fluent texts from graph-based data. In this paper, we investigate two recent pretrained language models (PLMs) and analyze the impact of different task-adaptive pretraining strategies for PLMs in graph-to-text generation. We present a study across three graph domains: meaning representations, Wikipedia knowledge graphs (KGs) and scientific KGs. We show that approaches based on PLMs BART and T5 achieve new state-of-the-art results and that task-adaptive pretraining strategies improve their performance even further. We report new state-of-the-art BLEU scores of 49.72 on AMR-LDC2017T10, 59.70 on WebNLG, and 25.66 on AGENDA datasets - a relative improvement of 31.8%, 4.5%, and 42.4%, respectively, with our models generating significantly more fluent texts than human references. In an extensive analysis, we identify possible reasons for the PLMs\u2019 success on graph-to-text tasks. Our findings suggest that the PLMs benefit from similar facts seen during pretraining or fine-tuning, such that they perform well even when the input graph is reduced to a simple bag of node and edge labels.",
            "year": 2020,
            "citationCount": 183,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "It is suggested that the PLMs benefit from similar facts seen during pretraining or fine-tuning, such that they perform well even when the input graph is reduced to a simple bag of node and edge labels."
            },
            "score": 2
        },
        {
            "id": "3b6179c293df29e31d31cea46476f104ab6950f2",
            "paperId": "3b6179c293df29e31d31cea46476f104ab6950f2",
            "title": "Kosmos-2: Grounding Multimodal Large Language Models to the World",
            "abstract": "We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling new capabilities of perceiving object descriptions (e.g., bounding boxes) and grounding text to the visual world. Specifically, we represent refer expressions as links in Markdown, i.e., ``[text span](bounding boxes)'', where object descriptions are sequences of location tokens. Together with multimodal corpora, we construct large-scale data of grounded image-text pairs (called GrIT) to train the model. In addition to the existing capabilities of MLLMs (e.g., perceiving general modalities, following instructions, and performing in-context learning), Kosmos-2 integrates the grounding capability into downstream applications. We evaluate Kosmos-2 on a wide range of tasks, including (i) multimodal grounding, such as referring expression comprehension, and phrase grounding, (ii) multimodal referring, such as referring expression generation, (iii) perception-language tasks, and (iv) language understanding and generation. This work lays out the foundation for the development of Embodiment AI and sheds light on the big convergence of language, multimodal perception, action, and world modeling, which is a key step toward artificial general intelligence. Code and pretrained models are available at https://aka.ms/kosmos-2.",
            "year": 2023,
            "citationCount": 271,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Kosmos-2, a Multimodal Large Language Model (MLLM), is introduced, enabling new capabilities of perceiving object descriptions and grounding text to the visual world and sheds light on the big convergence of language, multimodal perception, action, and world modeling."
            },
            "score": 2
        },
        {
            "id": "69144d537f90f214d5b07a7c79121d16afd7da16",
            "paperId": "69144d537f90f214d5b07a7c79121d16afd7da16",
            "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
            "abstract": "Recently, diffusion models have emerged as a new paradigm for generative models. Despite the success in domains using continuous signals such as vision and audio, adapting diffusion models to natural language is under-explored due to the discrete nature of texts, especially for conditional generation. We tackle this challenge by proposing DiffuSeq: a diffusion model designed for sequence-to-sequence (Seq2Seq) text generation tasks. Upon extensive evaluation over a wide range of Seq2Seq tasks, we find DiffuSeq achieving comparable or even better performance than six established baselines, including a state-of-the-art model that is based on pre-trained language models. Apart from quality, an intriguing property of DiffuSeq is its high diversity during generation, which is desired in many Seq2Seq tasks. We further include a theoretical analysis revealing the connection between DiffuSeq and autoregressive/non-autoregressive models. Bringing together theoretical analysis and empirical evidence, we demonstrate the great potential of diffusion models in complex conditional language generation tasks. Code is available at \\url{https://github.com/Shark-NLP/DiffuSeq}",
            "year": 2022,
            "citationCount": 171,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Upon extensive evaluation over a wide range of Seq2Seq tasks, DiffuSeq is found achieving comparable or even better performance than six established baselines, including a state-of-the-art model that is based on pre-trained language models."
            },
            "score": 2
        },
        {
            "id": "f70bf522a90c09ed06c32c9bf36b7ee14b8a9856",
            "paperId": "f70bf522a90c09ed06c32c9bf36b7ee14b8a9856",
            "title": "Knowledge Graph-Augmented Language Models for Knowledge-Grounded Dialogue Generation",
            "abstract": "Language models have achieved impressive performances on dialogue generation tasks. However, when generating responses for a conversation that requires factual knowledge, they are far from perfect, due to an absence of mechanisms to retrieve, encode, and reflect the knowledge in the generated responses. Some knowledge-grounded dialogue generation methods tackle this problem by leveraging facts from Knowledge Graphs (KGs); however, they do not guarantee that the model utilizes a relevant piece of knowledge from the KG. To overcome this limitation, we propose SUbgraph Retrieval-augmented GEneration (SURGE), a framework for generating context-relevant and knowledge-grounded dialogues with the KG. Specifically, our SURGE framework first retrieves the relevant subgraph from the KG, and then enforces consistency across facts by perturbing their word embeddings conditioned by the retrieved subgraph. Then, we utilize contrastive learning to ensure that the generated texts have high similarity to the retrieved subgraphs. We validate our SURGE framework on OpendialKG and KOMODIS datasets, showing that it generates high-quality dialogues that faithfully reflect the knowledge from KG.",
            "year": 2023,
            "citationCount": 15,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The proposed SUbgraph Retrieval-augmented GEneration (SURGE), a framework for generating context-relevant and knowledge-grounded dialogues with the KG, first retrieves the relevant subgraph from the KGs, and then enforces consistency across facts by perturbing their word embeddings conditioned by the retrieved subgraph."
            },
            "score": 2
        },
        {
            "id": "d530d3af727d8d9ff32849c0c13a20f9b1dfd583",
            "paperId": "d530d3af727d8d9ff32849c0c13a20f9b1dfd583",
            "title": "Performance in an Audiovisual Selective Attention Task Using Speech-Like Stimuli Depends on the Talker Identities, But Not Temporal Coherence",
            "abstract": "Audiovisual integration of speech can benefit the listener by not only improving comprehension of what a talker is saying but also helping a listener select a particular talker's voice from a mixture of sounds. Binding, an early integration of auditory and visual streams that helps an observer allocate attention to a combined audiovisual object, is likely involved in processing audiovisual speech. Although temporal coherence of stimulus features across sensory modalities has been implicated as an important cue for non-speech stimuli (Maddox et al., 2015), the specific cues that drive binding in speech are not fully understood due to the challenges of studying binding in natural stimuli. Here we used speech-like artificial stimuli that allowed us to isolate three potential contributors to binding: temporal coherence (are the face and the voice changing synchronously?), articulatory correspondence (do visual faces represent the correct phones?), and talker congruence (do the face and voice come from the same person?). In a trio of experiments, we examined the relative contributions of each of these cues. Normal hearing listeners performed a dual task in which they were instructed to respond to events in a target auditory stream while ignoring events in a distractor auditory stream (auditory discrimination) and detecting flashes in a visual stream (visual detection). We found that viewing the face of a talker who matched the attended voice (i.e., talker congruence) offered a performance benefit. We found no effect of temporal coherence on performance in this task, prompting an important recontextualization of previous findings.",
            "year": 2023,
            "citationCount": 0,
            "tldr": null,
            "score": 2
        },
        {
            "id": "f7665a18cfe08b539318b0798b6cea9579e62d28",
            "paperId": "f7665a18cfe08b539318b0798b6cea9579e62d28",
            "title": "Humans rely more on talker identity than temporal coherence in an audiovisual selective attention task using speech-like stimuli",
            "abstract": "Audiovisual integration of speech can benefit the listener by not only improving comprehension of what a talker is saying but also helping a listener pick a particular talker\u2019s voice out of a mix of sounds. Binding, an early integration of auditory and visual streams that helps an observer allocate attention to a combined audiovisual object, is likely involved in audiovisual speech processing. Although temporal coherence of stimulus features across sensory modalities has been implicated as an important cue for non-speech stimuli (Maddox et al., 2015), the specific cues that drive binding in speech are not fully understood due to the challenges of studying binding in natural stimuli. Here we used speech-like artificial stimuli that allowed us to isolate three potential contributors to binding: temporal coherence (are the face and the voice changing synchronously?), articulatory correspondence (do visual faces represent the correct phones?), and talker congruence (do the face and voice come from the same person?). In a trio of experiments, we examined the relative contributions of each of these cues. Normal hearing listeners performed a dual detection task in which they were instructed to respond to events in a target auditory stream and a visual stream while ignoring events in a distractor auditory stream. We found that viewing the face of a talker who matched the attended voice (i.e., talker congruence) offered a performance benefit. Importantly, we found no effect of temporal coherence on performance in this task, a result that prompts an important recontextualization of previous findings.",
            "year": 2022,
            "citationCount": 1,
            "tldr": null,
            "score": 2
        },
        {
            "id": "ea8a8265fc6083d9abf225581d1ae2ecfff6a8b4",
            "paperId": "ea8a8265fc6083d9abf225581d1ae2ecfff6a8b4",
            "title": "Automated Subjective Answer Evaluation Using NLP",
            "abstract": ": This study has been undertaken to investigate the determinants of Natural Language Processing (NLP) is one of the important issues of concern in giving computers the ability to understand text and speech in much the same way human beings can. NLP can be used in subjective answer evaluation in various ways. One of the most common approaches is to use NLP techniques to automatically score the quality of a written response based on its language features, such as grammar, syntax, vocabulary, and coherence. This can be done by training machine learning algorithms on a large dataset of human-scored essays or short answer responses, using the language features mentioned above as input features, and the corresponding scores as target values. The trained model can then be used to automatically score new responses based on their language features. Another approach is to use NLP techniques to analyze the content and structure of the response, in order to identify key concepts and arguments and assess their relevance and coherence with the question prompt. This can be done by using techniques such as topic modelling, sentiment analysis, and text classification. Overall, NLP can be a powerful tool for subjective answer evaluation, as it can help to improve the efficiency and consistency of the grading process, while also providing valuable insights into the language and reasoning skills of the students.",
            "year": 2023,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Natural Language Processing can be a powerful tool for subjective answer evaluation, as it can help to improve the efficiency and consistency of the grading process, while also providing valuable insights into the language and reasoning skills of the students."
            },
            "score": 2
        },
        {
            "id": "d7611093735a6d9e1a461be73859c6f6807a4be7",
            "paperId": "d7611093735a6d9e1a461be73859c6f6807a4be7",
            "title": "EEG coherence and power spectra during REM sleep related to melatonin intake in mild-to-moderate Alzheimer\u2019s disease: a pilot study",
            "abstract": "Abstract \n Introduction:\n It has been reported that melatonin diminishes rapid eye movement (REM) sleep latency in patients with Alzheimer\u2019s disease (AD). Pharmacological studies suggest that melatonin promotes prompt sleep installation through interaction with GABA receptors, and that it is associated with acute suppression of neural electrical activity. Nevertheless, melatonin\u2019s effects on electroencephalographic (EEG) activity related to REM sleep onset in AD patients have not been analyzed. Thus, in this pilot study we analyzed the effects of melatonin on EEG activity during the first episode of REM sleep in eight patients treated with 5-mg of fast-release melatonin. \n Methods:\n During a single-blind, placebo-controlled study, polysomnographic recordings were obtained from frontal, central, temporal, and occipital scalp derivations. REM sleep latency, as well as the relative power (RP) and EEG coherences of six EEG bands, were compared between the placebo and melatonin conditions. \n Results:\n Results showed that melatonin intake in AD patients decreased REM sleep onset, and that this was associated with lower RP and coherence of the \u03b2 and \u03b3 EEG bands. \n Discussion:\n The possibility that the inhibitory GABAergic pathways related to REM sleep generation are well-preserved in mild-to-moderate AD is discussed. We conclude that the short REM sleep onset related to melatonin intake in AD patients is associated with a significant decrease in both RP and EEG coherence, mainly in the fast frequencies.",
            "year": 2021,
            "citationCount": 3,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "It is concluded that the short REM sleep onset related to melatonin intake in AD patients is associated with a significant decrease in both RP and EEG coherence, mainly in the fast frequencies."
            },
            "score": 1
        },
        {
            "id": "bccdb70fe10a6011472c2efee511e6f59951330d",
            "paperId": "bccdb70fe10a6011472c2efee511e6f59951330d",
            "title": "Alport syndrome with bilateral simultaneous anterior and posterior lenticonus with severe temporal macular thinning",
            "abstract": "Alport syndrome (AS) is a hereditary disease with various modes of inheritance, X-linked being the the most common. Anterior lenticonus is the characteristic abnormality along with perimacular and peripheral fleck retinopathy. Our two cases of AS had simultaneous anterior and posterior lenticonus with severe temporal macular thinning on optical coherence tomography with no specific renal symptomatology and were diagnosed as AS without any invasive renal biopsy. First patient was a 19-year-old man who presented with compound myopia due to bilateral anterior and posterior lenticonus with perimacular fleck retinopathy and lozenge sign and bilateral moderate sensorineural hearing loss (SNHL). Second patient was a 24-year-old man who presented with difficulty in vision due to bilateral anterior and posterior lenticonus with bilateral severe SNHL. Our cases emphasise the crucial role of an ophthalmologist in diagnosing AS before the onset of renal symptoms and prompting further nephrological work-up in the patient or the carrier.",
            "year": 2019,
            "citationCount": 5,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Two cases of Alport syndrome with simultaneous anterior and posterior lenticonus with severe temporal macular thinning on optical coherence tomography with no specific renal symptomatology and diagnosed as AS without any invasive renal biopsy emphasise the crucial role of an ophthalmologist in diagnosing AS before the onset of renal symptoms."
            },
            "score": 1
        }
    ],
    "novelty": "yes"
}