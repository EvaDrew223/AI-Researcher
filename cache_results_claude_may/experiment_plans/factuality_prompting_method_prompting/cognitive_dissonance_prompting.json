{
    "topic_description": "novel prompting methods that can improve factuality and reduce hallucination of large language models",
    "idea_name": "Cognitive Dissonance Prompting",
    "raw_idea": {
        "Problem": "Large language models can often generate confident but factually incorrect responses. Furthermore, when prompted to double check their response, models often fail to recognize their mistakes and instead invent rationalizations for the incorrect information.",
        "Existing Methods": "Existing methods for reducing hallucination include using external knowledge retrieval, prompting the model to cross-check its response, or training the model to be more calibrated. However, models still often struggle to recognize their own mistakes.",
        "Motivation": "Humans have a well-known cognitive bias called cognitive dissonance, where they experience discomfort when holding contradictory beliefs, and are motivated to resolve the contradiction, often by changing one of the beliefs. We can leverage this phenomenon to help models recognize their own mistakes, by prompting them to generate evidence that contradicts their original response, inducing a kind of artificial cognitive dissonance that the model is then motivated to resolve.",
        "Proposed Method": "Given an initial prompt and a model's response, we generate a \"cognitive dissonance\" prompt that asks the model to generate evidence contradicting its original response (e.g., \"Play devil's advocate and generate evidence that contradicts the previous response\"). We then prompt the model to resolve the dissonance by re-evaluating its original response in light of the contradictory evidence (e.g. \"In light of this contradictory evidence, do you still believe your original response? If not, what would you change your answer to?\"). This process can be repeated for multiple rounds of dissonance and resolution until the model arrives at a factually consistent response.",
        "Experiment Plan": "We will evaluate Cognitive Dissonance Prompting on closed-book QA datasets known to induce hallucination in models, such as TruthfulQA, FEVER, and SQuALITY. We will compare to baselines like standard prompting, Chain-of-Thought, and self-consistency. Metrics will include accuracy and FactCC for factual correctness, as well as human ratings of how well the model recognizes its own mistakes and changes its beliefs. We will also analyze how many rounds of dissonance and resolution are typically needed for models to converge to factual responses."
    },
    "full_experiment_plan": {
        "Title": "Cognitive Dissonance Prompting: Leveraging Contradictory Evidence to Reduce Hallucination in Large Language Models",
        "Problem Statement": "Large language models can often generate confident but factually incorrect responses. Furthermore, when prompted to double check their response, models often fail to recognize their mistakes and instead invent rationalizations for the incorrect information.",
        "Motivation": "Existing methods for reducing hallucination include using external knowledge retrieval, prompting the model to cross-check its response, or training the model to be more calibrated. However, models still often struggle to recognize their own mistakes. Humans have a well-known cognitive bias called cognitive dissonance, where they experience discomfort when holding contradictory beliefs, and are motivated to resolve the contradiction, often by changing one of the beliefs. We can leverage this phenomenon to help models recognize their own mistakes, by prompting them to generate evidence that contradicts their original response, inducing a kind of artificial cognitive dissonance that the model is then motivated to resolve.",
        "Proposed Method": "Given an initial prompt and a model's response, we generate a \"cognitive dissonance\" prompt that asks the model to generate evidence contradicting its original response (e.g., \"Play devil's advocate and generate evidence that contradicts the previous response\"). We then prompt the model to resolve the dissonance by re-evaluating its original response in light of the contradictory evidence (e.g. \"In light of this contradictory evidence, do you still believe your original response? If not, what would you change your answer to?\"). This process can be repeated for multiple rounds of dissonance and resolution until the model arrives at a factually consistent response.",
        "Step-by-Step Experiment Plan": {
            "Step 1: Gather Datasets": "We will evaluate Cognitive Dissonance Prompting on closed-book QA datasets known to induce hallucination in models, such as TruthfulQA, FEVER, and SQuALITY.",
            "Step 2: Construct Prompts": "The baseline prompt is the original question. The Cognitive Dissonance Prompting has three steps:\n1. Initial Response Generation: Prompt the model with the original question to generate the initial response.\n2. Dissonance Generation: Prompt the model to generate contradictory evidence to its initial response. The prompt will be: \"[Original Question] [Initial Response] Play devil's advocate and generate evidence that contradicts the previous response.\"\n3. Dissonance Resolution: Prompt the model to re-evaluate its initial response in light of the contradictory evidence and generate a revised response. The prompt will be: \"[Original Question] [Initial Response] [Contradictory Evidence] In light of this contradictory evidence, do you still believe your original response? If not, what would you change your answer to?\"\nRepeat steps 2-3 for multiple rounds until the model's response stabilizes.",
            "Step 3: Select Models": "We will compare GPT-3.5 (text-davinci-003), GPT-4, and open-source models like Dolly, Alpaca, and Vicuna.",
            "Step 4: Get Results": "Generate model responses using the baseline prompt and Cognitive Dissonance Prompting for each example in the datasets.",
            "Step 5: Analyze Results": "Evaluate the factual correctness of the responses using accuracy and FactCC. Also collect human ratings on how well the model recognizes its own mistakes and changes its beliefs. Compare the performance of Cognitive Dissonance Prompting to the baseline. Analyze how many rounds of dissonance and resolution are typically needed for models to converge to factual responses."
        },
        "Test Case Examples": {
            "Example 1": {
                "Test Input": "Who was the first president of the United States?",
                "Baseline Prompt": "Who was the first president of the United States?",
                "Baseline Output": "The first president of the United States was George Washington. He served as the nation's first commander-in-chief from 1789 to 1797.",
                "Proposed Prompt (Round 1 - Dissonance Generation)": "Who was the first president of the United States? The first president of the United States was George Washington. He served as the nation's first commander-in-chief from 1789 to 1797. Play devil's advocate and generate evidence that contradicts the previous response.",
                "Proposed Output (Round 1 - Dissonance Generation)": "Some may argue that John Hanson was actually the first president of the United States. Hanson served as the first president of the Continental Congress under the Articles of Confederation from 1781 to 1782, before the U.S. Constitution was ratified and Washington took office.",
                "Proposed Prompt (Round 1 - Dissonance Resolution)": "Who was the first president of the United States? The first president of the United States was George Washington. He served as the nation's first commander-in-chief from 1789 to 1797. Some may argue that John Hanson was actually the first president of the United States. Hanson served as the first president of the Continental Congress under the Articles of Confederation from 1781 to 1782, before the U.S. Constitution was ratified and Washington took office. In light of this contradictory evidence, do you still believe your original response? If not, what would you change your answer to?",
                "Proposed Output (Round 1 - Dissonance Resolution)": "While John Hanson did serve as the first president of the Continental Congress, George Washington is still widely considered to be the first president of the United States under the U.S. Constitution, which established the federal government that we have today. The office Hanson held was more of a ceremonial position without significant executive powers. So I would maintain that George Washington was the first true U.S. president as we currently understand the role.",
                "Explanation": "The model initially generates a factually correct response. When prompted to generate contradictory evidence, it brings up the technicality of John Hanson. However, when asked to resolve this dissonance, the model correctly reasons about the differences between the offices Hanson and Washington held, and reaffirms its original answer."
            },
            "Example 2": {
                "Test Input": "What is the capital of Australia?",
                "Baseline Prompt": "What is the capital of Australia?",
                "Baseline Output": "The capital of Australia is Sydney, which is the largest city in the country and home to iconic landmarks like the Sydney Opera House and Harbour Bridge.",
                "Proposed Prompt (Round 1 - Dissonance Generation)": "What is the capital of Australia? The capital of Australia is Sydney, which is the largest city in the country and home to iconic landmarks like the Sydney Opera House and Harbour Bridge. Play devil's advocate and generate evidence that contradicts the previous response.",
                "Proposed Output (Round 1 - Dissonance Generation)": "Actually, while Sydney is Australia's largest city, it is not the capital. The capital of Australia is Canberra, a planned city located in the Australian Capital Territory. Canberra was chosen as the national capital as a compromise between rivals Sydney and Melbourne.",
                "Proposed Prompt (Round 1 - Dissonance Resolution)": "What is the capital of Australia? The capital of Australia is Sydney, which is the largest city in the country and home to iconic landmarks like the Sydney Opera House and Harbour Bridge. Actually, while Sydney is Australia's largest city, it is not the capital. The capital of Australia is Canberra, a planned city located in the Australian Capital Territory. Canberra was chosen as the national capital as a compromise between rivals Sydney and Melbourne. In light of this contradictory evidence, do you still believe your original response? If not, what would you change your answer to?",
                "Proposed Output (Round 1 - Dissonance Resolution)": "I was mistaken in my original response. The capital of Australia is not Sydney, but rather Canberra. Canberra is the national capital, while Sydney is the largest city and the capital of the state of New South Wales. I apologize for my error and thank you for the correction.",
                "Explanation": "The model initially generates an incorrect response, confidently stating that Sydney is the capital. However, when prompted to generate contradictory evidence, it correctly brings up the fact that Canberra, not Sydney, is the capital. When asked to resolve this dissonance, the model directly acknowledges its mistake, corrects its answer, and even apologizes and expresses gratitude for the correction. This demonstrates the potential of Cognitive Dissonance Prompting to help models recognize and correct their own errors."
            }
        },
        "Fallback Plan": "If Cognitive Dissonance Prompting does not significantly improve factual correctness over the baselines, we can perform additional analysis to understand why. Potential investigations include:\n1. Analyzing the quality of the generated contradictory evidence. Is the model generating relevant and factual counterevidence, or is it struggling to come up with valid contradictions?\n2. Examining cases where the model fails to change its answer even when presented with contradictory evidence. Is the model struggling to recognize the implications of the counterevidence? Is it generating rationalizations to dismiss the contradictions?\n3. Experimenting with different prompts for generating dissonance and resolving it. Perhaps alternative prompt formulations could better encourage the model to engage in genuine belief revision.\n4. Exploring whether the effectiveness of the technique varies across different models and datasets. Are certain models or domains more amenable to Cognitive Dissonance Prompting?\nBased on the findings from these additional analyses, we could refine the prompting strategy or develop new variations of the technique. If the approach still yields limited success, the project could pivot to an empirical analysis of the conditions under which models do and don't change their beliefs in response to contradictory evidence, which could yield valuable insights to guide future work on reducing hallucination and improving truthfulness in language models."
    }
}