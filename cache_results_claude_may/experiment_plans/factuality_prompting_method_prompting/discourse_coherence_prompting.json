{
    "topic_description": "novel prompting methods that can improve factuality and reduce hallucination of large language models",
    "idea_name": "Discourse Coherence Prompting",
    "raw_idea": {
        "Problem": "Large language models can lose coherence when generating long sequences, leading to issues like self-contradiction, irrelevant tangents, or abrupt topic shifts. This is especially problematic for tasks that require generating coherent long-form text, like story generation, dialogues, or explanations.",
        "Existing Methods": "Most existing methods for improving coherence focus on better planning and content selection to guide generation, such as by generating intermediates sketches, keyword transition sequences, or learned sentence representations. However, these approaches do not directly optimize for the linguistic markers of discourse coherence.",
        "Motivation": "Linguistic theories of discourse coherence, such as Centering Theory and Rhetorical Structure Theory, describe how humans maintain coherence in text and dialogue through specific discourse patterns, such as chains of mention, coreference, discourse relations, and coherent topic progression. We can prompt models to generate these discourse coherence markers as part of the generation process, to more directly guide them towards coherent output.",
        "Proposed Method": "We develop discourse coherence prompts that include explicit markers for the key components of discourse coherence theories, such as entities and coreference chains, discourse relations, and topic flow. For example, a prompt could include tags like <entity1>, <entity2>, <coref>, <elaboration>, <contrast>, <topic_shift> that the model must generate to make the discourse structure explicit. We also include a few-shot prompt that demonstrates how to map the discourse coherence markers to natural text. At generation time, we first prompt the model to generate the discourse coherence structure of the response, then condition the response generation on that structure.",
        "Experiment Plan": "We will evaluate Discourse Coherence Prompting on tasks that require generating coherent long-form text, including story generation (e.g. WritingPrompts), long-form QA (e.g. ELI5, NarrativeQA), and dialogue (e.g. TopicalChat, PersonaChat). We will measure coherence with automatic metrics like DiscEval, GED, and sentence topic flow (STF), as well as human ratings of coherence, consistency, and single-topic flow. We will also qualitatively analyze the generated discourse structures to understand what patterns lead to more or less coherent output."
    },
    "full_experiment_plan": {
        "Title": "Discourse Coherence Prompting: Improving Long-form Text Generation with Explicit Discourse Structure",
        "Problem Statement": "Large language models can lose coherence when generating long sequences, leading to issues like self-contradiction, irrelevant tangents, or abrupt topic shifts. This is especially problematic for tasks that require generating coherent long-form text, like story generation, dialogues, or explanations.",
        "Motivation": "Most existing methods for improving coherence focus on better planning and content selection to guide generation, such as by generating intermediates sketches, keyword transition sequences, or learned sentence representations. However, these approaches do not directly optimize for the linguistic markers of discourse coherence. Linguistic theories of discourse coherence, such as Centering Theory and Rhetorical Structure Theory, describe how humans maintain coherence in text and dialogue through specific discourse patterns, such as chains of mention, coreference, discourse relations, and coherent topic progression. We can prompt models to generate these discourse coherence markers as part of the generation process, to more directly guide them towards coherent output.",
        "Proposed Method": "We develop discourse coherence prompts that include explicit markers for the key components of discourse coherence theories, such as entities and coreference chains, discourse relations, and topic flow. For example, a prompt could include tags like <entity1>, <entity2>, <coref>, <elaboration>, <contrast>, <topic_shift> that the model must generate to make the discourse structure explicit. We also include a few-shot prompt that demonstrates how to map the discourse coherence markers to natural text. At generation time, we first prompt the model to generate the discourse coherence structure of the response, then condition the response generation on that structure.",
        "Step-by-Step Experiment Plan": {
            "Step 1: Gather Datasets": "We will evaluate Discourse Coherence Prompting on tasks that require generating coherent long-form text, including story generation (e.g. WritingPrompts), long-form QA (e.g. ELI5, NarrativeQA), and dialogue (e.g. TopicalChat, PersonaChat).",
            "Step 2: Define Discourse Coherence Markers": "Based on linguistic theories of discourse coherence, define a set of discourse markers to include in the prompts. These should cover key aspects like:\n- Entities and coreference chains (e.g. <entity1>, <entity2>, <coref>)\n- Discourse relations (e.g. <elaboration>, <contrast>, <cause-effect>)\n- Topic progression (e.g. <topic_shift>, <topic_continue>)",
            "Step 3: Construct Prompts": "Create prompts that include the discourse coherence markers defined in Step 2. The prompts should have two parts:\n1. A few-shot demonstration of how to map between discourse markers and natural text. Give 3-5 examples.\n2. The actual generation prompt, which first asks the model to generate the discourse structure, and then the full response conditioned on that structure.\nFor baselines, use standard prompts without any discourse markers.",
            "Step 4: Select Models": "Evaluate the prompts on GPT-3.5 (text-davinci-002) and GPT-4 via the OpenAI API.",
            "Step 5: Generate Outputs": "For each task and prompt, generate outputs from the models. For the discourse coherence prompts, first generate the discourse structure, then the full response.",
            "Step 6: Evaluate Coherence": "Measure the coherence of the generated texts using a combination of automatic metrics and human evaluation:\n- Automatic metrics: DiscEval, GED, sentence topic flow (STF)\n- Human evaluation: Ask raters to judge the coherence, consistency, and single-topic flow of the generated texts on a 1-5 scale.\nCompare the coherence scores of the discourse coherence prompt outputs vs. the baselines.",
            "Step 7: Analyze Discourse Structures": "Qualitatively analyze the discourse structures generated by the models to understand what patterns lead to more or less coherent output. Look for things like:\n- Are the entity and coreference chains consistent and relevant?\n- Are the discourse relations reasonable and do they match the text?\n- Is the topic progression natural or are there abrupt shifts?\nUse these insights to refine the discourse marker set and prompts."
        },
        "Test Case Examples": {
            "Baseline Prompt Input": "Write a story about a haunted house.",
            "Baseline Prompt Expected Output": "The old mansion on the hill had been abandoned for years, but local legends spoke of the ghosts that haunted its halls. One summer, a group of teenagers decided to explore the house on a dare. As they crept through the dusty rooms, they heard strange creaks and whispers. Suddenly, a chill wind blew through the house, slamming doors and rattling windows. The friends ran for the exit, but found themselves trapped in a maze of twisting corridors. Panic set in as they realized they were not alone. Ghostly figures appeared in the shadows, reaching out with pale hands. The teenagers fled in terror, barely escaping with their lives. From that night on, no one dared to enter the haunted house again, leaving the spirits to their eternal unrest.",
            "Proposed Prompt Input": "Generate a discourse structure for a story about a haunted house, using these markers:\n<entity>: introduce a character or object\n<coref>: refer back to a previously mentioned entity\n<setting>: describe the location or time\n<event>: describe an action or happening\n<reaction>: describe a character's response\n<topic_shift>: introduce a new topic or scene\n<topic_continue>: elaborate on the current topic\n\nThen, write out the full story based on the discourse structure.",
            "Proposed Prompt Expected Output": "<setting> The old mansion on the hill, abandoned for years\n<entity1> Local legends\n<coref1> spoke of ghosts haunting <coref2>\n<topic_shift>\n<entity2> A group of teenagers \n<event1> <coref2> decide to explore <coref3> on a dare.\n<topic_continue>\n<event2> As <coref2> crept through the dusty rooms,\n<event3> <coref2> heard strange creaks and whispers. \n<event4> Suddenly, a chill wind blew through <coref4>, slamming doors and rattling windows.\n<reaction1> <coref2> ran for the exit in panic \n<event5> but found <coref5> trapped in a maze of twisting corridors.\n<topic_shift>\n<entity3> Ghostly figures \n<event6> <coref3> appeared in the shadows, reaching out with pale hands.\n<reaction2> <coref2> fled in terror, barely escaping with <coref6> lives.\n<topic_shift>\n<event7> From that night on, no one dared to enter <coref7> again,\n<event8> leaving the spirits to <coref8> eternal unrest.\n\nThe old mansion on the hill had been abandoned for years, but local legends spoke of the ghosts that haunted its halls. One summer, a group of teenagers decided to explore the house on a dare. \n\nAs they crept through the dusty rooms, they heard strange creaks and whispers. Suddenly, a chill wind blew through the house, slamming doors and rattling windows. The friends ran for the exit in panic, but found themselves trapped in a maze of twisting corridors. \n\nGhostly figures appeared in the shadows, reaching out with pale hands. The teenagers fled in terror, barely escaping with their lives.\n\nFrom that night on, no one dared to enter the haunted house again, leaving the spirits to their eternal unrest.",
            "Explanation": "The discourse coherence prompt guides the model to first lay out the key entities, events, and topic shifts in the story, creating a 'narrative skeleton'. This helps keep the full story on track and maintain coherence. The baseline prompt provides no such guidance, allowing the model to potentially lose focus."
        },
        "Fallback Plan": "If the proposed discourse coherence prompts do not show improvements over the baselines, we can:\n1. Analyze the generated discourse structures to see if they are relevant and well-formed. If not, the prompt format or discourse marker set may need to be refined.\n2. Check if the full text generation is properly conditioned on the discourse structure. If not, the model may be ignoring the structure and the prompting approach needs to be adjusted.\n3. Experiment with different sets of discourse markers based on other coherence frameworks beyond Centering Theory and RST.\n4. Collect a dataset of 'discourse-labeled' long-form text to further pre-train or fine-tune the model to better leverage the discourse structure.\n5. If the discourse structures look good but the model still struggles with long-form coherence, the problem may be more fundamental to the model architecture. In this case, the project could pivot to analyzing the limitations of the current models in terms of discourse-level coherence."
    },
    "novelty_queries": [
        "KeywordQuery(\"discourse coherence language models\")",
        "KeywordQuery(\"long-form text generation coherence\")",
        "KeywordQuery(\"discourse structure language models\")",
        "KeywordQuery(\"centering theory rhetorical structure theory language models\")",
        "KeywordQuery(\"Discourse Coherence Prompting NLP\")"
    ],
    "novelty_papers": [
        {
            "id": "36a7b1a82390f5291b3bf8ff592f8630b4f33442",
            "paperId": "36a7b1a82390f5291b3bf8ff592f8630b4f33442",
            "title": "Neural Net Models for Open-Domain Discourse Coherence",
            "abstract": "Discourse coherence is strongly associated with text quality, making it important to natural language generation and understanding. Yet existing models of coherence focus on measuring individual aspects of coherence (lexical overlap, rhetorical structure, entity centering) in narrow domains. \nIn this paper, we describe domain-independent neural models of discourse coherence that are capable of measuring multiple aspects of coherence in existing sentences and can maintain coherence while generating new sentences. We study both discriminative models that learn to distinguish coherent from incoherent discourse, and generative models that produce coherent text, including a novel neural latent-variable Markovian generative model that captures the latent discourse dependencies between sentences in a text. \nOur work achieves state-of-the-art performance on multiple coherence evaluations, and marks an initial step in generating coherent texts given discourse contexts.",
            "year": 2016,
            "citationCount": 121,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": null
            },
            "score": 7,
            "novelty_score": "The project proposal aims to improve the coherence of long-form text generation by prompting language models with explicit discourse structure markers. The paper focuses on developing neural models that can measure and maintain discourse coherence in both discriminative and generative settings.\n\nWhile both works address the topic of discourse coherence, the project proposal specifically tackles the problem of generating coherent long-form text using large language models and discourse structure prompting. In contrast, the paper studies general neural models for measuring and generating coherent text without focusing on a specific domain or generation approach.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "ebfab85199156380c1b1246fef368e84fcf6a113",
            "paperId": "ebfab85199156380c1b1246fef368e84fcf6a113",
            "title": "Unlocking Structure Measuring: Introducing PDD, an Automatic Metric for Positional Discourse Coherence",
            "abstract": "Recent large language models (LLMs) have shown remarkable performance in aligning generated text with user intentions across various tasks. When it comes to long-form text generation, there has been a growing interest in generation from a discourse coherence perspective. However, existing lexical or semantic metrics such as BLEU, ROUGE, BertScore cannot effectively capture the discourse coherence. The development of discourse-specific automatic evaluation methods for assessing the output of LLMs warrants greater focus and exploration. In this paper, we present a novel automatic metric designed to quantify the discourse divergence between two long-form articles. Extensive experiments on three datasets from representative domains demonstrate that our metric aligns more closely with human preferences and GPT-4 coherence evaluation, outperforming existing evaluation methods.",
            "year": 2024,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A novel automatic metric designed to quantify the discourse divergence between two long-form articles is presented, which aligns more closely with human preferences and GPT-4 coherence evaluation, outperforming existing evaluation methods."
            },
            "score": 7,
            "novelty_score": "The project proposal aims to improve the coherence of long-form text generation by prompting language models with explicit discourse structure markers. The paper introduces a new automatic evaluation metric to measure the discourse coherence of generated long-form text.\n\nWhile both works focus on the discourse coherence of long-form text generation, the project proposal is about improving the generation process itself, while the paper is about evaluating the generated output. The proposal suggests a new method for generating more coherent text, while the paper proposes a new metric for assessing the coherence of generated text.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "bf468c8fc7cde9188c3eaa32735d804e4da087c7",
            "paperId": "bf468c8fc7cde9188c3eaa32735d804e4da087c7",
            "title": "A Centering Approach for Discourse Structure-aware Coherence Modeling",
            "abstract": "Previous neural coherence models have focused on identifying semantic relations between adjacent sentences. However, they do not have the means to exploit structural information. In this work, we propose a coherence model which takes discourse structural information into account without relying on human annotations. We approximate a linguistic theory of coherence, Centering theory, which we use to track the changes of focus between discourse segments. Our model first identifies the focus of each sentence, recognized with regards to the context, and constructs the structural relationship for discourse segments by tracking the changes of the focus. The model then incorporates this structural information into a structure-aware transformer. We evaluate our model on two tasks, automated essay scoring and assessing writing quality. Our results demonstrate that our model, built on top of a pretrained language model, achieves state-of-the-art performance on both tasks. We next statistically examine the identified trees of texts assigned to different quality scores. Finally, we investigate what our model learns in terms of theoretical claims.",
            "year": 2020,
            "citationCount": 4,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work proposes a coherence model which takes discourse structural information into account without relying on human annotations, and approximate a linguistic theory of coherence, Centering theory, which is used to track the changes of focus between discourse segments."
            },
            "score": 7,
            "novelty_score": "The project proposal aims to improve the coherence of long-form text generation by prompting language models with explicit discourse structure markers based on linguistic theories like Centering Theory. The paper proposes a coherence model that incorporates structural information based on Centering Theory to track focus changes between discourse segments, without relying on human annotations.\n\nWhile both works leverage Centering Theory to model discourse coherence, the project focuses on prompting language models to generate coherent long-form text, while the paper proposes a coherence model for automated essay scoring and assessing writing quality. The project emphasizes generating explicit discourse structures, while the paper focuses on identifying focus shifts to construct structural relationships.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "61c67b52a0377617d1bcf4b0c5d875c2aa974fa7",
            "paperId": "61c67b52a0377617d1bcf4b0c5d875c2aa974fa7",
            "title": "DiscoDVT: Generating Long Text with Discourse-Aware Discrete Variational Transformer",
            "abstract": "Despite the recent advances in applying pre-trained language models to generate high-quality texts, generating long passages that maintain long-range coherence is yet challenging for these models. In this paper, we propose DiscoDVT, a discourse-aware discrete variational Transformer to tackle the incoherence issue. DiscoDVT learns a discrete variable sequence that summarizes the global structure of the text and then applies it to guide the generation process at each decoding step. To further embed discourse-aware information into the discrete latent representations, we introduce an auxiliary objective to model the discourse relations within the text. We conduct extensive experiments on two open story generation datasets and demonstrate that the latent codes learn meaningful correspondence to the discourse structures that guide the model to generate long texts with better long-range coherence.",
            "year": 2021,
            "citationCount": 17,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The proposed DiscoDVT, a discourse-aware discrete variational Transformer, learns a discrete variable sequence that summarizes the global structure of the text and applies it to guide the generation process at each decoding step, and introduces an auxiliary objective to model the discourse relations within the text."
            },
            "score": 7,
            "novelty_score": "The research problem in the proposal is improving the coherence of long-form text generation by explicitly modeling discourse structure. The approach is to prompt the model to generate discourse coherence markers like entities, coreference, and discourse relations as an intermediate step before generating the full text.\n\nThe research problem in the paper is also improving the coherence of long-form text generation. The approach is to learn a discrete latent variable sequence that summarizes the global discourse structure and use it to guide the generation process.\n\nBoth the proposal and paper aim to improve long-form text coherence by explicitly modeling discourse structure. The main difference is in the specific approach: the proposal uses discourse-aware prompting, while the paper learns discourse-aware discrete latent variables.\n\nYes",
            "novelty_judgment": "yes"
        },
        {
            "id": "124b26932faad9ee76bfbe84262591cefffbef6d",
            "paperId": "124b26932faad9ee76bfbe84262591cefffbef6d",
            "title": "A Novel Computational and Modeling Foundation for Automatic Coherence Assessment",
            "abstract": "Coherence is an essential property of well-written texts, that refers to the way textual units relate to one another. In the era of generative AI, coherence assessment is essential for many NLP tasks; summarization, generation, long-form question-answering, and more. However, in NLP {coherence} is an ill-defined notion, not having a formal definition or evaluation metrics, that would allow for large-scale automatic and systematic coherence assessment. To bridge this gap, in this work we employ the formal linguistic definition of \\citet{Reinhart:1980} of what makes a discourse coherent, consisting of three conditions -- {\\em cohesion, consistency} and {\\em relevance} -- and formalize these conditions as respective computational tasks. We hypothesize that (i) a model trained on all of these tasks will learn the features required for coherence detection, and that (ii) a joint model for all tasks will exceed the performance of models trained on each task individually. On two benchmarks for coherence scoring rated by humans, one containing 500 automatically-generated short stories and another containing 4k real-world texts, our experiments confirm that jointly training on the proposed tasks leads to better performance on each task compared with task-specific models, and to better performance on assessing coherence overall, compared with strong baselines. We conclude that the formal and computational setup of coherence as proposed here provides a solid foundation for advanced methods of large-scale automatic assessment of coherence.",
            "year": 2023,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "It is concluded that the formal and computational setup of coherence as proposed here provides a solid foundation for advanced methods of large-scale automatic assessment of coherent assessment."
            },
            "score": 7,
            "novelty_score": "The project proposal aims to improve the coherence of long-form text generation by prompting language models with explicit discourse structure markers. The paper proposes a computational framework for automatic coherence assessment based on formalizing linguistic theories of coherence.\n\nThe project focuses on generating more coherent text by guiding language models with discourse-level prompts, while the paper focuses on automatically evaluating the coherence of existing texts using a model trained on cohesion, consistency, and relevance tasks. Although both deal with coherence, the project is about generation and the paper is about evaluation, using different approaches.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "e6de988c8f482ee6de355e22c7cab95f07a2c0ad",
            "paperId": "e6de988c8f482ee6de355e22c7cab95f07a2c0ad",
            "title": "Automated evaluation of written discourse coherence using GPT-4",
            "abstract": "The popularization of large language models (LLMs) such as OpenAI\u2019s GPT-3 and GPT-4 have led to numerous innovations in the field of AI in education. With respect to automated writing evaluation (AWE), LLMs have reduced challenges associated with assessing writing quality characteristics that are difficult to identify automatically, such as discourse coherence. In addition, LLMs can provide rationales for their evaluations (ratings) which increases score interpretability and transparency. This paper investigates one approach to producing ratings by training GPT-4 to assess discourse coherence in a manner consistent with expert human raters. The findings of the study suggest that GPT-4 has strong potential to produce discourse coherence ratings that are comparable to human ratings, accompanied by clear rationales. Furthermore, the GPT-4 ratings outperform traditional NLP coherence metrics with respect to agreement with human ratings. These results have implications for advancing AWE technology for learning and assessment.",
            "year": 2023,
            "citationCount": 27,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "It is suggested that GPT-4 has strong potential to produce discourse coherence ratings that are comparable to human ratings, accompanied by clear rationales, which has implications for advancing AWE technology for learning and assessment."
            },
            "score": 6,
            "novelty_score": "The research problem in the proposal is improving the coherence of long-form text generation by large language models, and the proposed approach is to use explicit discourse structure prompts to guide the generation process.\n\nThe research problem in the paper is automated evaluation of discourse coherence in written text, and the approach is to train GPT-4 to assess coherence in a manner consistent with expert human raters.\n\nWhile both works involve the concept of discourse coherence, the research problems and approaches are quite different. The proposal focuses on generating more coherent text, while the paper focuses on evaluating the coherence of existing text. The proposal uses discourse structure prompts to guide generation, while the paper trains GPT-4 to mimic human coherence ratings.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "e1c957e0cb6098304deffb01e4428eb368f8e1ff",
            "paperId": "e1c957e0cb6098304deffb01e4428eb368f8e1ff",
            "title": "Disco-Bench: A Discourse-Aware Evaluation Benchmark for Language Modelling",
            "abstract": "Modeling discourse -- the linguistic phenomena that go beyond individual sentences, is a fundamental yet challenging aspect of natural language processing (NLP). However, existing evaluation benchmarks primarily focus on the evaluation of inter-sentence properties and overlook critical discourse phenomena that cross sentences. To bridge the gap, we propose Disco-Bench, a benchmark that can evaluate intra-sentence discourse properties across a diverse set of NLP tasks, covering understanding, translation, and generation. Disco-Bench consists of 9 document-level testsets in the literature domain, which contain rich discourse phenomena (e.g. cohesion and coherence) in Chinese and/or English. For linguistic analysis, we also design a diagnostic test suite that can examine whether the target models learn discourse knowledge. We totally evaluate 20 general-, in-domain and commercial models based on Transformer, advanced pretraining architectures and large language models (LLMs). Our results show (1) the challenge and necessity of our evaluation benchmark; (2) fine-grained pretraining based on literary document-level training data consistently improves the modeling of discourse information. We will release the datasets, pretrained models, and leaderboard, which we hope can significantly facilitate research in this field: https://github.com/longyuewangdcu/Disco-Bench.",
            "year": 2023,
            "citationCount": 3,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Disco-Bench is proposed, a benchmark that can evaluate intra-sentence discourse properties across a diverse set of NLP tasks, covering understanding, translation, and generation and shows fine-grained pretraining based on literary document-level training data consistently improves the modeling of discourse information."
            },
            "score": 6,
            "novelty_score": "The project proposal aims to improve the coherence of long-form text generation by prompting language models with explicit discourse structure markers. The paper abstract proposes Disco-Bench, a benchmark for evaluating discourse phenomena in language models across various NLP tasks.\n\nThe project focuses on generating coherent long-form text, while the paper is about evaluating discourse properties in existing models. Although both involve discourse, the project is about generation and the paper is about evaluation, so they have different goals and approaches.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "80217f99eefaca813adcffec6968bcd28a66b8bd",
            "paperId": "80217f99eefaca813adcffec6968bcd28a66b8bd",
            "title": "PLANET: Dynamic Content Planning in Autoregressive Transformers for Long-form Text Generation",
            "abstract": "Despite recent progress of pre-trained language models on generating fluent text, existing methods still suffer from incoherence problems in long-form text generation tasks that require proper content control and planning to form a coherent high-level logical flow. In this work, we propose PLANET, a novel generation framework leveraging autoregressive self-attention mechanism to conduct content planning and surface realization dynamically. To guide the generation of output sentences, our framework enriches the Transformer decoder with latent representations to maintain sentence-level semantic plans grounded by bag-of-words. Moreover, we introduce a new coherence-based contrastive learning objective to further improve the coherence of output. Extensive experiments are conducted on two challenging long-form text generation tasks including counterargument generation and opinion article generation. Both automatic and human evaluations show that our method significantly outperforms strong baselines and generates more coherent texts with richer contents.",
            "year": 2022,
            "citationCount": 25,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "PANET is proposed, a novel generation framework leveraging autoregressive self-attention mechanism to conduct content planning and surface realization dynamically and introduces a new coherence-based contrastive learning objective to further improve the coherence of output."
            },
            "score": 6,
            "novelty_score": "The project proposal aims to improve the coherence of long-form text generation by explicitly modeling discourse structure using discourse coherence prompts. The paper abstract proposes a content planning approach using latent representations to maintain sentence-level semantic plans and a coherence-based contrastive learning objective.\n\nWhile both works aim to improve long-form text generation coherence, the project focuses on explicitly modeling discourse structure using linguistic theories, while the paper proposes a dynamic content planning approach using latent representations and contrastive learning. The methods are quite different.\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "32bfc242d0e85f1b6f2ff838c37287f8cfddf7c2",
            "paperId": "32bfc242d0e85f1b6f2ff838c37287f8cfddf7c2",
            "title": "Towards Coherent and Cohesive Long-form Text Generation",
            "abstract": "Generating coherent and cohesive long-form texts is a challenging task. Previous works relied on large amounts of human-generated texts to train neural language models. However, few attempted to explicitly improve neural language models from the perspectives of coherence and cohesion. In this work, we propose a new neural language model that is equipped with two neural discriminators which provide feedback signals at the levels of sentence (cohesion) and paragraph (coherence). Our model is trained using a simple yet efficient variant of policy gradient, called \u2018negative-critical sequence training\u2019, which is proposed to eliminate the need of training a separate critic for estimating \u2018baseline\u2019. Results demonstrate the effectiveness of our approach, showing improvements over the strong baseline \u2013 recurrent attention-based bidirectional MLE-trained neural language model.",
            "year": 2018,
            "citationCount": 43,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A new neural language model is proposed that is equipped with two neural discriminators which provide feedback signals at the levels of sentence (cohesion) and paragraph (coherence) and this model is trained using a simple yet efficient variant of policy gradient, called \u2018negative-critical sequence training\u2019."
            },
            "score": 6,
            "novelty_score": "The project proposal aims to improve the coherence of long-form text generation by explicitly prompting language models with discourse structure markers. The paper tries to achieve the same goal by equipping neural language models with sentence-level and paragraph-level discriminators to provide coherence and cohesion feedback.\n\nProject proposal: Improve long-form text coherence using discourse structure prompts\nPaper: Improve long-form text coherence using sentence and paragraph-level discriminators\n\nWhile both address the problem of coherence in long-form text generation, the proposed methods are quite different (explicit discourse prompting vs. discriminator feedback).\n\nNo",
            "novelty_judgment": "no"
        },
        {
            "id": "b7824228b404029bf4b72d2960bcaa2bed49231b",
            "paperId": "b7824228b404029bf4b72d2960bcaa2bed49231b",
            "title": "RSTGen: Imbuing Fine-Grained Interpretable Control into Long-FormText Generators",
            "abstract": "In this paper, we study the task of improving the cohesion and coherence of long-form text generated by language models.To this end, we propose RSTGen, a framework that utilises Rhetorical Structure Theory (RST), a classical language theory, to control the discourse structure, semantics and topics of generated text. Firstly, we demonstrate our model\u2019s ability to control structural discourse and semantic features of generated text in open generation evaluation. Then we experiment on the two challenging long-form text tasks of argument generation and story generation. Evaluation using automated metrics and a metric with high correlation to human evaluation, shows that our model performs competitively against existing models, while offering significantly more controls over generated text than alternative methods.",
            "year": 2022,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "RSTGen is proposed, a framework that utilises Rhetorical Structure Theory (RST), a classical language theory, to control the discourse structure, semantics and topics of generated text to improve the cohesion and coherence of long-form text generated by language models."
            },
            "score": 6,
            "novelty_score": "The project proposal aims to improve the coherence of long-form text generated by language models using discourse coherence prompts based on linguistic theories like Centering Theory and Rhetorical Structure Theory (RST). The paper also tackles the problem of improving the coherence of long-form text generated by language models, using RST to control the discourse structure, semantics, and topics.\n\nBoth the project proposal and the paper focus on improving the coherence of long-form text generation using RST-based methods to control the discourse structure.\n\nYes",
            "novelty_judgment": "yes"
        },
        {
            "id": "bb2ef694e8b5a99e1f7ceb014968b4d1dc2e122a",
            "paperId": "bb2ef694e8b5a99e1f7ceb014968b4d1dc2e122a",
            "title": "EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generation",
            "abstract": "Plan-and-Write is a common hierarchical approach in long-form narrative text generation, which first creates a plan to guide the narrative writing. Following this approach, several studies rely on simply prompting large language models for planning, which often yields suboptimal results. In this paper, we propose a new framework called Evaluation-guided Iterative Plan Extraction for long-form narrative text generation (EIPE-text), which extracts plans from the corpus of narratives and utilizes the extracted plans to construct a better planner. EIPE-text has three stages: plan extraction, learning, and inference. In the plan extraction stage, it iteratively extracts and improves plans from the narrative corpus and constructs a plan corpus. We propose a question answer (QA) based evaluation mechanism to automatically evaluate the plans and generate detailed plan refinement instructions to guide the iterative improvement. In the learning stage, we build a better planner by fine-tuning with the plan corpus or in-context learning with examples in the plan corpus. Finally, we leverage a hierarchical approach to generate long-form narratives. We evaluate the effectiveness of EIPE-text in the domains of novels and storytelling. Both GPT-4-based evaluations and human evaluations demonstrate that our method can generate more coherent and relevant long-form narratives. Our code will be released in the future.",
            "year": 2023,
            "citationCount": 3,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A new framework called Evaluation-guided Iterative Plan Extraction for long-form narrative text generation (EIPE-text), which extracts plans from the corpus of narratives and utilizes the extracted plans to construct a better planner."
            },
            "score": 6
        },
        {
            "id": "399c03772b2bc9e870ffa8cd88397cd694b46664",
            "paperId": "399c03772b2bc9e870ffa8cd88397cd694b46664",
            "title": "Discourse Structure Extraction from Pre-Trained and Fine-Tuned Language Models in Dialogues",
            "abstract": "Discourse processing suffers from data sparsity, especially for dialogues. As a result, we explore approaches to infer latent discourse structures for dialogues, based on attention matrices from Pre-trained Language Models (PLMs). We investigate multiple auxiliary tasks for fine-tuning and show that the dialogue-tailored Sentence Ordering task performs best. To locate and exploit discourse information in PLMs, we propose an unsupervised and a semi-supervised method. Our proposals thereby achieve encouraging results on the STAC corpus, with F1 scores of 57.2 and 59.3 for the unsupervised and semi-supervised methods, respectively. When restricted to projective trees, our scores improved to 63.3 and 68.1.",
            "year": 2023,
            "citationCount": 3,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work proposes an unsupervised and a semi-supervised method to locate and exploit discourse information in Pre-trained Language Models, and investigates multiple auxiliary tasks for fine-tuning and shows that the dialogue-tailored Sentence Ordering task performs best."
            },
            "score": 6
        },
        {
            "id": "961073143d3cfe662e9e820d24c0a88f0ae94c83",
            "paperId": "961073143d3cfe662e9e820d24c0a88f0ae94c83",
            "title": "Document Context Language Models",
            "abstract": "Text documents are structured on multiple levels of detail: individual words are related by syntax, but larger units of text are related by discourse structure. Existing language models generally fail to account for discourse structure, but it is crucial if we are to have language models that reward coherence and generate coherent texts. We present and empirically evaluate a set of multi-level recurrent neural network language models, called Document-Context Language Models (DCLM), which incorporate contextual information both within and beyond the sentence. In comparison with word-level recurrent neural network language models, the DCLM models obtain slightly better predictive likelihoods, and considerably better assessments of document coherence.",
            "year": 2015,
            "citationCount": 88,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A set of multi-level recurrent neural network language models, called Document-Context Language Models (DCLM), which incorporate contextual information both within and beyond the sentence, are presented and empirically evaluated."
            },
            "score": 6
        },
        {
            "id": "1badaf6065aba7b9c3eb6a7a059ad499acecbdd2",
            "paperId": "1badaf6065aba7b9c3eb6a7a059ad499acecbdd2",
            "title": "DiscoPrompt: Path Prediction Prompt Tuning for Implicit Discourse Relation Recognition",
            "abstract": "Implicit Discourse Relation Recognition (IDRR) is a sophisticated and challenging task to recognize the discourse relations between the arguments with the absence of discourse connectives. The sense labels for each discourse relation follow a hierarchical classification scheme in the annotation process (Prasad et al., 2008), forming a hierarchy structure. Most existing works do not well incorporate the hierarchy structure but focus on the syntax features and the prior knowledge of connectives in the manner of pure text classification. We argue that it is more effective to predict the paths inside the hierarchical tree (e.g.,\"Comparison ->Contrast ->however\") rather than flat labels (e.g., Contrast) or connectives (e.g., however). We propose a prompt-based path prediction method to utilize the interactive information and intrinsic senses among the hierarchy in IDRR. This is the first work that injects such structure information into pre-trained language models via prompt tuning, and the performance of our solution shows significant and consistent improvement against competitive baselines.",
            "year": 2023,
            "citationCount": 16,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work proposes a prompt-based path prediction method to utilize the interactive information and intrinsic senses among the hierarchy in IDRR, and is the first work that injects such structure information into pre-trained language models via prompt tuning."
            },
            "score": 6
        },
        {
            "id": "6960918666a8c9d50343bbe9e94baf6415edd5fb",
            "paperId": "6960918666a8c9d50343bbe9e94baf6415edd5fb",
            "title": "Language modeling via stochastic processes",
            "abstract": "Modern language models can generate high-quality short texts. However, they often meander or are incoherent when generating longer texts. These issues arise from the next-token-only language modeling objective. Recent work in self-supervised learning suggests that models can learn good latent representations via contrastive learning, which can be effective for discriminative tasks. Our work analyzes the application of contrastive representations for generative tasks, like long text generation. We propose one approach for leveraging constrastive representations, which we call Time Control (TC). TC first learns a contrastive representation of the target text domain, then generates text by decoding from these representations. Compared to domain-specific methods and fine-tuning GPT2 across a variety of text domains, TC performs competitively to methods specific for learning sentence representations on discourse coherence. On long text generation settings, TC preserves the text structure both in terms of ordering (up to $+15\\%$ better) and text length consistency (up to $+90\\%$ better).",
            "year": 2022,
            "citationCount": 21,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work analyzes the application of contrastive representations for generative tasks, like long text generation, and proposes one approach, which is called Time Control (TC), which first learns a contrastive representation of the target text domain, then generates text by decoding from these representations."
            },
            "score": 6
        },
        {
            "id": "31497c9d8ef07b6992896ef16e2f9b2fd9e08d0c",
            "paperId": "31497c9d8ef07b6992896ef16e2f9b2fd9e08d0c",
            "title": "Towards Discourse-Aware Document-Level Neural Machine Translation",
            "abstract": "Current document-level neural machine translation (NMT) systems have achieved remarkable progress with document context. Nevertheless, discourse information that has been proven effective in many NLP tasks is ignored in most previous work. In this work, we aim at incorporating the coherence information hidden within the RST-style discourse structure into machine translation. To achieve it, we propose a document-level NMT system enhanced with the discourse-aware document context, which is named Disco2NMT. Specifically, Disco2NMT models document context based on the discourse dependency structures through a hierarchical architecture. We first convert the RST tree of an article into a dependency structure and then build the graph convolutional network (GCN) upon the segmented EDUs under the guidance of RST dependencies to capture the discourse-aware context for NMT incorporation. We conduct experiments on the document-level English-German and English-Chinese translation tasks with three domains (TED, News, and Europarl). Experimental results show that our Disco2NMT model significantly surpasses both context-agnostic and context-aware baseline systems on multiple evaluation indicators.",
            "year": 2022,
            "citationCount": 3,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work proposes a document-level NMT system enhanced with the discourse-aware document context, which is named Disco2NMT, which significantly surpasses both context-agnostic and context-aware baseline systems on multiple evaluation indicators."
            },
            "score": 6
        },
        {
            "id": "a0f413552f5783581f305af4674e8ce7caf0490f",
            "paperId": "a0f413552f5783581f305af4674e8ce7caf0490f",
            "title": "Assessing Discourse Relations in Language Generation from GPT-2",
            "abstract": "Recent advances in NLP have been attributed to the emergence of large-scale pre-trained language models. GPT-2, in particular, is suited for generation tasks given its left-to-right language modeling objective, yet the linguistic quality of its generated text has largely remain unexplored. Our work takes a step in understanding GPT-2\u2019s outputs in terms of discourse coherence. We perform a comprehensive study on the validity of explicit discourse relations in GPT-2\u2019s outputs under both organic generation and fine-tuned scenarios. Results show GPT-2 does not always generate text containing valid discourse relations; nevertheless, its text is more aligned with human expectation in the fine-tuned scenario. We propose a decoupled strategy to mitigate these problems and highlight the importance of explicitly modeling discourse information.",
            "year": 2020,
            "citationCount": 14,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A comprehensive study on the validity of explicit discourse relations in GPT-2\u2019s outputs under both organic generation and fine-tuned scenarios and proposes a decoupled strategy to mitigate these problems and highlight the importance of explicitly modeling discourse information."
            },
            "score": 6
        },
        {
            "id": "451788cf6329f3258676118bc188c5bd69803d80",
            "paperId": "451788cf6329f3258676118bc188c5bd69803d80",
            "title": "Multi-Task Learning for Coherence Modeling",
            "abstract": "We address the task of assessing discourse coherence, an aspect of text quality that is essential for many NLP tasks, such as summarization and language assessment. We propose a hierarchical neural network trained in a multi-task fashion that learns to predict a document-level coherence score (at the network\u2019s top layers) along with word-level grammatical roles (at the bottom layers), taking advantage of inductive transfer between the two tasks. We assess the extent to which our framework generalizes to different domains and prediction tasks, and demonstrate its effectiveness not only on standard binary evaluation coherence tasks, but also on real-world tasks involving the prediction of varying degrees of coherence, achieving a new state of the art.",
            "year": 2019,
            "citationCount": 24,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A hierarchical neural network trained in a multi-task fashion that learns to predict a document-level coherence score along with word-level grammatical roles (at the network\u2019s top layers) taking advantage of inductive transfer between the two tasks is proposed."
            },
            "score": 6
        },
        {
            "id": "a8c48ecd6aac3130f300345cb451c6ed68d2cc50",
            "paperId": "a8c48ecd6aac3130f300345cb451c6ed68d2cc50",
            "title": "Pretraining with Contrastive Sentence Objectives Improves Discourse Performance of Language Models",
            "abstract": "Recent models for unsupervised representation learning of text have employed a number of techniques to improve contextual word representations but have put little focus on discourse-level representations. We propose Conpono, an inter-sentence objective for pretraining language models that models discourse coherence and the distance between sentences. Given an anchor sentence, our model is trained to predict the text k sentences away using a sampled-softmax objective where the candidates consist of neighboring sentences and sentences randomly sampled from the corpus. On the discourse representation benchmark DiscoEval, our model improves over the previous state-of-the-art by up to 13% and on average 4% absolute across 7 tasks. Our model is the same size as BERT-Base, but outperforms the much larger BERT-Large model and other more recent approaches that incorporate discourse. We also show that Conpono yields gains of 2%-6% absolute even for tasks that do not explicitly evaluate discourse: textual entailment (RTE), common sense reasoning (COPA) and reading comprehension (ReCoRD).",
            "year": 2020,
            "citationCount": 68,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Conpono, an inter-sentence objective for pretraining language models that models discourse coherence and the distance between sentences is proposed, and it is shown that Conpono yields gains of 2%-6% absolute even for tasks that do not explicitly evaluate discourse: textual entailment, common sense reasoning and reading comprehension."
            },
            "score": 5
        },
        {
            "id": "798c61b2b985e918a74b9aa154e6bc3f01040763",
            "paperId": "798c61b2b985e918a74b9aa154e6bc3f01040763",
            "title": "Long Text Generation by Modeling Sentence-Level and Discourse-Level Coherence",
            "abstract": "Generating long and coherent text is an important but challenging task, particularly for open-ended language generation tasks such as story generation. Despite the success in modeling intra-sentence coherence, existing generation models (e.g., BART) still struggle to maintain a coherent event sequence throughout the generated text. We conjecture that this is because of the difficulty for the decoder to capture the high-level semantics and discourse structures in the context beyond token-level co-occurrence. In this paper, we propose a long text generation model, which can represent the prefix sentences at sentence level and discourse level in the decoding process. To this end, we propose two pretraining objectives to learn the representations by predicting inter-sentence semantic similarity and distinguishing between normal and shuffled sentence orders. Extensive experiments show that our model can generate more coherent texts than state-of-the-art baselines.",
            "year": 2021,
            "citationCount": 58,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A long text generation model, which can represent the prefix sentences at sentence level and discourse level in the decoding process, and two pretraining objectives to learn the representations by predicting inter-sentence semantic similarity and distinguishing between normal and shuffled sentence orders."
            },
            "score": 5
        },
        {
            "id": "07cf32655f229ed0bfa76aad7e1afc60ea5bc9a5",
            "paperId": "07cf32655f229ed0bfa76aad7e1afc60ea5bc9a5",
            "title": "DYPLOC: Dynamic Planning of Content Using Mixed Language Models for Text Generation",
            "abstract": "We study the task of long-form opinion text generation, which faces at least two distinct challenges. First, existing neural generation models fall short of coherence, thus requiring efficient content planning. Second, diverse types of information are needed to guide the generator to cover both subjective and objective content. To this end, we propose DYPLOC, a generation framework that conducts dynamic planning of content while generating the output based on a novel design of mixed language models. To enrich the generation with diverse content, we further propose to use large pre-trained models to predict relevant concepts and to generate claims. We experiment with two challenging tasks on newly collected datasets: (1) argument generation with Reddit ChangeMyView, and (2) writing articles using New York Times\u2019 Opinion section. Automatic evaluation shows that our model significantly outperforms competitive comparisons. Human judges further confirm that our generations are more coherent with richer content.",
            "year": 2021,
            "citationCount": 18,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "DYPLOC is proposed, a generation framework that conducts dynamic planning of content while generating the output based on a novel design of mixed language models that significantly outperforms competitive comparisons and human judges confirm that the generations are more coherent with richer content."
            },
            "score": 5
        },
        {
            "id": "cc1db851e3881be28564aca2ef0fecae133c45a1",
            "paperId": "cc1db851e3881be28564aca2ef0fecae133c45a1",
            "title": "Boosting coherence of language models",
            "abstract": "Naturality of long-term information structure \u2013 coherence \u2013 remains a challenge in language generation. Large language models have insuf-\ufb01ciently learned such structure, as their long-form generations differ from natural text in measures of coherence. To alleviate this divergence, we propose coherence boosting , an inference procedure that increases the effect of distant context on next-token prediction. We show the bene\ufb01ts of coherence boosting with pretrained models by distributional analyses of generated ordinary text and dialog responses. We also \ufb01nd that coherence boosting with state-of-the-art models for various zero-shot NLP tasks yields performance gains with no additional training.",
            "year": 2021,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "It is shown that coherence boosting with state-of-the-art models for various zero-shot NLP tasks yields performance gains with no additional training."
            },
            "score": 5
        },
        {
            "id": "4449b78444844917f52b88be02e5d902e384a494",
            "paperId": "4449b78444844917f52b88be02e5d902e384a494",
            "title": "A bird's-eye view on coherence, and a worm's-eye view on cohesion",
            "abstract": "Generating coherent and cohesive long-form texts is a challenging problem in natural language generation. Previous works relied on a large amount of human-generated texts to train language models, however, few attempted to explicitly model the desired linguistic properties of natural language text, such as coherence and cohesion. In this work, we train two expert discriminators for coherence and cohesion, respectively, to provide hierarchical feedback for text generation. We also propose a simple variant of policy gradient, called 'negative-critical sequence training', using margin rewards, in which the 'baseline' is constructed from randomly generated negative samples. We demonstrate the effectiveness of our approach through empirical studies, showing significant improvements over the strong baseline -- attention-based bidirectional MLE-trained neural language model -- in a number of automated metrics. The proposed discriminators can serve as baseline architectures to promote further research to better extract, encode essential linguistic qualities, such as coherence and cohesion.",
            "year": 2018,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work trains two expert discriminators for coherence and cohesion, respectively, to provide hierarchical feedback for text generation and proposes a simple variant of policy gradient, called 'negative-critical sequence training', in which the 'baseline' is constructed from randomly generated negative samples."
            },
            "score": 5
        },
        {
            "id": "4dc3683fa223d160045bca575a8b5ecf94f61604",
            "paperId": "4dc3683fa223d160045bca575a8b5ecf94f61604",
            "title": "Coherent Long Text Generation by Contrastive Soft Prompt",
            "abstract": "Improving the coherence of long text generation is an important but challenging task. Existing models still struggle to generate a logical and coherent sentence sequence. It is difficult for a model to plan long text generation and avoid generating incoherent texts from a high-level semantic perspective. We speculate that this is due to two factors: (1) current training methods mainly rely on maximum likelihood estimation computed from token-level probability prediction; (2) the role of incoherent texts has been largely under-explored, thus the noised generated texts with errors are out-of-distribution for the model. To address these issues, in this paper, we propose a Contrastive Soft Prompt (CSP) model for improving the coherence of long text generation. It learns text representations in the hidden space for better planning long text generation. To this end, it jointly learns to generate a text representation close to representations of coherent texts and away from incoherent ones, and then generate long text taking this representation as the soft prompt. We conduct experiments on two public story generation datasets, and experiment results show that our method can generate more coherent stories than the state-of-the-art model.",
            "year": 2022,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A Contrastive Soft Prompt model is proposed for improving the coherence of long text generation that jointly learns to generate a text representation close to representations of coherent texts and away from incoherent ones, and then generates long text taking this representation as the soft prompt."
            },
            "score": 5
        },
        {
            "id": "14f78c24d5da77835ac4e80de3daa7bc9e92f0a8",
            "paperId": "14f78c24d5da77835ac4e80de3daa7bc9e92f0a8",
            "title": "Discourse structure interacts with reference but not syntax in neural language models",
            "abstract": "Language models (LMs) trained on large quantities of text have been claimed to acquire abstract linguistic representations. Our work tests the robustness of these abstractions by focusing on the ability of LMs to learn interactions between different linguistic representations. In particular, we utilized stimuli from psycholinguistic studies showing that humans can condition reference (i.e. coreference resolution) and syntactic processing on the same discourse structure (implicit causality). We compared both transformer and long short-term memory LMs to find that, contrary to humans, implicit causality only influences LM behavior for reference, not syntax, despite model representations that encode the necessary discourse information. Our results further suggest that LM behavior can contradict not only learned representations of discourse but also syntactic agreement, pointing to shortcomings of standard language modeling.",
            "year": 2020,
            "citationCount": 17,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work utilized stimuli from psycholinguistic studies showing that humans can condition reference and syntactic processing on the same discourse structure to find that, contrary to humans, implicit causality only influences LM behavior for reference, not syntax, despite model representations that encode the necessary discourse information."
            },
            "score": 5
        },
        {
            "id": "a0b3bbb635119bd3987753ae80bf94b70c6a77ab",
            "paperId": "a0b3bbb635119bd3987753ae80bf94b70c6a77ab",
            "title": "Unleashing the Power of Neural Discourse Parsers - A Context and Structure Aware Approach Using Large Scale Pretraining",
            "abstract": "RST-based discourse parsing is an important NLP task with numerous downstream applications, such as summarization, machine translation and opinion mining. In this paper, we demonstrate a simple, yet highly accurate discourse parser, incorporating recent contextual language models. Our parser establishes the new state-of-the-art (SOTA) performance for predicting structure and nuclearity on two key RST datasets, RST-DT and Instr-DT. We further demonstrate that pretraining our parser on the recently available large-scale \u201csilver-standard\u201d discourse treebank MEGA-DT provides even larger performance benefits, suggesting a novel and promising research direction in the field of discourse analysis.",
            "year": 2020,
            "citationCount": 10,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A simple, yet highly accurate discourse parser, incorporating recent contextual language models, that establishes the new state-of-the-art (SOTA) performance for predicting structure and nuclearity on two key RST datasets, RST-DT and Instr-DT."
            },
            "score": 5
        },
        {
            "id": "860859849b22393fe468efd6768904416d5f10f2",
            "paperId": "860859849b22393fe468efd6768904416d5f10f2",
            "title": "RST Discourse Parsing with Second-Stage EDU-Level Pre-training",
            "abstract": "Pre-trained language models (PLMs) have shown great potentials in natural language processing (NLP) including rhetorical structure theory (RST) discourse parsing.Current PLMs are obtained by sentence-level pre-training, which is different from the basic processing unit, i.e. element discourse unit (EDU).To this end, we propose a second-stage EDU-level pre-training approach in this work, which presents two novel tasks to learn effective EDU representations continually based on well pre-trained language models.Concretely, the two tasks are (1) next EDU prediction (NEP) and (2) discourse marker prediction (DMP).We take a state-of-the-art transition-based neural parser as baseline, and adopt it with a light bi-gram EDU modification to effectively explore the EDU-level pre-trained EDU representation.Experimental results on a benckmark dataset show that our method is highly effective,leading a 2.1-point improvement in F1-score.All codes and pre-trained models will be released publicly to facilitate future studies.",
            "year": 2022,
            "citationCount": 16,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work takes a state-of-the-art transition-based neural parser as baseline, and adopts it with a light bi-gram EDU modification to effectively explore the EDU-level pre-trained EDU representation."
            },
            "score": 5
        },
        {
            "id": "13c0b6eeac903f48a5fc270a47ece52a0e8344be",
            "paperId": "13c0b6eeac903f48a5fc270a47ece52a0e8344be",
            "title": "Discourse Analysis via Questions and Answers: Parsing Dependency Structures of Questions Under Discussion",
            "abstract": "Automatic discourse processing is bottlenecked by data: current discourse formalisms pose highly demanding annotation tasks involving large taxonomies of discourse relations, making them inaccessible to lay annotators. This work instead adopts the linguistic framework of Questions Under Discussion (QUD) for discourse analysis and seeks to derive QUD structures automatically. QUD views each sentence as an answer to a question triggered in prior context; thus, we characterize relationships between sentences as free-form questions, in contrast to exhaustive fine-grained taxonomies. We develop the first-of-its-kind QUD parser that derives a dependency structure of questions over full documents, trained using a large, crowdsourced question-answering dataset DCQA (Ko et al., 2022). Human evaluation results show that QUD dependency parsing is possible for language models trained with this crowdsourced, generalizable annotation scheme. We illustrate how our QUD structure is distinct from RST trees, and demonstrate the utility of QUD analysis in the context of document simplification. Our findings show that QUD parsing is an appealing alternative for automatic discourse processing.",
            "year": 2022,
            "citationCount": 4,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work adopts the linguistic framework of Questions Under Discussion (QUD) for discourse analysis and seeks to derive QUD structures automatically, developing the first-of-its-kind QUD parser that derives a dependency structure of questions over full documents, trained using a large, crowdsourced question-answering dataset DCQA."
            },
            "score": 5
        },
        {
            "id": "b141b78e77fa22e46e3085197b5c1001874ed4d9",
            "paperId": "b141b78e77fa22e46e3085197b5c1001874ed4d9",
            "title": "An Analysis Model of English Text Coherence Based on RST Dependency Relationship",
            "abstract": "Text coherence analysis is an important and challenging task that is essential for subtasks such as automatic summarisation, viewpoint extraction and machine translation in natural language processing (NLP). A large body of previous work has used linguistic features such as lexical, syntactic and entity features to capture relatively shallow coherence features, while ignoring deeper logically relevant features hidden in the text. We propose an end-to-end English text coherence analysis model (RGCM for short) that incorporates RST and graph convolutional neural networks (GCN). The intra- and inter-sentence logical relations of the input text are first mapped onto a discourse relationship tree, and then transformed into an RST-dependent context graph by certain pruning strategies. Subsequently, we propose a GCN-based text coherence assessment framework to capture intra- and inter-sentence interactions to assess text coherence. We conducted experiments on two different coherence assessment datasets and achieved accuracy rates of 95.5% and 97.8% respectively.",
            "year": 2023,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work proposes an end-to-end English text coherence analysis model (RGCM for short) that incorporates RST and graph convolutional neural networks (GCN) to capture intra- and inter-sentence interactions to assessText coherence."
            },
            "score": 5
        },
        {
            "id": "7cc2aac18db1493142240ae3982dce688e856f58",
            "paperId": "7cc2aac18db1493142240ae3982dce688e856f58",
            "title": "Discourse-Aware Prompt for Argument Impact Classification",
            "abstract": "Discourse information behind the arguments attracts a lot of attention from the field of Natural Language Processing (NLP) and computational argumentation. Durmus et al. [10] launched a new study on the influence of discourse contexts on determining argument impact. Argument Impact Classification is an intriguing but challenging task to classify whether the argumentative unit or an argument is impactful in a conversation. This paper empirically demonstrates that the discourse marker (e.g., \"for example,\" \"in other words\") can be represented by the learnable continuous prompt to align with discourse information existing in Pre-trained Language Model (PLM). This discourse information helps the Pre-trained Language Model understand the input template and elicit the discourse information to improve the performance on this task. Therefore, based on this intuition, we propose a prompt model DAPA and surpass the previous state-of-the-art model with a 2.5% F1 score.",
            "year": 2023,
            "citationCount": 6,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper empirically demonstrates that the discourse marker can be represented by the learnable continuous prompt to align with discourse information existing in Pre-trained Language Model (PLM) and proposes a prompt model DAPA to surpass the previous state-of-the-art model."
            },
            "score": 5
        },
        {
            "id": "cc53d235f7757983b17d9d2a1b63b0a94c9b695a",
            "paperId": "cc53d235f7757983b17d9d2a1b63b0a94c9b695a",
            "title": "A Language Model-based Generative Classifier for Sentence-level Discourse Parsing",
            "abstract": "Discourse segmentation and sentence-level discourse parsing play important roles for various NLP tasks to consider textual coherence. Despite recent achievements in both tasks, there is still room for improvement due to the scarcity of labeled data. To solve the problem, we propose a language model-based generative classifier (LMGC) for using more information from labels by treating the labels as an input while enhancing label representations by embedding descriptions for each label. Moreover, since this enables LMGC to make ready the representations for labels, unseen in the pre-training step, we can effectively use a pre-trained language model in LMGC. Experimental results on the RST-DT dataset show that our LMGC achieved the state-of-the-art F1 score of 96.72 in discourse segmentation. It further achieved the state-of-the-art relation F1 scores of 84.69 with gold EDU boundaries and 81.18 with automatically segmented boundaries, respectively, in sentence-level discourse parsing.",
            "year": 2021,
            "citationCount": 7,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A language model-based generative classifier (LMGC) for using more information from labels by treating the labels as an input while enhancing label representations by embedding descriptions for each label is proposed."
            },
            "score": 5
        },
        {
            "id": "428d1773377c3b6976f4738b678813617189a135",
            "paperId": "428d1773377c3b6976f4738b678813617189a135",
            "title": "Can we obtain significant success in RST discourse parsing by using Large Language Models?",
            "abstract": "Recently, decoder-only pre-trained large language models (LLMs), with several tens of billion parameters, have significantly impacted a wide range of natural language processing (NLP) tasks. While encoder-only or encoder-decoder pre-trained language models have already proved to be effective in discourse parsing, the extent to which LLMs can perform this task remains an open research question. Therefore, this paper explores how beneficial such LLMs are for Rhetorical Structure Theory (RST) discourse parsing. Here, the parsing process for both fundamental top-down and bottom-up strategies is converted into prompts, which LLMs can work with. We employ Llama 2 and fine-tune it with QLoRA, which has fewer parameters that can be tuned. Experimental results on three benchmark datasets, RST-DT, Instr-DT, and the GUM corpus, demonstrate that Llama 2 with 70 billion parameters in the bottom-up strategy obtained state-of-the-art (SOTA) results with significant differences. Furthermore, our parsers demonstrated generalizability when evaluated on RST-DT, showing that, in spite of being trained with the GUM corpus, it obtained similar performances to those of existing parsers trained with RST-DT.",
            "year": 2024,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper employs Llama 2 and fine-tune it with QLoRA, which has fewer parameters that can be tuned, and demonstrates generalizability when evaluated on RST-DT, showing that, in spite of being trained with the GUM corpus, it obtained similar performances to those of existing parsers trained with RST-DT."
            },
            "score": 5
        },
        {
            "id": "da7f9e6416d952355d1d4974f0b73296719915f1",
            "paperId": "da7f9e6416d952355d1d4974f0b73296719915f1",
            "title": "Coherent or Not? Stressing a Neural Language Model for Discourse Coherence in Multiple Languages",
            "abstract": "In this study, we investigate the capability of a Neural Language Model (NLM) to distinguish between coherent and incoherent text, where the latter has been artificially created to gradually undermine local coherence within text. While previous research on coherence assessment using NLMs has primarily focused on English, we extend our investigation to multiple languages. We employ a consistent evaluation framework to compare the performance of monolingual and multilingual models in both in-domain and out-domain settings. Additionally, we explore the model\u2019s performance in a cross-language scenario.",
            "year": 2023,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": null
            },
            "score": 4
        },
        {
            "id": "f6e28a79e90e517c6839d5d52a189bba9f54e13c",
            "paperId": "f6e28a79e90e517c6839d5d52a189bba9f54e13c",
            "title": "Is Incoherence Surprising? Targeted Evaluation of Coherence Prediction from Language Models",
            "abstract": "Coherent discourse is distinguished from a mere collection of utterances by the satisfaction of a diverse set of constraints, for example choice of expression, logical relation between denoted events, and implicit compatibility with world-knowledge. Do neural language models encode such constraints? We design an extendable set of test suites addressing different aspects of discourse and dialogue coherence. Unlike most previous coherence evaluation studies, we address specific linguistic devices beyond sentence order perturbations, which allow for a more fine-grained analysis of what constitutes coherence and what neural models trained on a language modelling objective are capable of encoding. Extending the targeted evaluation paradigm for neural language models (Marvin and Linzen, 2018) to phenomena beyond syntax, we show that this paradigm is equally suited to evaluate linguistic qualities that contribute to the notion of coherence.",
            "year": 2021,
            "citationCount": 11,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work addresses specific linguistic devices beyond sentence order perturbations, which allow for a more fine-grained analysis of what constitutes coherence and what neural models trained on a language modelling objective are capable of encoding."
            },
            "score": 4
        },
        {
            "id": "1ec7ed69af38c6c3e2273b2a424325eccd510347",
            "paperId": "1ec7ed69af38c6c3e2273b2a424325eccd510347",
            "title": "Assessing Discourse Relations in Language Generation from Pre-trained Language Models",
            "abstract": "Recent advances in NLP have been attributed to the emergence of large-scale pre-trained language models. GPT-2, in particular, is suited for generation tasks given its left-to-right language modeling objective, yet the linguistic quality of its generated text has largely remain unexplored. Our work takes a step in understanding GPT-2's outputs in terms of discourse coherence. We perform a comprehensive study on the validity of explicit discourse relations in GPT-2's outputs under both organic generation and fine-tuned scenarios. Results show GPT-2 does not always generate text containing valid discourse relations; nevertheless, its text is more aligned with human expectation in the fine-tuned scenario. We propose a decoupled strategy to mitigate these problems and highlight the importance of explicitly modeling discourse information.",
            "year": 2020,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Results show GPT-2 does not always generate text containing valid discourse relations; nevertheless, its text is more aligned with human expectation in the fine-tuned scenario."
            },
            "score": 4
        },
        {
            "id": "76c5fb418e08af37238d21ca9d6f18c45fc59fb9",
            "paperId": "76c5fb418e08af37238d21ca9d6f18c45fc59fb9",
            "title": "A Discourse Coherence Analysis Method Combining Sentence Embedding and Dimension Grid",
            "abstract": "Discourse coherence is strongly associated with text quality, making it important to natural language generation and understanding. However, existing coherence models focus on measuring individual aspects of coherence, such as lexical overlap, entity centralization, rhetorical structure, etc., lacking measurement of the semantics of text. In this paper, we propose a discourse coherence analysis method combining sentence embedding and the dimension grid, we obtain sentence-level vector representation by deep learning, and we introduce a coherence model that captures the fine-grained semantic transitions in text. Our work is based on the hypothesis that each dimension in the embedding vector is exactly assigned a stated certainty and specific semantic. We take every dimension as an equal grid and compute its transition probabilities. The document feature vector is also enriched to model the coherence. Finally, the experimental results demonstrate that our method achieves excellent performance on two coherence-related tasks.",
            "year": 2021,
            "citationCount": 2,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A discourse coherence analysis method combining sentence embedding and the dimension grid is proposed, sentence-level vector representation by deep learning is obtained, and a coherence model is introduced that captures the fine-grained semantic transitions in text."
            },
            "score": 4
        },
        {
            "id": "d9d12205007ac48b03d921225f9cdaf90f7c3fdd",
            "paperId": "d9d12205007ac48b03d921225f9cdaf90f7c3fdd",
            "title": "Model Criticism for Long-Form Text Generation",
            "abstract": "Language models have demonstrated the ability to generate highly fluent text; however, it remains unclear whether their output retains coherent high-level structure (e.g., story progression). Here, we propose to apply a statistical tool, model criticism in latent space, to evaluate the high-level structure of the generated text. Model criticism compares the distributions between real and generated data in a latent space obtained according to an assumptive generative process. Different generative processes identify specific failure modes of the underlying model. We perform experiments on three representative aspects of high-level discourse\u2014coherence, coreference, and topicality\u2014and find that transformer-based language models are able to capture topical structures but have a harder time maintaining structural coherence or modeling coreference.",
            "year": 2022,
            "citationCount": 12,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work proposes to apply a statistical tool, model criticism in latent space, to evaluate the high-level structure of the generated text and finds that transformer-based language models are able to capture topical structures but have a harder time maintaining structural coherence or modeling coreference."
            },
            "score": 4
        },
        {
            "id": "15c71781c88c60dbe923a22b4d73e9251347e2c2",
            "paperId": "15c71781c88c60dbe923a22b4d73e9251347e2c2",
            "title": "Fixed global memory for controllable long text generation",
            "abstract": null,
            "year": 2022,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A novel Transformer architecture called Transformer with Local and Global Memory (Transformer LGM), inspired by the way people write long articles, which could generate long, coherent, and consistent text without enlarging the length of the language model."
            },
            "score": 4
        },
        {
            "id": "94cd4b12fd5cdd0656b3421efc2129ea93f69856",
            "paperId": "94cd4b12fd5cdd0656b3421efc2129ea93f69856",
            "title": "Discourse-Wizard: Discovering Deep Discourse Structure in your Conversation with RNNs",
            "abstract": "Spoken language understanding is one of the key factors in a dialogue system, and a context in a conversation plays an important role to understand the current utterance. In this work, we demonstrate the importance of context within the dialogue for neural network models through an online web interface live demo. We developed two different neural models: a model that does not use context and a context-based model. The no-context model classifies dialogue acts at an utterance-level whereas the context-based model takes some preceding utterances into account. We make these trained neural models available as a live demo called Discourse-Wizard using a modular server architecture. The live demo provides an easy to use interface for conversational analysis and for discovering deep discourse structures in a conversation.",
            "year": 2018,
            "citationCount": 6,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work developed two different neural models: a model that does not use context and a context-based model, which classifies dialogue acts at an utterance-level whereas the context- based model takes some preceding utterances into account."
            },
            "score": 4
        },
        {
            "id": "1a84a87dfccab3e34c6e30bfcaf750792fd23666",
            "paperId": "1a84a87dfccab3e34c6e30bfcaf750792fd23666",
            "title": "Language Models With Meta-information",
            "abstract": "Language modeling plays a critical role in natural language processing and understanding. Starting from a general structure, language models are able to learn natural language patterns from rich input data. However, the state-of-the-art language models only take advantage of words themselves, which are not sufficient to characterize the language. In this thesis, we improve recurrent neural network language models (RNNLM) by training them with additional information. Different methods of integrating the different types of additional information into RNNLMs are proposed in this thesis. All the potential information beyond the word itself that can be used to characterize the language is called meta-information. In this thesis, we propose to use different types of meta-information to represent languages such as discourse level information, which is reflected from the whole discourse, sentence level information which characterize the patterns of sentences and morphological information which represents the word from different perspectives. For example, we consider the following Dutch paragraph. represents sentence beginning. stands for the sentence ending. kan allemaal nog natuurlijk maar ze ontlopen dan de groepswinnaar in elk geval in de kwartfinale en vooral Nederland wil graag in Rotterdam die kwartfinale spelen en dan moet er groepswinst behaald worden anders verhuizen ze naar Brugge en krijgt het Jan Breydelstadion Oranje dus op bezoek we gaan er even uit slotfase zit eraan te komen twee minuten nog tot het einde plus de toegevoegde tijd dat is uh toch nog ook wel een paar minuten denk ik maar de wedstrijd is gespeeld On the discourse level, this paragraph is labeled as \u201cLive commentaries (broadcast)\u201d from the socio-situational setting (SSS) perspective and \u201csport\u201d from the topic perspective. On the sentence level, each word except for the beginning word and ending word , is annotated with its preceding word information and succeeding word information. For example, we consider word \u201cslotfase\u201d in the following sentence. slotfase zit eraan te komen . This word has preceding information \u201c \u201d and succeeding information \u201czit eraan te komen \u201d. On the word level, the word \u201cslotfase\u201d is annotated by a vector containing some of the proposed meta-information. On the discourse level, we investigate classification methods for socio-situational settings and topics. On the sentence level, in this thesis, we focus on information such as succeeding words information and whole sentence information. In this thesis, each word is annotated by a vector containing the meta-information collected. Different methods are proposed in this thesis to integrate the meta-information into language models. On the discourse level, a curriculum learning method has been used to combine the socio-situational settings and topics. On the sentence level, forward-backward recurrent neural network language models have been proposed to integrate the succeeding word information and whole sentence information into language models. On the word level, each word has been conditioned on its preceding words as well as on preceding meta-information. The results reported in this thesis show that meta-information can be used to improve the effectiveness of language models at the cost of increasing training time. In this thesis, we address this problem by applying parallel processing techniques. A subsampling stochastic gradient descent algorithm has been proposed to accelerate the training of recurrent neural network language models.",
            "year": 2014,
            "citationCount": 31,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The results reported in this thesis show that meta-information can be used to improve the effectiveness of language models at the cost of increasing training time, and a subsampling stochastic gradient descent algorithm has been proposed to accelerate the training of recurrent neural network language models."
            },
            "score": 4
        },
        {
            "id": "c3f09349eb7823ecf4375456323cf2bc727364da",
            "paperId": "c3f09349eb7823ecf4375456323cf2bc727364da",
            "title": "Classification Models for RST Discourse Parsing of Texts in Russian",
            "abstract": "The paper considers the task of automatic discourse parsing of texts in Russian. Discourse parsing is a well-known approach to capturing text semantics across boundaries of single sentences. Discourse annotation was found to be useful for various tasks including summarization, sentiment analysis, question-answering. Recently, the release of manually annotated Ru-RSTreebank corpus unlocked the possibility of leveraging supervised machine learning techniques for creating such parsers for Russian language. The corpus provides the discourse annotation in a widely adopted formalisation \u2013 Rhetorical Structure Theory. In this work, we develop feature sets for rhetorical relation classification in Russian-language texts, investigate importance of various types of features, and report results of the first experimental evaluation of machine learning models trained on Ru-RSTreebank corpus. We consider various machine learning methods including gradient boosting, neural network, and ensembling of several models by soft voting.",
            "year": 2019,
            "citationCount": 3,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": null
            },
            "score": 4
        },
        {
            "id": "451cd66130ff4e17d69c81e93f704f48e606e8c7",
            "paperId": "451cd66130ff4e17d69c81e93f704f48e606e8c7",
            "title": "Cohesion and Coherence Analyses of Extended Written Schizophrenic Discourse: An Exploratory Case Study",
            "abstract": "Schizophrenic discourse is characterized by thought disorder, or a lack of coherence, prompting substantial research into identifying and measuring the incoherent discourse of schizophrenics. Much of this research has examined short extracts of elicited spoken data and used researcher judgments. This study examines the connectedness of naturally-occurring extensive written schizophrenic discourse using three methods of analysis: an automated analysis of cohesion, lexical cohesion analysis, and topic-based analysis focusing on propositional coherence. The results show that the schizophrenic texts are highly cohesive, especially in their use of connectives and the density of connections. The texts also show high proportions of topic shifts and a greater average distance of moves between concepts. These suggest that the topic structure of the schizophrenic texts consists predominantly of repetitive topic maintenance interspersed with short unrelated mini-topics, and it is this structure that manifests thought disorder.",
            "year": 2023,
            "citationCount": 0,
            "tldr": null,
            "score": 4
        },
        {
            "id": "0019759a51a1d261e2e90aeafb53c5a1bc62a8e4",
            "paperId": "0019759a51a1d261e2e90aeafb53c5a1bc62a8e4",
            "title": "An analysis of the relationship between cohesion and clause combination in English discourse employing NLP and data mining approaches",
            "abstract": "This study examines the relationship between the frequencies of clause combination and the distribution of discourse-pragmatic markers of cohesion in a subsample of the Susanne corpus. It addresses the theory that clause grammar constitutes a form of grammar-cued discourse coherence which functions as an integrated system with other methods of managing coherence in language. Evidence is sought for whether increased clause density in a corpus correlates with a reduction in explicit cohesive devices. To address this, a computational approach is outlined for the coding of cohesion in a corpus, using a semi-automated data mining procedure. To validate this approach, it is compared with cohesion measures on the same data using the NLP tool Coh-Metrix 3.0. The two approaches are shown to positively correlate on a series of measures, suggesting they significantly overlap in quantifying the cohesion construct. The final analysis of the tagged corpus indicates that as frequencies of clause combination increase in a text, the use of explicit lexical cohesive devices decrease. Also, higher frequencies of clause combination positively correlate with an increased use of grammatical cohesive devices. Findings are interpreted as generally aligning with the expectations of the theoretical framework known as the Adaptive Approach to Grammar.",
            "year": 2015,
            "citationCount": 3,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Analysis of the relationship between the frequencies of clause combination and the distribution of discourse-pragmatic markers of cohesion in a subsample of the Susanne corpus indicates that as frequencies of clauses combination increase in a text, the use of explicit lexical cohesive devices decrease."
            },
            "score": 4
        },
        {
            "id": "ea8a8265fc6083d9abf225581d1ae2ecfff6a8b4",
            "paperId": "ea8a8265fc6083d9abf225581d1ae2ecfff6a8b4",
            "title": "Automated Subjective Answer Evaluation Using NLP",
            "abstract": ": This study has been undertaken to investigate the determinants of Natural Language Processing (NLP) is one of the important issues of concern in giving computers the ability to understand text and speech in much the same way human beings can. NLP can be used in subjective answer evaluation in various ways. One of the most common approaches is to use NLP techniques to automatically score the quality of a written response based on its language features, such as grammar, syntax, vocabulary, and coherence. This can be done by training machine learning algorithms on a large dataset of human-scored essays or short answer responses, using the language features mentioned above as input features, and the corresponding scores as target values. The trained model can then be used to automatically score new responses based on their language features. Another approach is to use NLP techniques to analyze the content and structure of the response, in order to identify key concepts and arguments and assess their relevance and coherence with the question prompt. This can be done by using techniques such as topic modelling, sentiment analysis, and text classification. Overall, NLP can be a powerful tool for subjective answer evaluation, as it can help to improve the efficiency and consistency of the grading process, while also providing valuable insights into the language and reasoning skills of the students.",
            "year": 2023,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Natural Language Processing can be a powerful tool for subjective answer evaluation, as it can help to improve the efficiency and consistency of the grading process, while also providing valuable insights into the language and reasoning skills of the students."
            },
            "score": 4
        },
        {
            "id": "70f05d02921ad93ce1cddf8a993ff95a7ffd3ffa",
            "paperId": "70f05d02921ad93ce1cddf8a993ff95a7ffd3ffa",
            "title": "Discourse coherence and its relation with cognition in Alzheimer's disease",
            "abstract": "This study investigates discourse coherence and its relation with cognitive deficits in Alzheimer\u2019s disease (AD). Participants consisted, in two groups of individuals, 18 with AD in the moderate and moderate severe stages of cognitive decline, and 16 older adults without dementia matched by age, sex and education. Discourse tasks differed according to the presence of non-informative and informa- tive prompts. Verbal comprehension, semantic memory, episodic memory and working memory were tested. Findings showed that global coherence was affected in AD participants. Correlations between discourse and cognitive variables were observed. The strongest correlations found related global coherence to episodic and semantic memory in the informative prompt task. Results are discussed according to clinical and theoretical implications for the understanding of discourse production in AD.",
            "year": 2013,
            "citationCount": 17,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Investigation of discourse coherence and its relation with cognitive deficits in Alzheimer\u2019s disease showed that global coherence was affected in AD participants, and correlations between discourse and cognitive variables were observed."
            },
            "score": 4
        },
        {
            "id": "dd5beef3538574238af1b968b1f5559bf912ba1d",
            "paperId": "dd5beef3538574238af1b968b1f5559bf912ba1d",
            "title": "Towards Discourse Parsing and Connective Identification in Hindi",
            "abstract": "Discourse parsing is a sub-field of natural language processing which involves understanding the structure, information flow, and modeling the coherence of a given text. It forms the basis of several natural language processing tasks, including, but not limited to, question-answering, text summarization, and sentiment analysis. One of the fundamental tasks in discourse parsing is discourse unit segmentation and connective identification. Discourse unit segmentation refers to identifying the elementary units of text that combine to form a coherent text. Connectives signal the presence of explicit discourse relations in text. Connective identification is the task of identifying these discourse connectives. Language has always played a significant role in human interaction and the evolution of society. With the increasing amount of text data being generated every day on social media platforms such as Facebook, Twitter, WhatsApp, Reddit, etc., helping machines understand and analyse this data is going to be the fundamental task which will further enable us to improve the performance of systems for downstream NLP tasks. In this thesis, we explore the sub-field of shallow discourse parsing, compare approaches towards segmentation and connective identification, and build a dataset and connective identification system for Hindi data. First, we look at approaches towards shallow discourse parsing to identify individual discourse relations that are present in text. This involves given a text, identifying the span of the explicit discourse connective, labelling the two text spans that act as the arguments of the connective and predicting the sense of the discourse relation. We compare and analyse several approaches for these tasks. We then look at an approach towards shallow discourse parsing in Hindi and analyse the tasks of the identification of explicit discourse connectives and their arguments. Further, we work on building a multilingual model for discourse unit segmentation and connective identification. Early approaches towards segmentation and connective detection relied on rule-based systems using POS tags and other syntactic information to identify discourse segments. Recently, transformer based neural systems have shown promising results in this domain. We establish a baseline using a bidirectional LSTM model. We then look at transformer based neural systems and train our model on 16 datasets encompassing 11 languages and 3 discourse annotation frameworks. This model gives state of the art performance for the English dataset. We then present a curated dataset and model for connective identification in",
            "year": 2022,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This thesis explores the sub-field of shallow discourse parsing, compares approaches towards segmentation and connective identification, and builds a dataset and connectives identification system for Hindi data."
            },
            "score": 4
        },
        {
            "id": "08933faacad017f308ba1f85e23377183592494f",
            "paperId": "08933faacad017f308ba1f85e23377183592494f",
            "title": "Building Discourse Parser for Thirukkural",
            "abstract": "Thirukkural is one of the famous Tamil Literatures in the world. It was written by Thiruvalluvar, and focuses on ethics and morality. It provides all possible solutions to lead a successful and a peaceful life fitting any generation. It has been translated into 82 global languages, which necessitate the access of Thirukkural in any language on the World Wide Web (WWW) and processing the Thirukkural computationally. This paper aims at constructing the Thirukkural Discourse Parser which finds the semantic relations in the Thirukkurals which can extract the hidden meaning in it and help in utilizing the same in various Natural Language Processing (NLP) applications, such as, Summary Generation Systems, Information Retrieval (IR) Systems and Question Answering (QA) Systems. Rhetorical Structure Theory (RST) is one of the discourse theories, which is used in NLP to find the coherence between texts. This paper finds the relation within the Thriukkurals and the discourse structure is created using the Thirukkural Discourse Parser. The resultant discourse structure of Thirukkural can be indexed and further be used by Summary Generation Systems, IR Systems and QA Systems. This facilitates the end user to access Thirukkural on WWW and get benefited. This Thirukkural Discourse Parser has been tested with all 1330 Thirukurals using precision and recall.",
            "year": 2019,
            "citationCount": 36,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The resultant discourse structure of Thirukkural can be indexed and further be used by Summary Generation Systems, IR Systems and QA Systems, and facilitates the end user to access ThirUKkural on WWW and get benefited."
            },
            "score": 4
        },
        {
            "id": "61bcddd58375d30d8a446aa8a69baa6f1af93abd",
            "paperId": "61bcddd58375d30d8a446aa8a69baa6f1af93abd",
            "title": "What Drives the Use of Metaphorical Language? Negative Insights from Abstractness, Affect, Discourse Coherence and Contextualized Word Representations",
            "abstract": "Given a specific discourse, which discourse properties trigger the use of metaphorical language, rather than using literal alternatives? For example, what drives people to say grasp the meaning rather than understand the meaning within a specific context? Many NLP approaches to metaphorical language rely on cognitive and (psycho-)linguistic insights and have successfully defined models of discourse coherence, abstractness and affect. In this work, we build five simple models relying on established cognitive and linguistic properties ? frequency, abstractness, affect, discourse coherence and contextualized word representations ? to predict the use of a metaphorical vs. synonymous literal expression in context. By comparing the models? outputs to human judgments, our study indicates that our selected properties are not sufficient to systematically explain metaphorical vs. literal language choices.",
            "year": 2022,
            "citationCount": 2,
            "tldr": null,
            "score": 3
        },
        {
            "id": "76e5069425547d4f53b5aa843a765a305b7fa470",
            "paperId": "76e5069425547d4f53b5aa843a765a305b7fa470",
            "title": "Discursive Socratic Questioning: (Unsupervised) Interpreting Neural Language Models for Discourse Understanding",
            "abstract": "Do neural language models (NLMs) understand 001 the discourse they are processing? Traditional 002 interpretation methods that address this ques-003 tion require pre-annotated explanations, which 004 defeats the purpose of unsupervised explana-005 tion. We propose unsupervised Discursive So-006 cratic Questioning ( D I SQ ), a two-step interpre-007 tative measure. 008 D I SQ first generates Socratic-style questions 009 about the discourse and then queries NLMs 010 about these questions. A model\u2019s understand-011 ing is measured by its responses to these ques-012 tions. We apply D I SQ to examine two fun-013 damental discourse phenomena, namely dis-014 course relation and discourse coherence. We 015 find NLMs demonstrate non-trivial capacities 016 without being trained on any discourse data: 017 Q&A pairs in D I SQ are shown to be evidence 018 for discourse relation and cohesive devices for 019 discourse coherence. D I SQ brings initial evi-020 dence that NLMs understand discourse through 021 reasoning. We find larger models perform bet-022 ter, but contradictions and hallucinations are 023 still problems. We recommend D I SQ as a uni-024 versal diagnostic for discursive NLMs and us-025 ing its output for self-supervision. 026",
            "year": 2022,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "D I SQ brings initial evi-020 dence that NLMs understand discourse through 021 reasoning, and is recommended as a unsupervised versal diagnostic for discursive NLMs and its output for self-supervision."
            },
            "score": 3
        },
        {
            "id": "6295434a9f8aeb1ca0bb54ee2b85a539b9db4a1d",
            "paperId": "6295434a9f8aeb1ca0bb54ee2b85a539b9db4a1d",
            "title": "DisCoTex at EVALITA 2023: Overview of the Assessing DIScourse COherence in Italian TEXts task",
            "abstract": "The Assessing DIScourse COherence in Italian TEXts (DisCoTEX) task is the first shared task focused on modelling discourse coherence for Italian real-word texts, which has been proposed for the first time at EVALITA 2023. Providing two different datasets from different textual genres, we arranged the task into two independent tasks: a more traditional one, aimed at evaluating whether models are able to distinguish well-organized documents from corrupted ones and a less explored one, which assesses the models\u2019 performance on texts evaluated for coherence by human raters. In this paper, we describe the datasets released, we discuss the different approaches tackled by the participating systems and provide a first analysis of the obtained results.",
            "year": 2023,
            "citationCount": 2,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The Assessing DIScourse COherence in Italian TEXts (DisCoTEX) task is the first shared task focused on modelling discourse coherence for Italian real-word texts and the different approaches tackled by the participating systems are discussed and a first analysis of the obtained results are provided."
            },
            "score": 3
        },
        {
            "id": "ef1a43dcb7845bdcf275dff3d0757456b14653c0",
            "paperId": "ef1a43dcb7845bdcf275dff3d0757456b14653c0",
            "title": "DDisCo: A Discourse Coherence Dataset for Danish",
            "abstract": "To date, there has been no resource for studying discourse coherence on real-world Danish texts. Discourse coherence has mostly been approached with the assumption that incoherent texts can be represented by coherent texts in which sentences have been shuffled. However, incoherent real-world texts rarely resemble that. We thus present DDisCo, a dataset including text from the Danish Wikipedia and Reddit annotated for discourse coherence. We choose to annotate real-world texts instead of relying on artificially incoherent text for training and testing models. Then, we evaluate the performance of several methods, including neural networks, on the dataset.",
            "year": 2022,
            "citationCount": 2,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "DDisCo, a dataset including text from the Danish Wikipedia and Reddit annotated for discourse coherence, is presented, choosing to annotate real-world texts instead of relying on artificially incoherent text for training and testing models."
            },
            "score": 3
        },
        {
            "id": "d15c0f3042a82befa42eb5cf7fc806351edc800e",
            "paperId": "d15c0f3042a82befa42eb5cf7fc806351edc800e",
            "title": "Argue Better: Using Large Language Models to Generate Better Examples for Ineffective Persuasive Essay Arguments",
            "abstract": "Automatic essay scoring has been a challenging task in the domain of educational natural language processing (NLP) because of the high variation and divergence in essay styles for the same prompt. Past work has focused on assessing and scoring the coherence, structure, style, and effectiveness of persuasive essays; however, applying these methods to real-life cases would remain ineffective from a learning standpoint because the essay writers are not provided with feedback on how they can improve their writing. We propose an extension to the automatic essay evaluation systems developed for the Kaggle Feedback Prize Competition, with the goal of either retrieving or generating better examples for ineffective discourse elements in persuasive essays. Our methods include implementing a context-aware SentenceTransformer search algorithm, as well as fine-tuning GPT-2 to convert ineffective examples into effective ones. The results of our two-stage retriever-generator implementation evaluated on cosine similarity, BERTScore, and BLEURT demonstrate that the extraction approach does a better job of providing examples that match the flow of the ground truth than the generative approach does.",
            "year": 2023,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The results of the two-stage retriever-generator implementation evaluated on cosine similarity, BERTScore, and BLEURT demonstrate that the extraction approach does a better job of providing examples that match the flow of the ground truth than the generative approach does."
            },
            "score": 3
        },
        {
            "id": "55cc8231f9d223ce1e7040d30976584ea6c4f77c",
            "paperId": "55cc8231f9d223ce1e7040d30976584ea6c4f77c",
            "title": "Towards Modelling Coherence in Spoken Discourse",
            "abstract": "While there has been significant progress towards modelling coherence in written discourse, the work in modelling spoken discourse coherence has been quite limited. Unlike the coherence in text, coherence in spoken discourse is also dependent on the prosodic and acoustic patterns in speech. In this paper, we model coherence in spoken discourse with audio-based coherence models. We perform experiments with four coherence-related tasks with spoken discourses. In our experiments, we evaluate machine-generated speech against the speech delivered by expert human speakers. We also compare the spoken discourses generated by human language learners of varying language proficiency levels. Our results show that incorporating the audio modality along with the text benefits the coherence models in performing downstream coherence related tasks with spoken discourses.",
            "year": 2020,
            "citationCount": 8,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The results show that incorporating the audio modality along with the text benefits the coherence models in performing downstream coherence related tasks with spoken discourses."
            },
            "score": 3
        },
        {
            "id": "a84e36b5e5a018203c1d8d8f4c631c18b9c2430a",
            "paperId": "a84e36b5e5a018203c1d8d8f4c631c18b9c2430a",
            "title": "Turn of Phrase: Contrastive Pre-Training for Discourse-Aware Conversation Models",
            "abstract": "Turn of Phrase: Contrastive Pre-Training for Discourse-Aware Conversation Models Roland Laboulaye Department of Computer Science, BYU Master of Science Understanding long conversations requires recognizing a discourse flow unique to conversation. Recent advances in unsupervised representation learning of text have been attained primarily through language modeling, which models discourse only implicitly and within a small window. These representations are in turn evaluated chiefly on sentence pair or paragraph-question pair benchmarks, which measure only local discourse coherence. In order to improve performance on discourse-reliant, long conversation tasks, we propose Turn-of-Phrase Pre-Training, an objective designed to encode long conversation discourse flow. We leverage tree-structured Reddit conversations in English to, relative to a chosen conversation path through the tree, select paths of varying degrees of relatedness. The final utterance of the chosen path is appended to the related paths and the model learns to identify the most coherent conversation path. We demonstrate that our pre-training objective encodes conversational discourse awareness by improving performance on a dialogue act classification task. We then demonstrate the value of transferring discourse awareness with a comprehensive array of conversation-level classification tasks evaluating persuasion, conflict, and deception.",
            "year": 2022,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work proposes Turn-of-Phrase Pre-Training, an objective designed to encode long conversation discourse flow, and demonstrates the value of transferring discourse awareness with a comprehensive array of conversation-level classification tasks evaluating persuasion, conflict, and deception."
            },
            "score": 3
        },
        {
            "id": "0899c8fecd47b2843db8dc28e53ee06c3115fb3d",
            "paperId": "0899c8fecd47b2843db8dc28e53ee06c3115fb3d",
            "title": "A Critical Evaluation of Evaluations for Long-form Question Answering",
            "abstract": "Long-form question answering (LFQA) enables answering a wide range of questions, but its flexibility poses enormous challenges for evaluation. We perform the first targeted study of the evaluation of long-form answers, covering both human and automatic evaluation practices. We hire domain experts in seven areas to provide preference judgments over pairs of answers, along with free-form justifications for their choices. We present a careful analysis of experts\u2019 evaluation, which focuses on new aspects such as the comprehensiveness of the answer. Next, we examine automatic text generation metrics, finding that no existing metrics are predictive of human preference judgments. However, some metrics correlate with fine-grained aspects of answers (e.g., coherence). We encourage future work to move away from a single \u201coverall score\u201d of the answer and adopt a multi-faceted evaluation, targeting aspects such as factuality and completeness. We publicly release all of our annotations and code to spur future work into LFQA evaluation.",
            "year": 2023,
            "citationCount": 34,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work performs the first targeted study of the evaluation of long-form answers, covering both human and automatic evaluation practices, and presents a careful analysis of experts\u2019 evaluation, which focuses on new aspects such as the comprehensiveness of the answer."
            },
            "score": 3
        },
        {
            "id": "bd5deadc58ee45b5e004378ba1d54a96bc947b4a",
            "paperId": "bd5deadc58ee45b5e004378ba1d54a96bc947b4a",
            "title": "FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation",
            "abstract": "Evaluating the factuality of long-form text generated by large language models (LMs) is non-trivial because (1) generations often contain a mixture of supported and unsupported pieces of information, making binary judgments of quality inadequate, and (2) human evaluation is time-consuming and costly. In this paper, we introduce FACTSCORE, a new evaluation that breaks a generation into a series of atomic facts and computes the percentage of atomic facts supported by a reliable knowledge source. We conduct an extensive human evaluation to obtain FACTSCOREs of people biographies generated by several state-of-the-art commercial LMs -- InstructGPT, ChatGPT, and the retrieval-augmented PerplexityAI -- and report new analysis demonstrating the need for such a fine-grained score (e.g., ChatGPT only achieves 58%). Since human evaluation is costly, we also introduce an automated model that estimates FACTSCORE using retrieval and a strong language model, with less than a 2% error rate. Finally, we use this automated metric to evaluate 6,500 generations from a new set of 13 recent LMs that would have cost $26K if evaluated by humans, with various findings: GPT-4 and ChatGPT are more factual than public models, and Vicuna and Alpaca are some of the best public models. FACTSCORE is available for public use via `pip install factscore`.",
            "year": 2023,
            "citationCount": 189,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "An automated model is introduced that estimates FACTSCORE using retrieval and a strong language model, and is used to evaluate 6,500 generations from a new set of 13 recent LMs that would have cost $26K if evaluated by humans, with various findings."
            },
            "score": 3
        },
        {
            "id": "d891face4565ef3970c1a0965d8126456651f81e",
            "paperId": "d891face4565ef3970c1a0965d8126456651f81e",
            "title": "PROXYQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models",
            "abstract": "Large Language Models (LLMs) have exhibited remarkable success in long-form context comprehension tasks. However, their capacity to generate long contents, such as reports and articles, remains insufficiently explored. Current benchmarks do not adequately assess LLMs' ability to produce informative and comprehensive content, necessitating a more rigorous evaluation approach. In this study, we introduce \\textsc{ProxyQA}, a framework for evaluating long-form text generation, comprising in-depth human-curated \\textit{meta-questions} spanning various domains. Each meta-question contains corresponding \\textit{proxy-questions} with annotated answers. LLMs are prompted to generate extensive content in response to these meta-questions. Utilizing an evaluator and incorporating generated content as background context, \\textsc{ProxyQA} evaluates the quality of generated content based on the evaluator's performance in answering the \\textit{proxy-questions}. We examine multiple LLMs, emphasizing \\textsc{ProxyQA}'s demanding nature as a high-quality assessment tool. Human evaluation demonstrates that evaluating through \\textit{proxy-questions} is a highly self-consistent and human-criteria-correlated validation method. The dataset and leaderboard will be available at \\url{https://github.com/Namco0816/ProxyQA}.",
            "year": 2024,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A framework for evaluating long-form text generation, comprising in-depth human-curated \\textit{meta-questions} spanning various domains, and human evaluation demonstrates that evaluating through \\textit{proxy-questions} is a highly self-consistent and human-criteria-correlated validation method."
            },
            "score": 3
        },
        {
            "id": "ff97fec88d73371b230f0c8149fbde561e496892",
            "paperId": "ff97fec88d73371b230f0c8149fbde561e496892",
            "title": "Two-step Text Summarization for Long-form Biographical Narrative Genre",
            "abstract": "Transforming narrative structure to implicit discourse relations in long-form text has recently seen a mindset shift toward assessing generation consistency. To this extent, summarization of lengthy biographical discourse is of practical benefit to readers, as it helps them decide whether immersing for days or weeks in a bulky book turns a rewarding experience. Machine-generated summaries can reduce the cognitive load and the time spent by authors to write the summary. Nevertheless, summarization faces significant challenges of factual inconsistencies with respect to the inputs. In this paper, we explored a two-step summary generation aimed to retain source-summary faithfulness. Our method uses a graph representation to rank sentence saliency in each of the novel chapters, leading to distributing summary segments in distinct regions of the chapter. Basing on the previously extracted sentences we produced an abstractive summary in a manner more computationally tractable for detecting inconsistent information. We conducted a series of quantitative analyses on a test set of four long biographical novels and showed to improve summarization quality in automatic evaluation over both single-tier settings and external baselines.",
            "year": 2023,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper explored a two-step summary generation aimed to retain source-summary faithfulness and showed to improve summarization quality in automatic evaluation over both single-tier settings and external baselines."
            },
            "score": 3
        },
        {
            "id": "ea61232aa8932f79d6151a025496dc806e4603d6",
            "paperId": "ea61232aa8932f79d6151a025496dc806e4603d6",
            "title": "Understanding Retrieval Augmentation for Long-Form Question Answering",
            "abstract": "We present a study of retrieval-augmented language models (LMs) on long-form question answering. We analyze how retrieval augmentation impacts different LMs, by comparing answers generated from models while using the same evidence documents, and how differing quality of retrieval document set impacts the answers generated from the same LM. We study various attributes of generated answers (e.g., fluency, length, variance) with an emphasis on the attribution of generated long-form answers to in-context evidence documents. We collect human annotations of answer attribution and evaluate methods for automatically judging attribution. Our study provides new insights on how retrieval augmentation impacts long, knowledge-rich text generation of LMs. We further identify attribution patterns for long text generation and analyze the main culprits of attribution errors. Together, our analysis reveals how retrieval augmentation impacts long knowledge-rich text generation and provide directions for future work.",
            "year": 2023,
            "citationCount": 12,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This study presents a study of retrieval-augmented language models (LMs) on long-form question answering, and identifies attribution patterns for long text generation and analyzes the main culprits of attribution errors."
            },
            "score": 3
        },
        {
            "id": "2bb7d3153779035983d397ae7e2d35fffc23e408",
            "paperId": "2bb7d3153779035983d397ae7e2d35fffc23e408",
            "title": "Mapping ESG Trends by Distant Supervision of Neural Language Models",
            "abstract": "The integration of Environmental, Social and Governance (ESG) considerations into business decisions and investment strategies have accelerated over the past few years. It is important to quantify the extent to which ESG-related conversations are carried out by companies so that their impact on business operations can be objectively assessed. However, profiling ESG language is challenging due to its multi-faceted nature and the lack of supervised datasets. This research study aims to detect historical trends in ESG discussions by analyzing the transcripts of corporate earning calls. The proposed solution exploits recent advances in neural language modeling to understand the linguistic structure in ESG discourse. In detail, firstly we develop a classification model that categorizes the relevance of a text sentence to ESG. A pre-trained language model is fine-tuned on a small corporate sustainability reports dataset for this purpose. The semantic knowledge encoded in this classification model is then leveraged by applying it to the sentences in the conference transcripts using a novel distant-supervision approach. Extensive empirical evaluations against various pretraining techniques demonstrate the efficacy of the proposed transfer learning framework. Our analysis indicates that in the last 5 years, nearly 15% of the discussions during earnings calls pertained to ESG, implying that ESG factors are integral to business strategy.",
            "year": 2020,
            "citationCount": 22,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This research study aims to detect historical trends in ESG discussions by analyzing the transcripts of corporate earning calls and develops a classification model that categorizes the relevance of a text sentence to ESG."
            },
            "score": 3
        },
        {
            "id": "22cd89da4b6561c68be6c2586fb1d3aeea842075",
            "paperId": "22cd89da4b6561c68be6c2586fb1d3aeea842075",
            "title": "Examining the rhetorical capacities of neural language models",
            "abstract": "Recently, neural language models (LMs) have demonstrated impressive abilities in generating high-quality discourse. While many recent papers have analyzed the syntactic aspects encoded in LMs, there has been no analysis to date of the inter-sentential, rhetorical knowledge. In this paper, we propose a method that quantitatively evaluates the rhetorical capacities of neural LMs. We examine the capacities of neural LMs understanding the rhetoric of discourse by evaluating their abilities to encode a set of linguistic features derived from Rhetorical Structure Theory (RST). Our experiments show that BERT-based LMs outperform other Transformer LMs, revealing the richer discourse knowledge in their intermediate layer representations. In addition, GPT-2 and XLNet apparently encode less rhetorical knowledge, and we suggest an explanation drawing from linguistic philosophy. Our method shows an avenue towards quantifying the rhetorical capacities of neural LMs.",
            "year": 2020,
            "citationCount": 8,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper proposes a method that quantitatively evaluates the rhetorical capacities of neural LMs and shows that BERT-based LMs outperform other Transformer LMs, revealing the richer discourse knowledge in their intermediate layer representations."
            },
            "score": 3
        },
        {
            "id": "776e9e920d6bff230565094a5396015c57f255c0",
            "paperId": "776e9e920d6bff230565094a5396015c57f255c0",
            "title": "SURREY-CTS-NLP at WASSA2022: An Experiment of Discourse and Sentiment Analysis for the Prediction of Empathy, Distress and Emotion",
            "abstract": "This paper summarises the submissions our team, SURREY-CTS-NLP has made for the WASSA 2022 Shared Task for the prediction of empathy, distress and emotion. In this work, we tested different learning strategies, like ensemble learning and multi-task learning, as well as several large language models, but our primary focus was on analysing and extracting emotion-intensive features from both the essays in the training data and the news articles, to better predict empathy and distress scores from the perspective of discourse and sentiment analysis. We propose several text feature extraction schemes to compensate the small size of training examples for fine-tuning pretrained language models, including methods based on Rhetorical Structure Theory (RST) parsing, cosine similarity and sentiment score. Our best submissions achieve an average Pearson correlation score of 0.518 for the empathy prediction task and an F1 score of 0.571 for the emotion prediction task, indicating that using these schemes to extract emotion-intensive information can help improve model performance.",
            "year": 2022,
            "citationCount": 7,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper summarises the submissions the SURREY-CTS-NLP team has made for the WASSA 2022 Shared Task for the prediction of empathy, distress and emotion, and proposes several text feature extraction schemes to compensate the small size of training examples for fine-tuning pretrained language models."
            },
            "score": 3
        },
        {
            "id": "4f4c15a00f63b8f47aae38bcdbb05ae004734386",
            "paperId": "4f4c15a00f63b8f47aae38bcdbb05ae004734386",
            "title": "Modeling Persuasive Discourse to Adaptively Support Students\u2019 Argumentative Writing",
            "abstract": "We introduce an argumentation annotation approach to model the structure of argumentative discourse in student-written business model pitches. Additionally, the annotation scheme captures a series of persuasiveness scores such as the specificity, strength, evidence, and relevance of the pitch and the individual components. Based on this scheme, we annotated a corpus of 200 business model pitches in German. Moreover, we trained predictive models to detect argumentative discourse structures and embedded them in an adaptive writing support system for students that provides them with individual argumentation feedback independent of an instructor, time, and location. We evaluated our tool in a real-world writing exercise and found promising results for the measured self-efficacy and perceived ease-of-use. Finally, we present our freely available corpus of persuasive business model pitches with 3,207 annotated sentences in German language and our annotation guidelines.",
            "year": 2022,
            "citationCount": 13,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "An argumentation annotation approach to model the structure of argumentative discourse in student-written business model pitches and embedded predictive models in an adaptive writing support system for students that provides them with individual argumentation feedback independent of an instructor, time, and location is introduced."
            },
            "score": 3
        },
        {
            "id": "5f59b83e2f60cd09f221b168ce4fee225ab7d8fa",
            "paperId": "5f59b83e2f60cd09f221b168ce4fee225ab7d8fa",
            "title": "Paying Attention to Deflections: Mining Pragmatic Nuances for Whataboutism Detection in Online Discourse",
            "abstract": "Whataboutism, a potent tool for disrupting narratives and sowing distrust, remains under-explored in quantitative NLP research. Moreover, past work has not distinguished its use as a strategy for misinformation and propaganda from its use as a tool for pragmatic and semantic framing. We introduce new datasets from Twitter and YouTube, revealing overlaps as well as distinctions between whataboutism, propaganda, and the tu quoque fallacy. Furthermore, drawing on recent work in linguistic semantics, we differentiate the `what about' lexical construct from whataboutism. Our experiments bring to light unique challenges in its accurate detection, prompting the introduction of a novel method using attention weights for negative sample mining. We report significant improvements of 4% and 10% over previous state-of-the-art methods in our Twitter and YouTube collections, respectively.",
            "year": 2024,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work introduces new datasets from Twitter and YouTube, revealing overlaps as well as distinctions between whataboutism, propaganda, and the tu quoque fallacy, and distinguishes the `what about' lexical construct from whataboutism."
            },
            "score": 3
        },
        {
            "id": "74faeae7af1f2952fa31526419ccd2298fb4ddee",
            "paperId": "74faeae7af1f2952fa31526419ccd2298fb4ddee",
            "title": "Global Coherence and Cognition in Parkinson's Disease.",
            "abstract": "PURPOSE\nThis study compared global coherence (GC) in individuals with Parkinson's disease (PD) to a healthy older adult (HOA) group during single (sitting) and dual (stationary cycling) tasks. Additionally, it explored the relationship between GC and cognition in PD.\n\n\nMETHOD\nThirty-seven individuals with PD and 19 HOAs participated in the prospective, cross-sectional study. Participants completed discourse monologues elicited using published prompts while seated and while pedaling a stationary bicycle. Four rating levels of GC were analyzed (GC1 = no relationship to the topic, GC2 = remote relationship, GC3 = conditional relationship, and GC4 = complete relationship) using a published protocol with good interrater reliability and test-retest stability. Participants completed a battery of cognitive tasks, from which four latent factors were extracted: processing speed, working memory, inhibition, and updating.\n\n\nRESULTS\nLinear mixed modeling identified significant effects of GC level and GC level interactions with group, processing speed, and inhibition. The Group \u00d7 GC Level interaction reflected that the PD group had a higher proportion of GC2 and GC1 utterances and fewer GC4 utterances than the HOA group. No differences between single and dual task conditions were found. Faster speed of processing predicted more GC4 utterances, whereas slower speed of processing predicted more G1 utterances. Better inhibition predicted fewer GC2 utterances. Group also predicted GC4 and GC2 proportions.\n\n\nCONCLUSIONS\nIndividuals with PD experienced greater difficulties with GC than HOAs. Processing speed and inhibition contributed significantly to GC across groups. Analysis of GC should be considered an informative addition to assessment of communicative effectiveness in PD.\n\n\nSUPPLEMENTAL MATERIAL\nhttps://doi.org/10.23641/asha.20416056.",
            "year": 2022,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Analysis of GC should be considered an informative addition to assessment of communicative effectiveness in PD, as it identified significant effects of GC level and GC level interactions with group, processing speed, and inhibition."
            },
            "score": 3
        },
        {
            "id": "cf2d8886def9e199b348499bc5c26775da3eb291",
            "paperId": "cf2d8886def9e199b348499bc5c26775da3eb291",
            "title": "ExtremITA at EVALITA 2023: Multi-Task Sustainable Scaling to Large Language Models at its Extreme",
            "abstract": "This paper explores the potential application of a monolithic neural model for all tasks in EVALITA 2023. We evaluated two models: extremIT5 , an encoder-decoder model, and extremITLLaMA an instruction-tuned Decoder-only Large Language Model, specifically designed for handling Italian instructions. Our approach revolves around representing tasks in natural language, where we provide instructions to the model using prompts that define the expected responses. Remarkably, our best-performing model achieved first place in 41% of the subtasks and showcased top-three performance in 64%. These subtasks encompass various semantic dimensions, including Affect Detection, Authorship Analysis, Computational Ethics, Named Entity Recognition, Information Extraction, and Discourse Coherence.",
            "year": 2023,
            "citationCount": 9,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": null
            },
            "score": 2
        },
        {
            "id": "4d15f4d66016a1e31ef7524ddc082ccbbc12fe5a",
            "paperId": "4d15f4d66016a1e31ef7524ddc082ccbbc12fe5a",
            "title": "Spoken discourse in episodic autobiographical and verbal short-term memory in Chinese people with dementia: the roles of global coherence and informativeness",
            "abstract": "Introduction Memory and discourse production are closely related in healthy populations. A few studies in people with amnestic mild cognitive impairment and people with dementia (PWD) suggested similar links, although empirical evidence is insufficient to inform emerging intervention design and natural language processing research. Fine-grained discourse assessment is needed to understand their complex relationship in PWD. Methods Spoken samples from 104 PWD were elicited using personal narrative and sequential picture description and assessed using Main Concept Analysis and other content-based analytic methods. Discourse and memory performance data were analyzed in bivariate correlation and linear multiple regression models to determine the relationship between discourse production and episodic autobiographical memory and verbal short-term memory (vSTM). Results Global coherence was a significant predictor of episodic autobiographical memory, explaining over half of the variance. Both episodic autobiographical memory and vSTM were positively correlated with global coherence and informativeness, and negatively with empty speech indices. Discussion Coherence in personal narrative may be supported by episodic autobiographical memory and vice versa, suggesting potential mechanism of interventions targeting personhood through conversation. Indices of global coherence, informativeness, and empty speech can be used as markers of memory functions in PWD.",
            "year": 2023,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Coherence in personal narrative may be supported by episodic autobiographical memory and vice versa, suggesting potential mechanism of interventions targeting personhood through conversation in people with dementia (PWD)."
            },
            "score": 2
        },
        {
            "id": "cd1e2ded67cefc8811bd2bed6b39182e11aae5a7",
            "paperId": "cd1e2ded67cefc8811bd2bed6b39182e11aae5a7",
            "title": "PhysNLU: A Language Resource for Evaluating Natural Language Understanding and Explanation Coherence in Physics",
            "abstract": "In order for language models to aid physics research, they must first encode representations of mathematical and natural language discourse which lead to coherent explanations, with correct ordering and relevance of statements. We present a collection of datasets developed to evaluate the performance of language models in this regard, which measure capabilities with respect to sentence ordering, position, section prediction, and discourse coherence. Analysis of the data reveals the classes of arguments and sub-disciplines which are most common in physics discourse, as well as the sentence-level frequency of equations and expressions. We present baselines that demonstrate how contemporary language models are challenged by coherence related tasks in physics, even when trained on mathematical natural language objectives.",
            "year": 2022,
            "citationCount": 2,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A collection of datasets developed to evaluate the performance of language models in this regard are presented, which measure capabilities with respect to sentence ordering, position, section prediction, and discourse coherence."
            },
            "score": 2
        },
        {
            "id": "e4a38435a08da7af34e801494c318a9ebb699e10",
            "paperId": "e4a38435a08da7af34e801494c318a9ebb699e10",
            "title": "WikiTableT: A Large-Scale Data-to-Text Dataset for Generating Wikipedia Article Sections",
            "abstract": "Datasets for data-to-text generation typically focus either on multi-domain, single-sentence generation or on single-domain, long-form generation. In this work, we cast generating Wikipedia sections as a data-to-text generation task and create a large-scale dataset, WikiTableT, that pairs Wikipedia sections with their corresponding tabular data and various metadata. WikiTableT contains millions of instances, covering a broad range of topics, as well as a variety of flavors of generation tasks with different levels of flexibility. We benchmark several training and decoding strategies on WikiTableT. Our qualitative analysis shows that the best approaches can generate fluent and high quality texts but they struggle with coherence and factuality, showing the potential for our dataset to inspire future work on long-form generation.",
            "year": 2020,
            "citationCount": 23,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Qualitative analysis shows that the best approaches can generate fluent and high quality texts but they struggle with coherence and factuality, showing the potential for the WikiTableT dataset to inspire future work on long-form generation."
            },
            "score": 2
        },
        {
            "id": "25c48c7b462330667b32941e1361ba7d5972c5ad",
            "paperId": "25c48c7b462330667b32941e1361ba7d5972c5ad",
            "title": "Generating Wikipedia Article Sections from Diverse Data Sources",
            "abstract": "Datasets for data-to-text generation typically focus either on multi-domain, single-sentence generation or on single-domain, long-form generation. In this work, we create a large-scale dataset, W IKI T ABLE T, that pairs Wikipedia sections with their corresponding tabular data and various metadata. W IKI - T ABLE T contains millions of instances, covering a broad range of topics, as well as a variety of \ufb02avors of generation tasks with different levels of \ufb02exibility. We benchmark several training and decoding strategies on W IKI T ABLE T. Our qualitative analysis shows that the best approaches can generate \ufb02uent and high quality texts but they sometimes struggle with coherence. 1",
            "year": 2020,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work creates a large-scale dataset, W IKI T ABLE T, that pairs Wikipedia sections with their corresponding tabular data and various metadata and shows that the best approaches can generate high quality texts but they sometimes struggle with coherence."
            },
            "score": 2
        },
        {
            "id": "9a4f929b44345b9d547f8d2e1700caaab99237c0",
            "paperId": "9a4f929b44345b9d547f8d2e1700caaab99237c0",
            "title": "Task-Adaptive Tokenization: Enhancing Long-Form Text Generation Efficacy in Mental Health and Beyond",
            "abstract": "We propose task-adaptive tokenization as a way to adapt the generation pipeline to the specifics of a downstream task and enhance long-form generation in mental health. Inspired by insights from cognitive science, our task-adaptive tokenizer samples variable segmentations from multiple outcomes, with sampling probabilities optimized based on task-specific data. We introduce a strategy for building a specialized vocabulary and introduce a vocabulary merging protocol that allows for the integration of task-specific tokens into the pre-trained model's tokenization step. Through extensive experiments on psychological question-answering tasks in both Chinese and English, we find that our task-adaptive tokenization approach brings a significant improvement in generation performance while using up to 60% fewer tokens. Preliminary experiments point to promising results when using our tokenization approach with very large language models.",
            "year": 2023,
            "citationCount": 2,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Through extensive experiments on psychological question-answering tasks in both Chinese and English, this work finds that the task-adaptive tokenization approach brings a significant improvement in generation performance while using up to 60% fewer tokens."
            },
            "score": 2
        },
        {
            "id": "0820d7ef9eaf81318714015dd759d9780625b44e",
            "paperId": "0820d7ef9eaf81318714015dd759d9780625b44e",
            "title": "What Do Audio Transformers Hear? Probing Their Representations For Language Delivery & Structure",
            "abstract": "Transformer models across multiple domains such as natural language processing and speech form an unavoidable part of the tech stack of practitioners and researchers alike. Au-dio transformers that exploit representational learning to train on unlabeled speech have recently been used for tasks from speaker verification to discourse-coherence with much success. However, little is known about what these models learn and represent in the high-dimensional latent space. In this paper, we interpret two such recent state-of-the-art models, wav2vec2.0 and Mockingjay, on linguistic and acoustic features. We probe each of their layers to understand what it is learning and at the same time, we draw a distinction between the two models. By comparing their performance across a wide variety of settings including native, non-native, read and spontaneous speeches, we also show how much these models are able to learn transferable features. Our results show that the models are capable of significantly capturing a wide range of characteristics such as audio, fluency, supraseg-mental pronunciation, and even syntactic and semantic text-based characteristics. For each category of characteristics, we identify a learning pattern for each framework and conclude which model and which layer of that model is better for a specific category of feature to choose for feature extraction for downstream tasks.",
            "year": 2022,
            "citationCount": 8,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper interprets two such recent state-of-the-art models, wav2vec2.0 and Mockingjay, on linguistic and acoustic features and concludes which model and which layer of that model is better for a specific category of feature to choose for feature extraction for downstream tasks."
            },
            "score": 2
        },
        {
            "id": "9b5dfaa8fe037653435ba7f8cb13c772c7192b78",
            "paperId": "9b5dfaa8fe037653435ba7f8cb13c772c7192b78",
            "title": "Persian Rhetorical Structure Theory",
            "abstract": "Over the past years, interest in discourse analysis and discourse parsing has steadily grown, and many discourse-annotated corpora and, as a result, discourse parsers have been built. In this paper, we present a discourse-annotated corpus for the Persian language built in the framework of Rhetorical Structure Theory as well as a discourse parser built upon the DPLP parser, an open-source discourse parser. Our corpus consists of 150 journalistic texts, each text having an average of around 400 words. Corpus texts were annotated using 18 discourse relations and based on the annotation guideline of the English RST Discourse Treebank corpus. Our text-level discourse parser is trained using gold segmentation and is built upon the DPLP discourse parser, which uses a large-margin transition-based approach to solve the problem of discourse parsing. The performance of our discourse parser in span (S), nuclearity (N) and relation (R) detection is around 78%, 64%, 44% respectively, in terms of F1 measure.",
            "year": 2021,
            "citationCount": 8,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A discourse-annotated corpus for the Persian language built in the framework of Rhetorical Structure Theory as well as a discourse parser built upon the DPLP parser, an open-source discourse parser."
            },
            "score": 2
        },
        {
            "id": "1db0140975a1d2791d6b83f9ea2279d5e84e9da3",
            "paperId": "1db0140975a1d2791d6b83f9ea2279d5e84e9da3",
            "title": "An Extractive Text Summarization Model Based on Rhetorical Structure Theory",
            "abstract": "In response to the issues of excessive redundant information and unclear hierarchical structure in abstracts, this paper proposes an extractive text summarization method based on rhetorical structure theory. First, use Bert to tokenize the text and divide it into smaller text units; Then, construct a text parsing tree based on the rhetorical structure theory, labeling the relationships between tree nodes and whether they are central information. Furthermore, set the extraction depth and the key EDU sequences are sequentially output as the final summary. Experimental analysis shows that this method effectively reduces redundant information in summary sentences, outperforms the current best benchmark model in terms of the ROUGE index, and improves the accuracy and hierarchical structure of the abstract.",
            "year": 2023,
            "citationCount": 1,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Experimental analysis shows that this method effectively reduces redundant information in summary sentences, outperforms the current best benchmark model in terms of the ROUGE index, and improves the accuracy and hierarchical structure of the abstract."
            },
            "score": 2
        },
        {
            "id": "bb7ebd61af08825ac4ee21ff29946c65eb3db006",
            "paperId": "bb7ebd61af08825ac4ee21ff29946c65eb3db006",
            "title": "Rhetorical Structure Theory and coherence break identification",
            "abstract": "Abstract This article examines the claim of Rhetorical Structure Theory (RST) that violations of RST diagram formation principles indicate coherence breaks. In doing so, this article makes a significant contribution to the testing of RST. More broadly, it indicates that examining the coherence-break identification potential of coherence theories could help specify each theory\u2019s purview and, in the long term, lead to the creation of hybrid models of coherence. Moreover, it paves the way for the development of training resources on discourse (in)coherence for language teachers, exam markers and language learners. 84 paragraphs written by Taiwanese learners of English were analysed according to RST and coherence measures were calculated on the basis of this analysis. The results suggest that the violation of any diagram-formation principle indicates coherence breaks, thus corroborating this RST claim. Inter- and intrajudge agreement in terms of both RST coding and coherence measures calculated on the basis of coherence breaks are reported and discussed. The kinds of coherence breaks which are and are not located by RST analysis are discussed and exemplified. The paper concludes with a discussion of implications for pedagogy and future research.",
            "year": 2019,
            "citationCount": 5,
            "tldr": null,
            "score": 2
        },
        {
            "id": "64410909714f421c153ac123f975f86cc15c1fec",
            "paperId": "64410909714f421c153ac123f975f86cc15c1fec",
            "title": "StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding",
            "abstract": "Analogy-making between narratives is crucial for human reasoning. In this paper, we evaluate the ability to identify and generate analogies by constructing a first-of-its-kind large-scale story-level analogy corpus, \\textsc{StoryAnalogy}, which contains 24K story pairs from diverse domains with human annotations on two similarities from the extended Structure-Mapping Theory. We design a set of tests on \\textsc{StoryAnalogy}, presenting the first evaluation of story-level analogy identification and generation. Interestingly, we find that the analogy identification tasks are incredibly difficult not only for sentence embedding models but also for the recent large language models (LLMs) such as ChatGPT and LLaMa. ChatGPT, for example, only achieved around 30% accuracy in multiple-choice questions (compared to over 85% accuracy for humans). Furthermore, we observe that the data in \\textsc{StoryAnalogy} can improve the quality of analogy generation in LLMs, where a fine-tuned FlanT5-xxl model achieves comparable performance to zero-shot ChatGPT.",
            "year": 2023,
            "citationCount": 8,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "It is observed that the data in \\textsc{StoryAnalogy} can improve the quality of analogy generation in LLMs, where a fine-tuned FlanT5-xxl model achieves comparable performance to zero-shot ChatGPT."
            },
            "score": 2
        },
        {
            "id": "78823931631a5102221b5fead6006a6caf1a99a2",
            "paperId": "78823931631a5102221b5fead6006a6caf1a99a2",
            "title": "RhetoRical StRuctuRe theoRy aS a FeatuRe FoR Deception Detection in newS RepoRtS in the RuSSian language",
            "abstract": "The framework of the Rhetorical Structure Theory (RST) can be used to reveal the differences between structures of truthful and deceptive (fake) news. This approach was already used for English. In this paper it is applied to Russian. Corpus consists of 134 truthful and deceptive news stories in Russian. Texts annotations contain 33 relation categories. Three data sets of experimental data were created: with only rhetorical relation categories (frequencies), with rhetorical relation categories and bigrams of categories, with rhetorical relation categories and trigrams of categories. Support Vector Machines and Random Forest Classifier were used for text classification. The best results we got by using Support Vector Machines with linear kernel for the first data set (0.65). The model could be used as a preliminary filter for fake news detection.",
            "year": 2015,
            "citationCount": 9,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The framework of the Rhetorical Structure Theory (RST) can be used to reveal the differences between structures of truthful and deceptive (fake) news in Russian and could be used as a preliminary filter for fake news detection."
            },
            "score": 2
        },
        {
            "id": "754df4eed5c280be390cb96e6a34428baf697bc9",
            "paperId": "754df4eed5c280be390cb96e6a34428baf697bc9",
            "title": "Using Rhetorical Structure Theory to Assess Discourse Coherence for Non-native Spontaneous Speech",
            "abstract": "This study aims to model the discourse structure of spontaneous spoken responses within the context of an assessment of English speaking proficiency for non-native speakers. Rhetorical Structure Theory (RST) has been commonly used in the analysis of discourse organization of written texts; however, limited research has been conducted to date on RST annotation and parsing of spoken language, in particular, non-native spontaneous speech. Due to the fact that the measurement of discourse coherence is typically a key metric in human scoring rubrics for assessments of spoken language, we conducted research to obtain RST annotations on non-native spoken responses from a standardized assessment of academic English proficiency. Subsequently, automatic parsers were trained on these annotations to process non-native spontaneous speech. Finally, a set of features were extracted from automatically generated RST trees to evaluate the discourse structure of non-native spontaneous speech, which were then employed to further improve the validity of an automated speech scoring system.",
            "year": 2019,
            "citationCount": 10,
            "tldr": null,
            "score": 2
        },
        {
            "id": "fe6daee4edbb413793d6f3a6700328f9e5639894",
            "paperId": "fe6daee4edbb413793d6f3a6700328f9e5639894",
            "title": "Towards automated content analysis of rhetorical structure of written essays using sequential content-independent features in Portuguese",
            "abstract": "Brazilian universities have included essay writing assignments in the entrance examination procedure to select prospective students. The essay scorers manually look for the presence of required Rhetorical Structure Theory (RST) categories and evaluate essay coherence. However, identifying RST categories is a time-consuming task. The literature reported several attempts to automate the identification of RST categories in essays with machine learning. Still, previous studies have focused on using machine learning algorithms trained on content-dependent features that can diminish classification performance, leading to over-fitting and hindering model generalisability. Therefore, this paper proposes: (i) the analysis of state-of-the-art classifiers and content-independent features to the task of RST rhetorical moves; (ii) a new approach that considers the sequence of the text to extract features \u2013 i.e. sequential content-independent features; (iii) an empirical study about the generalisability of the machine learning models and sequential content-independent features for this context; (iv) the identification of the most predictive features for automated identification of RST categories in essays written in Portuguese. The best performing classifier, XGBoost, based on sequential content-independent features, outperformed the classifiers used in the literature and are based on traditional content-dependent features. The XGBoost classifier based on sequential content-independent features also reached promising accuracy when tested for generalisability.",
            "year": 2022,
            "citationCount": 7,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "The analysis of state-of-the-art classifiers and content-independent features to the task of RST rhetorical moves and a new approach that considers the sequence of the text to extract features is proposed."
            },
            "score": 2
        },
        {
            "id": "35ee4f5474d9670ca4985f47ce52cffc9061c910",
            "paperId": "35ee4f5474d9670ca4985f47ce52cffc9061c910",
            "title": "Measuring discourse coherence in anomic aphasia using Rhetorical Structure Theory",
            "abstract": "Abstract Purpose: The existing body of work regarding discourse coherence in aphasia has provided mixed results, leaving the question of coherence being impaired or intact as a result of brain injury unanswered. In this study, discourse coherence in non-brain-damaged (NBD) speakers and speakers with anomic aphasia was investigated quantitatively and qualitatively. Method: Fifteen native speakers of Cantonese with anomic aphasia and 15 NBD participants produced 60 language samples. Elicitation tasks included story-telling induced by a picture series and a procedural description. The samples were annotated for discourse structure in the framework of Rhetorical Structure Theory (RST) in order to analyse a number of structural parameters. After that 20\u2009na\u00efve listeners rated coherence of each sample. Result: Disordered discourse was rated as significantly less coherent. The NBD group demonstrated a higher production fluency than the participants with aphasia and used a richer set of semantic relations to create discourse, particularly in the description of settings, expression of causality, and extent of elaboration. People with aphasia also tended to omit essential information content. Conclusion: Reduced essential information content, lower degree of elaboration, and a larger amount of structural disruptions may have contributed to the reduced overall discourse coherence in speakers with anomic aphasia.",
            "year": 2018,
            "citationCount": 14,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "Reduced essential information content, lower degree of elaboration, and a larger amount of structural disruptions may have contributed to the reduced overall discourse coherence in speakers with anomic aphasia."
            },
            "score": 2
        },
        {
            "id": "cf4b6fa0be844a405cbf5361227adae5e3fa30c6",
            "paperId": "cf4b6fa0be844a405cbf5361227adae5e3fa30c6",
            "title": "Discourse Functions of Kama in Arabic Journalistic Discourse from the Perspective of Rhetorical Structure Theory",
            "abstract": "The study aims at examining the functions of the discourse marker Kama in the Arabic journalistic discourse in the light of Rhetorical Structure Theory (RST) proposed by Mann and Thompson (1987). To this end, the study compiled a small-scale corpus of journalistic discourse taken from two prominent Arabic news websites:\u00a0 Aljazeera.net and Alarabia.net. The corpus covers three distinct sub-genres of journalistic discourse: opinion articles, news reports, and sport reports. The journalistic discourse is chosen on the basis that it is considered as the best representative of the contemporary written Arabic and it receives a wide readership in the Arabic-speaking countries. The motivation for the study is that although it is frequently used in the written form of Arabic (particularly in the language of Arabic media), the discourse marker kama is largely neglected and very few has been said about it in the present literature on Arabic discourse markers. The current findings show that kama is found to achieve 290 occurrences in the corpus under investigation. This obviously indicates that kama is commonly used in the language of Arabic journalistic discourse, which calls for paying attention to its usage in such a type of discourse. In the light of Rhetorical Structure Theory (RST) proposed by Mann and Thompson (1987), kama was found to serve four common functions: elaboration (around 50 %), similarity (around 19 %), evidence (16 %), and exemplification (13 %). Two functions of kama (similarity and\u00a0\u00a0 exemplification) are listed in RST while the other two are incorporated.",
            "year": 2018,
            "citationCount": 6,
            "tldr": null,
            "score": 2
        },
        {
            "id": "5fffa6a85cbb1fa2dc0cd44fba132b98669f8a9f",
            "paperId": "5fffa6a85cbb1fa2dc0cd44fba132b98669f8a9f",
            "title": "Automatic Query-Focused Summary Generation System for Tourism Discourse Using Rhetorical Structure Theory: Cognitive and Multimodal Approach to Tourism Discourse",
            "abstract": "generation systems when integrated with Information Retrieval (IR) can give an idea about the retrieved web pages to the user before even the user opens the web page. The summary could be generated for a single web page or for a set of web pages retrieved for a given query. When such a system is built for tourism web sites, the user can get a summary of a particular tourist spot or about the tourist spots present in a particular place. This chapter describes about such a summary generation system which is built using Rhetorical Structure Theory (RST). RST is a well-known discourse theory which is used for discourse analysis of text documents. The RST makes use of another semantic representation namely, Universal Networking Language (UNL) to find the coherent text fragments. These coherent text fragments are indexed and linked with an IR system. When a user gives a query, the web pages along with a single document and multi document summary. Automatic Query-Focused Summary Generation System for Tourism Discourse Using Rhetorical Structure Theory: Cognitive and Multimodal Approach to Tourism Discourse",
            "year": 2018,
            "citationCount": 3,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This chapter describes about an automatic Query-Focused Summary Generation System for Tourism Discourse using Rhetorical Structure Theory: Cognitive and Multimodal approach to Tourism Discourses."
            },
            "score": 2
        },
        {
            "id": "bfccd43bc4758b3e90faf79f3b1f40cffff23d16",
            "paperId": "bfccd43bc4758b3e90faf79f3b1f40cffff23d16",
            "title": "Discourse Modeling of Non-Native Spontaneous Speech Using the Rhetorical Structure Theory Framework",
            "abstract": "This study aims to model the discourse structure of spontaneous spoken responses within the context of an assessment of English speaking proficiency for non-native speakers. Rhetorical Structure Theory (RST) has been commonly used in the analysis of discourse organization of written texts; however, limited research has been conducted to date on RST annotation and parsing of spoken language, in particular, non-native spontaneous speech. Due to the fact that the measurement of discourse coherence is typically a key metric in human scoring rubrics for assessments of spoken language, we initiated a research to first obtain RST annotations on non-native spoken responses from a standardized assessment of academic English proficiency. Afterwards, based on the annotations obtained, automatic parsers were built to process non-native spontaneous speech. Finally, a set of effective features were extracted from both manually annotated and automatically generated RST trees to evaluate the discourse structure of non-native spontaneous speech, and then employed to further improve the validity of an automated speech scoring system.",
            "year": 2018,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A set of effective features were extracted from both manually annotated and automatically generated RST trees to evaluate the discourse structure of non-native spontaneous speech, and then employed to further improve the validity of an automated speech scoring system."
            },
            "score": 2
        },
        {
            "id": "d4a051278307269ce63a8822e1b08b84a5c543e4",
            "paperId": "d4a051278307269ce63a8822e1b08b84a5c543e4",
            "title": "Discourse Annotation of Non-native Spontaneous Spoken Responses Using the Rhetorical Structure Theory Framework",
            "abstract": "The availability of the Rhetorical Structure Theory (RST) Discourse Treebank has spurred substantial research into discourse analysis of written texts; however, limited research has been conducted to date on RST annotation and parsing of spoken language, in particular, non-native spontaneous speech. Considering that the measurement of discourse coherence is typically a key metric in human scoring rubrics for assessments of spoken language, we initiated a research effort to obtain RST annotations of a large number of non-native spoken responses from a standardized assessment of academic English proficiency. The resulting inter-annotator kappa agreements on the three different levels of Span, Nuclearity, and Relation are 0.848, 0.766, and 0.653, respectively. Furthermore, a set of features was explored to evaluate the discourse structure of non-native spontaneous speech based on these annotations; the highest performing feature resulted in a correlation of 0.612 with scores of discourse coherence provided by expert human raters.",
            "year": 2017,
            "citationCount": 6,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A research effort to obtain RST annotations of a large number of non-native spoken responses from a standardized assessment of academic English proficiency found that the highest performing feature resulted in a correlation of 0.612 with scores of discourse coherence provided by expert human raters."
            },
            "score": 2
        },
        {
            "id": "023adc678b220ff064b7e48215bb1c20dfa33695",
            "paperId": "023adc678b220ff064b7e48215bb1c20dfa33695",
            "title": "Long Short-term Memory Network over Rhetorical Structure Theory for Sentence-level Sentiment Analysis",
            "abstract": "Using deep learning models to solve sentiment analysis of sentences is still a challenging task. Long short-term memory (LSTM) network solves the gradient disappeared problem existed in recurrent neural network (RNN), but LSTM structure is linear chain-structure that can\u2019t capture text structure information. Afterwards, Tree-LSTM is proposed, which uses LSTM forget gate to skip sub-trees that have little e\ufb00ect on the results to get good performance. It illustrates that the chain-structured LSTM more strongly depends on text structure. However, Tree-LSTM can\u2019t clearly (cid:12)gure out which sub-trees are important and which sub-trees have little e\ufb00ect. We propose a simple model which uses Rhetorical Structure Theory (RST) for text parsing. By building LSTM network on RST parse structure, we make full use of LSTM structural characteristics to automatically enhance the nucleus information and (cid:12)lter the satellite information of text. Furthermore, this approach can make the representations concerning the relations between segments of text, which can improve text semantic representations. Experiment results show that this method not only has higher classi(cid:12)cation accuracy, but also trains quickly.",
            "year": 2016,
            "citationCount": 17,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "A simple model which uses Rhetorical Structure Theory (RST) for text parse structure is proposed, which makes full use of LSTM structural characteristics to automatically enhance the nucleus information and the satellite information of text."
            },
            "score": 2
        },
        {
            "id": "b2c21ebdaf87dccead074f017a1eac41df2db3e2",
            "paperId": "b2c21ebdaf87dccead074f017a1eac41df2db3e2",
            "title": "Coherence Errors in Iranian EFL Learners' Writing: A Rhetorical Structure Theory Approach",
            "abstract": "One of the key elements in the organization of any piece of writing is its coherence. To date, many propositions have been given regarding the definition, analysis, and evaluation of text coherence. In the current study, Mann and Thompson's (1988) Rhetorical Structure Theory (RST) was adopted as the method of text analysis to detect the coherence breaks in writing samples. In order to see what problems Iranian EFL learners have with regard to text coherence, 64 essays in descriptive and argumentative genres written by male students of a language institute in Shiraz were analyzed. The essays were analyzed for discourse errors using RST. The findings indicated that Iranian EFL learners committed eight different types of coherence errors, namely irrelevant content, violation of completedness, violation of connectedness, incorrect place, incorrect relation, crossed dependency, scattered units, and topic. The reason behind these errors partly came from the learners' tendency to write in an inductive order, and partly from their inability to coherently connect the constituent parts of their texts together. Genre difference was also proved to be significant in the number of coherence relations and in the type and number of coherence errors. In general, descriptive writing samples were more coherent than argumentative ones. Keywords: Rhetorical Structure Theory (RST), coherence errors, descriptive writing, argumentative writing, genre.",
            "year": 2017,
            "citationCount": 4,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "In the current study, Mann and Thompson's Rhetorical Structure Theory (RST) was adopted as the method of text analysis to detect the coherence breaks in writing samples and indicated that Iranian EFL learners committed eight different types of coherence errors."
            },
            "score": 2
        },
        {
            "id": "0752afda83927741d41a3f91325e2618425436e9",
            "paperId": "0752afda83927741d41a3f91325e2618425436e9",
            "title": "Fast Rhetorical Structure Theory Discourse Parsing",
            "abstract": "Author(s): Heilman, Michael; Sagae, Kenji | Abstract: In recent years, There has been a variety of research on discourse parsing, particularly RST discourse parsing. Most of the recent work on RST parsing has focused on implementing new types of features or learning algorithms in order to improve accuracy, with relatively little focus on efficiency, robustness, or practical use. Also, most implementations are not widely available. Here, we describe an RST segmentation and parsing system that adapts models and feature sets from various previous work, as described below. Its accuracy is near state-of-the-art, and it was developed to be fast, robust, and practical. For example, it can process short documents such as news articles or essays in less than a second.",
            "year": 2015,
            "citationCount": 37,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "An RST segmentation and parsing system that adapts models and feature sets from various previous work, as described below, that can process short documents such as news articles or essays in less than a second."
            },
            "score": 2
        },
        {
            "id": "06f9b5542e45fb7c201b522db363b6f119a76955",
            "paperId": "06f9b5542e45fb7c201b522db363b6f119a76955",
            "title": "Rhetorical Structure of The News Story and Implication for Language Teaching",
            "abstract": "This study tried to investigate the application of the Rhetorical Structure Theory (RST) in analyzing the relationships between the markers used in the four texts and identify the types of the marker relationship and their functions in the whole clauses. It found out that RST operated with highly generalized Rhetorical Relations, such as elaboration, sequence, and motivation; it was intended to be applicable across a variety of different registers. Based on the analysis of texts 1-4, it was also found that the texts apply four types of elements of a clause complex covering elaboration, enhancement, projection, and extension. These findings are in line with the logical meaning which functions to realize its existence and application in some forms of news stories being analyzed. Therefore, teaching of Grammar and Writing Subjects should involve the process of discourse development and news stories so that students will enhance and update their knowledge and improve their understanding.\u00c2\u00a0",
            "year": 2020,
            "citationCount": 2,
            "tldr": null,
            "score": 2
        },
        {
            "id": "c3f91f90f45e935f8ec369172584ea69c6b405c7",
            "paperId": "c3f91f90f45e935f8ec369172584ea69c6b405c7",
            "title": "COMMIT at SemEval-2016 Task 5: Sentiment Analysis with Rhetorical Structure Theory",
            "abstract": "This paper reports our submission to the Aspect-Based Sentiment Analysis task of SemEval 2016. It covers the prediction of sentiment for a given set of aspects (e.g., subtask 1, slot 2) for the English language using discourse analysis. To that end, a discourse parser implementing the Rhetorical Structure Theory is employed and the resulting information is used to determine the context of each aspect, as well as to compute the expressed sentiment in that context by weighing the discourse relations between words. While discourse analysis yields high level linguistic information that can be used to better predict sentiment, the proposed algorithm does not yet stack up to the high-performing machine learning approaches that are commonly exploited for this task.",
            "year": 2016,
            "citationCount": 3,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper reports the submission to the Aspect-Based Sentiment Analysis task of SemEval 2016, which covers the prediction of sentiment for a given set of aspects for the English language using discourse analysis using the Rhetorical Structure Theory."
            },
            "score": 2
        },
        {
            "id": "a8912e439ac787c91892ea3d5223e7dd0fea4052",
            "paperId": "a8912e439ac787c91892ea3d5223e7dd0fea4052",
            "title": "RHETORICAL STRUCTURE THEORY: A THEORY OF TEXT ORGANIZATION",
            "abstract": "Abstract : Rhetorical Structure Theory is a descriptive theory of a major aspect of the organization of natural text. It is a linguistically useful method for describing natural texts, characterizing their structure primarily in terms of relations that hold between parts of the text. This paper establishes a new definitional foundation for RST. Definitions are made more systematic and explicit, they introduce a new functional element, and incidentally reflect more experience in text analysis. Along with the definitions, the paper examines three claims and findings of RST: the predominance of nucleus/satellite structural patterns, the functional basis of hierarchy, and the communicative role of text structure. (Author) Keywords: Artificial intelligence; Coherence; Computational linguistics; Discourse; Grammar; Knowledge delivery; Natural language processing; Pragmatics.",
            "year": 1987,
            "citationCount": 1212,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This paper establishes a new definitional foundation for RST, Definitions are made more systematic and explicit, they introduce a new functional element, and incidentally reflect more experience in text analysis."
            },
            "score": 2
        },
        {
            "id": "1157efb8ddfbfdbe3e23078ae823507e3b8971ea",
            "paperId": "1157efb8ddfbfdbe3e23078ae823507e3b8971ea",
            "title": "Discursive Fields and the Diversity-Coherence Paradox: An Ecological Perspective on the Blockchain Community Discourse",
            "abstract": "Innovation breakthroughs prompt sensemaking discourses that promote community learning and socially construct the innovation. Through this discourse, interested actors advance diverse frames, appealing to consumers with disparate preferences but raising concerns for the coherence of that discourse. We unpack this diversity-coherence paradox by recasting coherence as the relatedness of innovation frames and spotlighting the role of discursive fields that circumscribe meaning. Our empirical context is the first six years of blockchain discourse across seven discursive fields. Our research offers three insights in furtherance of an ecological perspective on innovation discourse. First, framing diversity emanates from discursive fields rather than from actors. Second, fields play differentiated roles in the framing process. Enactment fields comprised of actors with direct experience with the technology limit diversity. They do so by erecting walls that circumscribe discourse through imprinting on their original frame and retracting from or abandoning frames learned from other fields. In contrast, mediated fields, in which actors lack direct experience with the technology, enhance diversity. They do so by imitating or learning from other fields and foreshadowing or anticipating the frames used by other fields, thereby building bridges. Third, rather than opposing each other, diversity and coherence coevolve as the diversity induced by mediated fields increases framing redundancies, synthesizing frames into a coherent community understanding of the innovation. Our research signals to the actors who serve as innovation ambassadors and gatekeepers that diverse views of an innovation are not only inevitable, given the many discourse fields in which those views are formulated, but can also be coherent and desirable.",
            "year": 2022,
            "citationCount": 7,
            "tldr": null,
            "score": 2
        },
        {
            "id": "12146b4a8c87eb1d58c28db0919aa389bbf658d0",
            "paperId": "12146b4a8c87eb1d58c28db0919aa389bbf658d0",
            "title": "Syntactic Inductive Bias in Transformer Language Models: Especially Helpful for Low-Resource Languages?",
            "abstract": "A line of work on Transformer-based language models such as BERT has attempted to use syntactic inductive bias to enhance the pretraining process, on the theory that building syntactic structure into the training process should reduce the amount of data needed for training. But such methods are often tested for high-resource languages such as English. In this work, we investigate whether these methods can compensate for data sparseness in low-resource languages, hypothesizing that they ought to be more effective for low-resource languages. We experiment with five low-resource languages: Uyghur, Wolof, Maltese, Coptic, and Ancient Greek. We find that these syntactic inductive bias methods produce uneven results in low-resource settings, and provide surprisingly little benefit in most cases.",
            "year": 2023,
            "citationCount": 0,
            "tldr": {
                "model": "tldr@v2.0.0",
                "text": "This work investigates whether syntactic inductive bias methods can compensate for data sparseness in low-resource languages, hypothesizing that they ought to be more effective for low- resource languages."
            },
            "score": 1
        }
    ],
    "novelty": "no"
}