{
    "topic_description": "novel prompting methods that can better quantify uncertainty or calibrate the confidence of large language models",
    "idea_name": "Confidence-Aware Information Seeking",
    "raw_idea": {
        "Problem": "LLMs often fail to accurately assess when they need additional information to answer a query confidently, leading to overconfident responses based on incomplete knowledge.",
        "Existing Methods": "Existing approaches typically focus on improving confidence calibration for fixed inputs rather than actively seeking additional information.",
        "Motivation": "Emulating human information-seeking behavior could allow LLMs to more accurately assess their knowledge gaps and calibrate their confidence through targeted information gathering.",
        "Proposed Method": "We introduce a dynamic prompting strategy that enables the LLM to actively seek information: 1) Generate an initial response and confidence estimate. 2) If confidence is below a threshold, prompt the model to generate specific questions that would increase its confidence if answered. 3) Simulate answers to these questions (e.g., by querying the model with related prompts). 4) Incorporate new information and update the response and confidence estimate. 5) Repeat steps 2-4 until confidence exceeds the threshold or a maximum number of iterations is reached. This approach allows the model to iteratively refine its knowledge and calibrate its confidence through targeted information seeking.",
        "Experiment Plan": "Evaluate on open-domain QA tasks, comparing against static prompting methods. Assess both the final calibration of confidence estimates and the quality and relevance of the generated information-seeking questions."
    },
    "full_experiment_plan": {
        "Title": "Dynamic Information-Seeking Prompting for Improved Uncertainty Quantification in Large Language Models",
        "Problem Statement": "Large Language Models (LLMs) often fail to accurately assess when they need additional information to answer a query confidently, leading to overconfident responses based on incomplete knowledge. This problem is particularly acute in open-domain question answering tasks where the model's knowledge may be incomplete or outdated.",
        "Motivation": "Existing approaches typically focus on improving confidence calibration for fixed inputs rather than actively seeking additional information. However, emulating human information-seeking behavior could allow LLMs to more accurately assess their knowledge gaps and calibrate their confidence through targeted information gathering. This approach is inspired by human cognitive processes, where we often recognize when we need more information and actively seek it out before making a confident assertion.",
        "Proposed Method": "We introduce a dynamic prompting strategy that enables the LLM to actively seek information: 1) Generate an initial response and confidence estimate. 2) If confidence is below a threshold, prompt the model to generate specific questions that would increase its confidence if answered. 3) Simulate answers to these questions (e.g., by querying the model with related prompts). 4) Incorporate new information and update the response and confidence estimate. 5) Repeat steps 2-4 until confidence exceeds the threshold or a maximum number of iterations is reached. This approach allows the model to iteratively refine its knowledge and calibrate its confidence through targeted information seeking.",
        "Step-by-Step Experiment Plan": {
            "Step 1: Dataset Preparation": "Use the TriviaQA dataset for open-domain question answering. Split the dataset into training, validation, and test sets.",
            "Step 2: Baseline Implementation": "Implement two baseline methods: 1) Direct prompting: simply ask the question to the LLM. 2) Static confidence estimation: append 'How confident are you in your answer on a scale of 0-100?' to each question.",
            "Step 3: Dynamic Information-Seeking Prompting Implementation": "Implement the proposed method with the following steps: a) Initial response generation: 'Answer the following question and provide a confidence score (0-100): [QUESTION]' b) Information-seeking question generation: 'You're not confident enough. What specific questions would help you answer the original question more confidently? Generate 3 questions.' c) Answer simulation: For each generated question, prompt the model with 'Answer this question briefly: [GENERATED_QUESTION]' d) Response update: 'Given the following new information: [SIMULATED_ANSWERS], update your answer to the original question: [ORIGINAL_QUESTION]. Also provide an updated confidence score (0-100).'",
            "Step 4: Model Selection": "Use GPT-3.5 (text-davinci-003) and GPT-4 from the OpenAI API for all experiments.",
            "Step 5: Hyperparameter Tuning": "On the validation set, tune the confidence threshold (e.g., try values from 70 to 90) and maximum number of iterations (e.g., try 1 to 5) for the dynamic prompting method.",
            "Step 6: Evaluation": "On the test set, compare the performance of the baseline methods and the proposed method using the following metrics: 1) Accuracy of the final answers. 2) Calibration error (difference between confidence and accuracy). 3) Average number of information-seeking iterations. 4) Relevance of generated information-seeking questions (manually evaluate a subset).",
            "Step 7: Analysis": "Conduct additional analyses: 1) Compare performance across different question types or topics. 2) Analyze how confidence changes across iterations. 3) Examine cases where the method fails to improve confidence or accuracy."
        },
        "Test Case Examples": {
            "Baseline Prompt Input (Direct Prompting)": "Q: Who was the first person to reach the South Pole?",
            "Baseline Prompt Expected Output (Direct Prompting)": "Roald Amundsen was the first person to reach the South Pole.",
            "Baseline Prompt Input (Static Confidence Estimation)": "Q: Who was the first person to reach the South Pole? How confident are you in your answer on a scale of 0-100?",
            "Baseline Prompt Expected Output (Static Confidence Estimation)": "Roald Amundsen was the first person to reach the South Pole. Confidence: 90",
            "Proposed Prompt Input (Dynamic Information-Seeking; Step 1: Initial Response)": "Answer the following question and provide a confidence score (0-100): Who was the first person to reach the South Pole?",
            "Proposed Prompt Expected Output (Dynamic Information-Seeking; Step 1: Initial Response)": "Roald Amundsen was the first person to reach the South Pole. Confidence: 80",
            "Proposed Prompt Input (Dynamic Information-Seeking; Step 2: Question Generation)": "You're not confident enough. What specific questions would help you answer the original question more confidently? Generate 3 questions.",
            "Proposed Prompt Expected Output (Dynamic Information-Seeking; Step 2: Question Generation)": "1. In what year did Roald Amundsen reach the South Pole?\n2. Was there any competition or race to reach the South Pole?\n3. What nationality was Roald Amundsen?",
            "Proposed Prompt Input (Dynamic Information-Seeking; Step 3: Answer Simulation)": "Answer these questions briefly: 1. In what year did Roald Amundsen reach the South Pole? 2. Was there any competition or race to reach the South Pole? 3. What nationality was Roald Amundsen?",
            "Proposed Prompt Expected Output (Dynamic Information-Seeking; Step 3: Answer Simulation)": "1. Roald Amundsen reached the South Pole on December 14, 1911.\n2. Yes, there was a race to the South Pole between Amundsen and British explorer Robert Falcon Scott.\n3. Roald Amundsen was Norwegian.",
            "Proposed Prompt Input (Dynamic Information-Seeking; Step 4: Response Update)": "Given the following new information: 1. Roald Amundsen reached the South Pole on December 14, 1911. 2. Yes, there was a race to the South Pole between Amundsen and British explorer Robert Falcon Scott. 3. Roald Amundsen was Norwegian. Update your answer to the original question: Who was the first person to reach the South Pole? Also provide an updated confidence score (0-100).",
            "Proposed Prompt Expected Output (Dynamic Information-Seeking; Step 4: Response Update)": "Roald Amundsen, a Norwegian explorer, was the first person to reach the South Pole on December 14, 1911. He achieved this feat during a race against British explorer Robert Falcon Scott. Confidence: 100",
            "Explanation": "The dynamic information-seeking method allows the model to gather additional relevant information, leading to a more detailed and confident answer compared to the baseline methods. The final response includes specific details about the date, nationality, and historical context, which were not present in the initial responses."
        },
        "Fallback Plan": "If the proposed dynamic information-seeking method doesn't significantly improve performance over the baselines, we can explore several alternative directions: 1) Analyze the generated information-seeking questions to understand if they are relevant and diverse enough. If not, we could experiment with different prompting strategies to improve question generation. 2) Investigate whether the simulated answers are providing useful information. We could try using external knowledge sources or different prompting strategies for answer simulation. 3) Examine how the model incorporates new information into its updated responses. If this step is ineffective, we could explore different prompting strategies for information integration. 4) If the method improves answer quality but not confidence calibration, we could focus on developing better prompts specifically for confidence estimation. 5) Turn the project into an analysis paper by conducting in-depth investigations into how LLMs seek and incorporate information, which could provide valuable insights for future research in this area."
    }
}