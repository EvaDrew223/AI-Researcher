{
    "topic_description": "novel prompting methods that can better quantify uncertainty or calibrate the confidence of large language models",
    "idea_name": "Temporal Coherence Prompting",
    "raw_idea": {
        "Problem": "LLMs often produce inconsistent confidence estimates when asked similar questions at different times or in different contexts.",
        "Existing Methods": "Most current methods focus on single-instance confidence estimation without considering temporal consistency.",
        "Motivation": "Human experts tend to maintain consistent levels of certainty about a topic over time, barring the acquisition of new information.",
        "Proposed Method": "We introduce Temporal Coherence Prompting, a technique that challenges the LLM to maintain consistent confidence estimates across time and context. The method involves a series of prompts that present the same or similar questions at different 'time points' within the conversation. These prompts include hypothetical scenarios where time has passed or new, irrelevant information has been introduced. The LLM is explicitly asked to consider its previous confidence estimates and justify any changes. This approach encourages the model to develop a more robust and temporally consistent understanding of its own knowledge and uncertainty.",
        "Experiment Plan": "Evaluate the temporal consistency of confidence estimates using a specially designed dataset of question pairs or sequences. Compare against standard confidence estimation techniques and measure improvements in consistency over time."
    },
    "full_experiment_plan": {
        "Title": "Temporal Coherence Prompting: Improving Consistency in LLM Confidence Estimation",
        "Problem Statement": "Large Language Models (LLMs) often produce inconsistent confidence estimates when asked similar questions at different times or in different contexts. This inconsistency undermines the reliability of LLMs in real-world applications where consistent uncertainty quantification is crucial.",
        "Motivation": "Existing methods primarily focus on single-instance confidence estimation, neglecting the temporal aspect of consistency. Human experts, in contrast, maintain consistent levels of certainty about a topic over time, barring the acquisition of new information. By introducing a method that encourages LLMs to consider their previous confidence estimates and justify any changes, we aim to develop a more robust and temporally consistent approach to uncertainty quantification in LLMs.",
        "Proposed Method": "We introduce Temporal Coherence Prompting (TCP), a technique that challenges the LLM to maintain consistent confidence estimates across time and context. The method involves a series of prompts that present the same or similar questions at different 'time points' within the conversation. These prompts include hypothetical scenarios where time has passed or new, irrelevant information has been introduced. The LLM is explicitly asked to consider its previous confidence estimates and justify any changes.",
        "Step-by-Step Experiment Plan": {
            "Step 1: Dataset Preparation": "Create a dataset of question pairs or sequences that test temporal consistency. This dataset should include: a) Identical questions asked at different 'time points', b) Similar questions with slight variations, c) Questions with added irrelevant information.",
            "Step 2: Baseline Methods": "Implement standard confidence estimation techniques: a) Direct prompting for confidence, b) Calibrated confidence estimation using temperature scaling, c) Ensemble-based uncertainty estimation.",
            "Step 3: Temporal Coherence Prompting Implementation": "Develop the TCP method with the following components: a) Initial confidence estimation, b) Time passage simulation, c) Confidence re-estimation with justification, d) Consistency check and adjustment.",
            "Step 4: Model Selection": "Use GPT-3.5 (text-davinci-003) and GPT-4 from OpenAI API for experiments.",
            "Step 5: Experiment Execution": "For each question in the dataset: a) Apply baseline methods, b) Apply TCP method, c) Record confidence estimates, justifications, and any adjustments made.",
            "Step 6: Evaluation Metrics": "Implement the following metrics: a) Confidence Consistency Score (CCS): measure of how consistent the confidence estimates are across time points, b) Justification Quality Score (JQS): human evaluation of the quality and relevance of justifications for confidence changes, c) Calibration Error: measure of how well-calibrated the confidence estimates are with actual performance.",
            "Step 7: Analysis": "Compare TCP against baselines using the defined metrics. Analyze patterns in confidence adjustments and justifications provided by the model."
        },
        "Test Case Examples": {
            "Baseline Prompt Input": "Q: What is the capital of France? Please provide your answer and your confidence level (0-100%).",
            "Baseline Prompt Expected Output": "A: The capital of France is Paris. Confidence: 95%",
            "Proposed Prompt Input (TCP; Step 1: Initial Estimation)": "Q: What is the capital of France? Please provide your answer and your confidence level (0-100%).",
            "Proposed Prompt Expected Output (TCP; Step 1: Initial Estimation)": "A: The capital of France is Paris. Confidence: 95%",
            "Proposed Prompt Input (TCP; Step 2: Time Passage)": "It's now 6 months later. Q: What is the capital of France? Please provide your answer, your confidence level (0-100%), and explain any changes in your confidence.",
            "Proposed Prompt Expected Output (TCP; Step 2: Time Passage)": "A: The capital of France is still Paris. Confidence: 95%. My confidence remains unchanged because the capital of a country is a stable fact that doesn't typically change over a 6-month period, and I haven't received any new information that would alter my confidence in this knowledge.",
            "Proposed Prompt Input (TCP; Step 3: Irrelevant Information)": "You just learned that the Eiffel Tower was repainted last month. Q: What is the capital of France? Please provide your answer, your confidence level (0-100%), and explain any changes in your confidence.",
            "Proposed Prompt Expected Output (TCP; Step 3: Irrelevant Information)": "A: The capital of France remains Paris. Confidence: 95%. The new information about the Eiffel Tower being repainted is irrelevant to the question of France's capital. While it's an interesting fact about a famous Parisian landmark, it doesn't affect the status of Paris as the capital or my confidence in this knowledge.",
            "explanation": "The TCP method maintains consistent confidence across time points and in the face of irrelevant information, while also providing justifications for the consistency. This contrasts with potential inconsistencies in baseline methods that might fluctuate without explanation."
        },
        "Fallback Plan": "If the TCP method doesn't significantly improve consistency over baselines, we can pivot to an analysis paper. We would investigate patterns in confidence fluctuations across different question types and time intervals. This could involve categorizing questions based on their susceptibility to temporal inconsistency and analyzing the linguistic features of justifications provided. We could also explore the impact of different 'time passage' intervals on confidence estimates, potentially uncovering optimal intervals for maintaining consistency. Additionally, we might investigate how the introduction of truly relevant new information affects confidence estimates, comparing this to the irrelevant information cases. This analysis could provide valuable insights into the temporal dynamics of LLM confidence estimation, even if our original hypothesis about improving consistency isn't fully supported."
    }
}