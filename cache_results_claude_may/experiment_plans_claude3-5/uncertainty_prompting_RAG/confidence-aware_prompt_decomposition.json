{
    "topic_description": "novel prompting methods that can better quantify uncertainty or calibrate the confidence of large language models",
    "idea_name": "Confidence-Aware Prompt Decomposition",
    "raw_idea": {
        "Problem": "LLMs often struggle to accurately quantify uncertainty for complex queries that require multi-step reasoning.",
        "Existing Methods": "Current approaches like direct confidence elicitation or consistency sampling fail to capture fine-grained uncertainties in different reasoning steps.",
        "Motivation": "Breaking down complex queries into simpler sub-queries and aggregating uncertainties can lead to more precise overall uncertainty estimation.",
        "Proposed Method": "We introduce Confidence-Aware Prompt Decomposition (CAPD), a novel prompting technique that (1) uses the LLM to decompose a complex query into a series of simpler sub-queries, (2) prompts for confidence estimates on each sub-query, and (3) aggregates these estimates using another LLM-generated aggregation strategy. The decomposition prompt guides the LLM to break down the query into atomic steps. For each sub-query, we use calibrated verbalized confidence prompts. Finally, we prompt the LLM to generate an aggregation strategy (e.g., minimum confidence, weighted average) based on the logical structure of the decomposition, and apply this to combine sub-query confidences into an overall estimate.",
        "Experiment Plan": "Evaluate CAPD against baselines like direct confidence elicitation and consistency sampling on multi-step reasoning benchmarks such as GSM8K and MATH. Measure calibration using metrics like Expected Calibration Error (ECE) and compare the granularity of uncertainty estimates."
    },
    "full_experiment_plan": {
        "Title": "Confidence-Aware Prompt Decomposition (CAPD): Improving Uncertainty Quantification in Large Language Models",
        "Problem Statement": "Large Language Models (LLMs) often struggle to accurately quantify uncertainty for complex queries that require multi-step reasoning. Current approaches like direct confidence elicitation or consistency sampling fail to capture fine-grained uncertainties in different reasoning steps, leading to overconfident or poorly calibrated predictions.",
        "Motivation": "Existing methods for uncertainty quantification in LLMs often treat complex queries as monolithic tasks, failing to account for the varying levels of uncertainty associated with different reasoning steps. By breaking down complex queries into simpler sub-queries and aggregating uncertainties, we can potentially achieve more precise overall uncertainty estimation. This approach is inspired by human problem-solving strategies, where we often decompose complex problems into smaller, more manageable parts and assess our confidence in each step separately.",
        "Proposed Method": "We introduce Confidence-Aware Prompt Decomposition (CAPD), a novel prompting technique that leverages the LLM's own capabilities to improve uncertainty quantification. CAPD consists of three main steps: (1) Query Decomposition: We prompt the LLM to break down a complex query into a series of simpler sub-queries. (2) Confidence Elicitation: For each sub-query, we use calibrated verbalized confidence prompts to elicit uncertainty estimates. (3) Confidence Aggregation: We prompt the LLM to generate an aggregation strategy based on the logical structure of the decomposition and apply this to combine sub-query confidences into an overall estimate.",
        "Step-by-Step Experiment Plan": {
            "Step 1: Dataset Preparation": "We will use two datasets for our experiments: (1) GSM8K: A dataset of 8,500 grade school math word problems. (2) MATH: A dataset of 12,500 middle and high school mathematics problems. Split each dataset into training (80%) and test (20%) sets.",
            "Step 2: Baseline Implementation": "Implement two baseline methods: (1) Direct confidence elicitation: Prompt the LLM to solve the problem and provide a confidence estimate. (2) Consistency sampling: Generate multiple solutions and use the consistency as a proxy for confidence.",
            "Step 3: CAPD Implementation": "Implement the three steps of CAPD: (1) Query Decomposition: Prompt the LLM to break down the problem into sub-queries. Example prompt: 'Break down this problem into simpler sub-questions: [PROBLEM]'. (2) Confidence Elicitation: For each sub-query, use calibrated verbalized confidence prompts. Example prompt: 'Solve this sub-question and express your confidence in your answer on a scale from 0 to 100: [SUB-QUERY]'. (3) Confidence Aggregation: Prompt the LLM to generate an aggregation strategy. Example prompt: 'Given the following sub-questions and their confidence scores, propose a method to aggregate these into an overall confidence score: [SUB-QUERIES AND SCORES]'.",
            "Step 4: Model Selection": "We will use GPT-4 as our primary model for all experiments. Additionally, we will test GPT-3.5-turbo to assess the method's generalizability.",
            "Step 5: Evaluation": "For each problem in the test set, apply both baseline methods and CAPD. Measure performance using the following metrics: (1) Accuracy: Percentage of correctly solved problems. (2) Expected Calibration Error (ECE): Measure of calibration quality. (3) Brier Score: Combines calibration and resolution aspects of probabilistic predictions. (4) Decomposition Quality: Manual evaluation of a subset of decompositions for relevance and completeness.",
            "Step 6: Analysis": "Compare CAPD against baselines across all metrics. Conduct ablation studies to assess the impact of each CAPD component. Analyze cases where CAPD significantly outperforms or underperforms baselines."
        },
        "Test Case Examples": {
            "Baseline Prompt Input (Direct Confidence Elicitation)": "Solve this problem and provide your confidence in the answer on a scale from 0 to 100: Janet's doughnut shop sold 20 boxes of doughnuts on Thursday, 25 boxes on Friday, and 30 boxes on Saturday. A box of doughnuts costs $15. How much money did Janet's shop make over these three days?",
            "Baseline Prompt Expected Output (Direct Confidence Elicitation)": "Answer: Janet's shop made $1,125 over these three days. Here's the calculation:\nThursday: 20 boxes * $15 = $300\nFriday: 25 boxes * $15 = $375\nSaturday: 30 boxes * $15 = $450\nTotal: $300 + $375 + $450 = $1,125\n\nConfidence: 95",
            "Proposed Prompt Input (CAPD Step 1: Query Decomposition)": "Break down this problem into simpler sub-questions: Janet's doughnut shop sold 20 boxes of doughnuts on Thursday, 25 boxes on Friday, and 30 boxes on Saturday. A box of doughnuts costs $15. How much money did Janet's shop make over these three days?",
            "Proposed Prompt Expected Output (CAPD Step 1: Query Decomposition)": "1. How many boxes of doughnuts were sold on Thursday?\n2. How many boxes of doughnuts were sold on Friday?\n3. How many boxes of doughnuts were sold on Saturday?\n4. What is the cost of one box of doughnuts?\n5. How much money was made from Thursday's sales?\n6. How much money was made from Friday's sales?\n7. How much money was made from Saturday's sales?\n8. What is the total amount of money made over the three days?",
            "Proposed Prompt Input (CAPD Step 2: Confidence Elicitation)": "Solve this sub-question and express your confidence in your answer on a scale from 0 to 100: How much money was made from Thursday's sales?",
            "Proposed Prompt Expected Output (CAPD Step 2: Confidence Elicitation)": "Answer: $300 was made from Thursday's sales. This is calculated by multiplying the number of boxes sold on Thursday (20) by the price per box ($15).\nConfidence: 100",
            "Proposed Prompt Input (CAPD Step 3: Confidence Aggregation)": "Given the following sub-questions and their confidence scores, propose a method to aggregate these into an overall confidence score:\n1. How many boxes of doughnuts were sold on Thursday? (Confidence: 100)\n2. How many boxes of doughnuts were sold on Friday? (Confidence: 100)\n3. How many boxes of doughnuts were sold on Saturday? (Confidence: 100)\n4. What is the cost of one box of doughnuts? (Confidence: 100)\n5. How much money was made from Thursday's sales? (Confidence: 100)\n6. How much money was made from Friday's sales? (Confidence: 100)\n7. How much money was made from Saturday's sales? (Confidence: 100)\n8. What is the total amount of money made over the three days? (Confidence: 98)",
            "Proposed Prompt Expected Output (CAPD Step 3: Confidence Aggregation)": "To aggregate the confidence scores, we should consider that the overall confidence is limited by the lowest confidence in any critical step. In this case, all sub-questions have a confidence of 100 except for the final calculation of the total amount, which has a confidence of 98. Since the final calculation depends on all previous steps and introduces a slight uncertainty, the overall confidence should be 98.\n\nAggregation method: Take the minimum confidence score among all sub-questions.\n\nOverall confidence score: 98",
            "explanation": "CAPD improves uncertainty quantification by breaking down the problem into simpler sub-questions, assessing confidence for each sub-question, and then aggregating these confidences. This approach allows for more nuanced uncertainty estimation compared to the baseline method, which might overlook uncertainties in specific steps of the problem-solving process."
        },
        "Fallback Plan": "If CAPD does not significantly outperform the baselines, we will conduct a thorough analysis to understand why. This may include: (1) Examining the quality of problem decompositions to ensure they are logical and comprehensive. (2) Analyzing the confidence estimates for individual sub-queries to identify any systematic biases or errors. (3) Evaluating the effectiveness of different aggregation strategies. Based on these analyses, we might refine the CAPD method, for example, by experimenting with different prompting techniques for decomposition or confidence elicitation. Additionally, we could explore combining CAPD with other uncertainty quantification methods, such as ensemble techniques or calibration methods, to create a hybrid approach. If these refinements do not yield significant improvements, we could pivot the project towards an in-depth analysis of why decomposition-based approaches struggle with uncertainty quantification in LLMs, potentially uncovering important insights about the limitations of current language models in reasoning tasks."
    }
}