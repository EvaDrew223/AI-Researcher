from openai import OpenAI
import anthropic
import json
import random 
from tqdm import tqdm 
from utils import call_api, load_model
import random
random.seed(2024)

## Step 1: Generate synthetic test examples
def generate_testset():
    test_data = [
        {
            "input": "How do solar panels work?",
            "output": "Solar panels work by converting sunlight into electricity. They are made up of many individual solar cells, which are typically made of silicon. When sunlight hits a solar cell, it knocks electrons loose from their atoms, allowing them to flow through the material to produce electricity. This process is called the photovoltaic effect.\n\nHere's a step-by-step breakdown of how solar panels generate electricity:\n\n1. Photons in sunlight hit the solar panel and are absorbed by the semiconducting material, usually silicon.\n\n2. The photons knock electrons loose from their atoms, allowing them to flow freely.\n\n3. The solar panel is designed with positively and negatively charged semiconductors sandwiched together, creating an electric field. This electric field forces the dislodged electrons to flow in a certain direction, generating an electrical current.\n\n4. Metal conductive plates on the sides of each cell collect the electrons and transfer them to wires. The electrons then flow through the wires as electricity.\n\n5. The electricity generated by the solar panels is direct current (DC). For most residential and commercial uses, the DC electricity is passed through an inverter to convert it to alternating current (AC) electricity, which is the type of electricity used in homes and businesses.\n\nSolar panels are typically combined into larger arrays to increase the total amount of electricity generated. The electricity can be used immediately, fed into the electrical grid, or stored in batteries for later use. The efficiency of solar panels depends on factors such as the materials used, the design of the panel, and the amount of sunlight available."
        },
        {
            "input": "What is the process of nuclear fusion?",
            "output": "Nuclear fusion is the process by which two light atomic nuclei combine to form a single heavier nucleus, releasing a large amount of energy in the process. It is the same process that powers the sun and other stars. Here's a step-by-step explanation of how nuclear fusion works:\n\n1. High temperatures: For fusion to occur, the atoms need to be heated to extremely high temperatures, typically around 100 million degrees Celsius. At these temperatures, the atoms are moving so fast that they can overcome the electrostatic repulsion between their positively charged nuclei.\n\n2. High pressure: In addition to high temperatures, high pressure is also necessary for fusion. The pressure helps to force the nuclei together, increasing the chances of a fusion reaction occurring.\n\n3. Fusion reaction: When the nuclei of two light atoms, such as hydrogen, are forced together, they can fuse to form a heavier nucleus, such as helium. In the process, a small amount of the mass of the original nuclei is converted into a large amount of energy, according to Einstein's famous equation E=mc^2.\n\n4. Energy release: The energy released by fusion is carried away by the resulting nucleus and by high-energy particles called neutrons. In a fusion reactor, the goal is to capture this energy and use it to generate electricity.\n\n5. Containment: One of the main challenges of harnessing fusion power is containing the incredibly hot plasma where the fusion reactions occur. This is typically done using strong magnetic fields in devices called tokamaks or stellarators.\n\nThe most common fusion reaction being researched for power generation is the fusion of deuterium and tritium, two isotopes of hydrogen. This reaction produces helium and a high-energy neutron.\n\nWhile fusion power offers the potential for nearly limitless, clean energy, it has proven to be a significant technical challenge. Scientists and engineers are still working on developing practical, efficient fusion reactors that can generate more energy than they consume. Despite the challenges, many see fusion as a promising long-term solution for meeting the world's growing energy needs."
        },
        {
            "input": "Explain the water cycle and its importance for life on Earth.",
            "output": "The water cycle, also known as the hydrologic cycle, is the continuous movement of water on, above, and below the surface of the Earth. This process is essential for maintaining life on our planet. Here's a breakdown of the water cycle and its importance:\n\nStages of the water cycle:\n1. Evaporation: Water on the Earth's surface, such as in oceans, lakes, and rivers, is heated by the sun and turns into water vapor, which rises into the atmosphere.\n\n2. Transpiration: Plants absorb water through their roots and release it into the atmosphere through their leaves.\n\n3. Condensation: As water vapor rises into the atmosphere, it cools and condenses into tiny water droplets, forming clouds and fog.\n\n4. Precipitation: When the water droplets in clouds become too heavy, they fall back to the Earth's surface as rain, snow, sleet, or hail.\n\n5. Runoff: When precipitation reaches the ground, some of the water flows over the surface as runoff, eventually reaching streams, rivers, and oceans.\n\n6. Infiltration: Some of the water also seeps into the ground, becoming groundwater. This water can later resurface through springs or be extracted by humans via wells.\n\nImportance of the water cycle:\n1. Sustains life: The water cycle is crucial for the survival of all living organisms. It ensures a continuous supply of freshwater for drinking, hygiene, and agriculture.\n\n2. Regulates climate: The evaporation and condensation processes in the water cycle help to regulate the Earth's temperature and climate patterns.\n\n3. Shapes the landscape: The movement of water through runoff and infiltration helps to shape the Earth's landscape, creating rivers, lakes, and canyons.\n\n4. Supports ecosystems: The water cycle is essential for maintaining healthy ecosystems, as it provides the water needed for plants to grow and supports aquatic life.\n\n5. Renewable resource: The water cycle makes water a renewable resource, as it is continuously recycled and replenished through natural processes.\n\nHuman activities, such as deforestation, urbanization, and climate change, can disrupt the water cycle and affect the availability and quality of freshwater resources. Therefore, it is essential to manage and protect our water resources to ensure a sustainable future for life on Earth."
        }
    ]

    return test_data


## Step 2: Implement the baseline method 
def baseline_method(client, model_name, seed, question):
    ## vanilla prompting
    prompt = "Answer the following question: {}\n".format(question)
    prompt_messages = [{"role": "user", "content": prompt}]
    response, _ = call_api(client, model_name, prompt_messages, temperature=0., max_tokens=2000, seed=seed, json_output=False)
    return response.strip()


## Step 3: Implement the proposed method 
def proposed_method(client, model_name, seed, question, print_all=False):
    intermediate_outputs = "" 
    
    if print_all:
        print ("question:\n", question)

    ## Socratic probing step 1: initial response generation
    prompt = "Answer the following question: {}\n".format(question)
    prompt_messages = [{"role": "user", "content": prompt}]
    initial_response, _ = call_api(client, model_name, prompt_messages, temperature=0., max_tokens=2000, seed=seed, json_output=False)
    intermediate_outputs += "initial response:\n" + initial_response + "\n"
    if print_all:
        print ("initial response:\n", initial_response)

    ## Socratic probing step 2: factuality probing
    prompt = "Given the following response:\n{}\n\nPlease ask a series of Socratic questions to probe the factuality of the claims made in the response. For example:\n- What is the source of this claim?\n- Is there any evidence that supports or contradicts this statement?\n- Are there any implicit assumptions being made?\n\nAsk at least 3 probing questions.".format(initial_response)
    prompt_messages = [{"role": "user", "content": prompt}]
    factuality_probes, _ = call_api(client, model_name, prompt_messages, temperature=0., max_tokens=2000, seed=seed, json_output=False)
    intermediate_outputs += "factuality probes:\n" + factuality_probes + "\n"
    if print_all:
        print ("factuality probes:\n", factuality_probes)

    ## Socratic probing step 3: answer probing questions
    prompt = "Given the following response:\n{}\n\nAnd the following factuality probing questions:\n{}\n\nPlease answer each of the probing questions to the best of your ability based on your knowledge.".format(initial_response, factuality_probes)
    prompt_messages = [{"role": "user", "content": prompt}]
    probe_answers, _ = call_api(client, model_name, prompt_messages, temperature=0., max_tokens=2000, seed=seed, json_output=False)
    intermediate_outputs += "probe answers:\n" + probe_answers + "\n"
    if print_all:
        print ("probe answers:\n", probe_answers)

    ## Socratic probing step 4: factuality scoring
    prompt = "Given the following response:\n{}\n\nAnd the following factuality probing questions and answers:\n{}\n{}\n\nPlease score the factuality of each sentence in the original response on a scale of 1-5, where 1 means the sentence is not factual at all and 5 means the sentence is completely factual. Provide a brief justification for each score.".format(initial_response, factuality_probes, probe_answers)
    prompt_messages = [{"role": "user", "content": prompt}]
    factuality_scores, _ = call_api(client, model_name, prompt_messages, temperature=0., max_tokens=2000, seed=seed, json_output=False)
    intermediate_outputs += "factuality scores:\n" + factuality_scores + "\n"
    if print_all:
        print ("factuality scores:\n", factuality_scores)

    ## Socratic probing step 5: response refinement
    prompt = "Given the following response:\n{}\n\nAnd the following factuality scores for each sentence:\n{}\n\nPlease refine the response to improve the factuality of the low-scoring sentences. You may need to remove unsupported claims, add evidence from reliable sources, or clarify assumptions. The refined response should be factual and coherent.".format(initial_response, factuality_scores)
    prompt_messages = [{"role": "user", "content": prompt}]
    refined_response, _ = call_api(client, model_name, prompt_messages, temperature=0., max_tokens=2000, seed=seed, json_output=False)
    intermediate_outputs += "refined response:\n" + refined_response
    if print_all:
        print ("refined response:\n", refined_response)

    return refined_response.strip(), intermediate_outputs


## Step 4: Define the style evaluator
def style_evaluator(client, model_name, seed, question, baseline_prediction, proposed_prediction):
    ## check if the proposed method output contains all the desired components
    prompt = "Given the task: {}\n".format(question)
    prompt += "The baseline method produced the following output:\n{}\n\n".format(baseline_prediction)
    prompt += "The proposed new method produced the following output:\n{}\n\n".format(proposed_prediction)
    prompt += "Please check if the proposed method's output contains all of the following components:\n"
    prompt += "1. Initial response\n2. Factuality probing questions\n3. Answers to probing questions\n4. Factuality scores for each sentence\n5. Refined response\n\n"
    prompt += "Respond with a single word: PASS if all components are present, or FAIL if any are missing."
    prompt_messages = [{"role": "user", "content": prompt}]
    response, _ = call_api(client, model_name, prompt_messages, temperature=0., max_tokens=1, seed=seed, json_output=False)
    
    judgment = False
    if response.strip().lower() == "pass":
        return True 
    
    return judgment


## Step 5: Define the output evaluator
def output_evaluator(client, model_name, seed, question, gold_label, prediction):
    ## score the factuality and coherence of the prediction compared to the gold label
    prompt = "Given the following question:\n{}\n\nThe reference answer is:\n{}\n\nAnd the predicted answer is:\n{}\n\n".format(question, gold_label, prediction)
    prompt += "Please score the factuality and coherence of the predicted answer compared to the reference answer on a scale of 1-10, where 1 means the prediction is not at all factual or coherent, and 10 means it is perfectly factual and coherent.\n\n"
    prompt += "Provide a single number score."
    prompt_messages = [{"role": "user", "content": prompt}]
    response, _ = call_api(client, model_name, prompt_messages, temperature=0., max_tokens=1, seed=seed, json_output=False)
    
    try:
        score = float(response.strip())
    except:
        score = 0.0

    return score


## Step 6: Define the function that runs the experiments to obtain model predictions and performance
## you shouldn't need to modify this function in most cases
def run_experiment(client, model_name, seed, testset):
    sample_size = len(testset) 
    baseline_predictions = []
    proposed_predictions = []

    baseline_scores = []
    proposed_scores = []

    style_check = []

    for i in tqdm(range(sample_size)):
        question = testset[i]["input"].strip()
        gold_label = testset[i]["output"].strip()
        
        baseline_prediction = baseline_method(client, model_name, seed, question)
        proposed_prediction_final, proposed_prediction_intermediate = proposed_method(client, model_name, seed, question)
        baseline_predictions.append(baseline_prediction)
        proposed_predictions.append(proposed_prediction_final)
        
        baseline_scores.append(output_evaluator(client, model_name, seed, question, gold_label, baseline_prediction))
        proposed_scores.append(output_evaluator(client, model_name, seed, question, gold_label, proposed_prediction_final))

        style_check.append(style_evaluator(client, model_name, seed, question, baseline_prediction, proposed_prediction_intermediate))

    return baseline_scores, proposed_scores, style_check


## Step 7: Execute the experiments and compare performance 
if __name__ == "__main__":
    testset = generate_testset()
    print ("simulated {} test examples for evaluation.".format(len(testset)))

    model_name = "claude-3-opus-20240229" ## don't change this
    seed = 2024 
    client = load_model(model_name)
    print ("using model: ", model_name)

    ## output scores 
    baseline_scores, proposed_scores, style_check = run_experiment(client, model_name, seed, testset)
    print ("baseline average score: ", sum(baseline_scores) / len(baseline_scores))
    print ("proposed average score: ", sum(proposed_scores) / len(proposed_scores))
    print ("style check pass rate: ", sum(style_check) / len(style_check))
