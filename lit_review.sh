# python3 lit_review.py \
#  --topic_description "better prompting strategies for large language models to improve multi-step problem solving abilities" \
#  --cache_name "multi_step_prompting" \
#  --print_all

# python3 lit_review.py \
#  --topic_description "probing large multimodal models through prompting to reveal specific limitations or interesting behaviors" \
#  --cache_name "multimodal_probing" \
#  --print_all

# python3 lit_review.py \
#  --topic_description "methods that can quantify confidence or uncertainty of black-box language model predictions" \
#  --cache_name "uncertainty" \
#  --print_all

# python3 lit_review.py \
#  --topic_description "probing biases and fairness issues of large language models through prompting" \
#  --cache_name "bias" \
#  --print_all

# python3 lit_review.py \
#  --topic_description "probing biases and fairness issues of large multimodal models through prompting" \
#  --cache_name "multimodal_bias" \
#  --print_all

# python3 lit_review.py \
#  --topic_description "better prompting strategies for large language models to improve code generation accuracy" \
#  --cache_name "code_prompting" \
#  --print_all

# python3 lit_review.py \
#  --topic_description "better prompting methods that can improve factuality and reduce hallucination of large language models or multimodal models" \
#  --cache_name "factuality" \
#  --print_all

# python3 lit_review.py \
#  --topic_description "empirical analysis to study how in-context learning works, such as the impact of each component of the prompt and how to optimize in-context learning performance" \
#  --cache_name "in_context_learning" \
#  --print_all

python3 lit_review.py \
 --topic_description "the effect of governance in online communities on participation" \
 --cache_name "dora" \
 --print_all